{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Оптимизаторы</h3>\n",
    "<li> adam </li>\n",
    "<li> rmsprop </li>\n",
    "\n",
    "<h3>Функции активации</h3>\n",
    "<li> relu </li>\n",
    "<li> selu </li>\n",
    "<li> gelu </li>\n",
    "<li> elu </li>\n",
    "\n",
    "<h3> Реккурентные слои </h3>\n",
    "\n",
    "<li> LSTM </li>\n",
    "<li> GRU </li>\n",
    "\n",
    "<h3> Дропауты</h3>\n",
    "Следи за переобучением/недообучением. Меняй значения от 0.1 до 0.5\n",
    "\n",
    "<h3> Размерность эмбеддинга </h3>\n",
    "Попробуй 64, 128, 256 (embed_dim)\n",
    "\n",
    "<h3> Линейные слои </h3>\n",
    "Добавляй / убирай Dense слои, только не трогай последний!\n",
    "После Dense можно попробовать поставить layers.LayerNormalization()\n",
    "\n",
    "<h3> Одномерные сверточные слои (Conv1D) </h3>\n",
    "Меняй количество units и размер kernel size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import datasets, layers, models, preprocessing\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "        attention_output = self.attention(\n",
    "            inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ekaterinaaleksandrovna/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 128)               74496     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1354625 (5.17 MB)\n",
      "Trainable params: 1354625 (5.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "50/50 [==============================] - 31s 600ms/step - loss: 0.6918 - accuracy: 0.5276 - f1_score: 0.6667 - precision_1: 0.5275 - recall_1: 0.5286 - val_loss: 0.6899 - val_accuracy: 0.5637 - val_f1_score: 0.6667 - val_precision_1: 0.5604 - val_recall_1: 0.5912\n",
      "Epoch 2/40\n",
      "50/50 [==============================] - 29s 591ms/step - loss: 0.6849 - accuracy: 0.5753 - f1_score: 0.6667 - precision_1: 0.5744 - recall_1: 0.5816 - val_loss: 0.6773 - val_accuracy: 0.6028 - val_f1_score: 0.6667 - val_precision_1: 0.5965 - val_recall_1: 0.6359\n",
      "Epoch 3/40\n",
      "50/50 [==============================] - 35s 706ms/step - loss: 0.6376 - accuracy: 0.6470 - f1_score: 0.6667 - precision_1: 0.6421 - recall_1: 0.6642 - val_loss: 0.5522 - val_accuracy: 0.7341 - val_f1_score: 0.6667 - val_precision_1: 0.7100 - val_recall_1: 0.7917\n",
      "Epoch 4/40\n",
      "50/50 [==============================] - 36s 729ms/step - loss: 0.5046 - accuracy: 0.7586 - f1_score: 0.6667 - precision_1: 0.7569 - recall_1: 0.7618 - val_loss: 0.4335 - val_accuracy: 0.8046 - val_f1_score: 0.6667 - val_precision_1: 0.7518 - val_recall_1: 0.9095\n",
      "Epoch 5/40\n",
      "50/50 [==============================] - 36s 726ms/step - loss: 0.4324 - accuracy: 0.8067 - f1_score: 0.6686 - precision_1: 0.7955 - recall_1: 0.8255 - val_loss: 0.3944 - val_accuracy: 0.8271 - val_f1_score: 0.6668 - val_precision_1: 0.7883 - val_recall_1: 0.8944\n",
      "Epoch 6/40\n",
      "50/50 [==============================] - 37s 737ms/step - loss: 0.4206 - accuracy: 0.8312 - f1_score: 0.6676 - precision_1: 0.8582 - recall_1: 0.7935 - val_loss: 0.4432 - val_accuracy: 0.8267 - val_f1_score: 0.6985 - val_precision_1: 0.9153 - val_recall_1: 0.7201\n",
      "Epoch 7/40\n",
      "50/50 [==============================] - 37s 739ms/step - loss: 0.3482 - accuracy: 0.8559 - f1_score: 0.6693 - precision_1: 0.8560 - recall_1: 0.8558 - val_loss: 0.5304 - val_accuracy: 0.8202 - val_f1_score: 0.6667 - val_precision_1: 0.7511 - val_recall_1: 0.9577\n",
      "Epoch 8/40\n",
      "50/50 [==============================] - 37s 738ms/step - loss: 0.3317 - accuracy: 0.8661 - f1_score: 0.6678 - precision_1: 0.8694 - recall_1: 0.8615 - val_loss: 0.3408 - val_accuracy: 0.8517 - val_f1_score: 0.6668 - val_precision_1: 0.8781 - val_recall_1: 0.8168\n",
      "Epoch 9/40\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 0.3183 - accuracy: 0.8722 - f1_score: 0.6669 - precision_1: 0.8798 - recall_1: 0.8622 - val_loss: 0.3497 - val_accuracy: 0.8480 - val_f1_score: 0.6667 - val_precision_1: 0.8045 - val_recall_1: 0.9196\n",
      "Epoch 10/40\n",
      "50/50 [==============================] - 38s 756ms/step - loss: 0.2946 - accuracy: 0.8832 - f1_score: 0.6667 - precision_1: 0.8795 - recall_1: 0.8882 - val_loss: 0.3486 - val_accuracy: 0.8482 - val_f1_score: 0.6667 - val_precision_1: 0.9104 - val_recall_1: 0.7725\n",
      "Epoch 11/40\n",
      "50/50 [==============================] - 36s 726ms/step - loss: 0.2737 - accuracy: 0.8909 - f1_score: 0.6667 - precision_1: 0.8920 - recall_1: 0.8896 - val_loss: 0.5440 - val_accuracy: 0.7725 - val_f1_score: 0.6667 - val_precision_1: 0.9640 - val_recall_1: 0.5661\n",
      "Epoch 12/40\n",
      "50/50 [==============================] - 36s 729ms/step - loss: 0.2612 - accuracy: 0.8978 - f1_score: 0.6667 - precision_1: 0.9048 - recall_1: 0.8890 - val_loss: 0.3570 - val_accuracy: 0.8511 - val_f1_score: 0.6667 - val_precision_1: 0.9256 - val_recall_1: 0.7636\n",
      "Epoch 13/40\n",
      "50/50 [==============================] - 37s 737ms/step - loss: 0.2512 - accuracy: 0.9017 - f1_score: 0.6667 - precision_1: 0.9047 - recall_1: 0.8980 - val_loss: 0.3140 - val_accuracy: 0.8640 - val_f1_score: 0.6667 - val_precision_1: 0.8682 - val_recall_1: 0.8584\n",
      "Epoch 14/40\n",
      "50/50 [==============================] - 37s 753ms/step - loss: 0.2346 - accuracy: 0.9103 - f1_score: 0.6667 - precision_1: 0.9138 - recall_1: 0.9062 - val_loss: 0.3494 - val_accuracy: 0.8556 - val_f1_score: 0.6667 - val_precision_1: 0.9247 - val_recall_1: 0.7743\n",
      "Epoch 15/40\n",
      "50/50 [==============================] - 36s 724ms/step - loss: 0.2233 - accuracy: 0.9170 - f1_score: 0.6667 - precision_1: 0.9186 - recall_1: 0.9150 - val_loss: 0.3242 - val_accuracy: 0.8650 - val_f1_score: 0.6667 - val_precision_1: 0.9115 - val_recall_1: 0.8086\n",
      "Epoch 16/40\n",
      "50/50 [==============================] - 36s 725ms/step - loss: 0.2160 - accuracy: 0.9173 - f1_score: 0.6667 - precision_1: 0.9237 - recall_1: 0.9097 - val_loss: 0.4263 - val_accuracy: 0.8465 - val_f1_score: 0.6667 - val_precision_1: 0.7857 - val_recall_1: 0.9530\n",
      "Epoch 17/40\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 0.2081 - accuracy: 0.9217 - f1_score: 0.6667 - precision_1: 0.9237 - recall_1: 0.9193 - val_loss: 0.3271 - val_accuracy: 0.8656 - val_f1_score: 0.6667 - val_precision_1: 0.9098 - val_recall_1: 0.8117\n",
      "Epoch 18/40\n",
      "50/50 [==============================] - 36s 730ms/step - loss: 0.1974 - accuracy: 0.9248 - f1_score: 0.6667 - precision_1: 0.9284 - recall_1: 0.9205 - val_loss: 0.3121 - val_accuracy: 0.8750 - val_f1_score: 0.6667 - val_precision_1: 0.8899 - val_recall_1: 0.8559\n",
      "Epoch 19/40\n",
      "50/50 [==============================] - 37s 746ms/step - loss: 0.1834 - accuracy: 0.9337 - f1_score: 0.6667 - precision_1: 0.9389 - recall_1: 0.9278 - val_loss: 0.3290 - val_accuracy: 0.8724 - val_f1_score: 0.6667 - val_precision_1: 0.8530 - val_recall_1: 0.8998\n",
      "Epoch 20/40\n",
      "50/50 [==============================] - 36s 726ms/step - loss: 0.1892 - accuracy: 0.9291 - f1_score: 0.6667 - precision_1: 0.9329 - recall_1: 0.9247 - val_loss: 0.4155 - val_accuracy: 0.8557 - val_f1_score: 0.6667 - val_precision_1: 0.8032 - val_recall_1: 0.9423\n",
      "Epoch 21/40\n",
      "50/50 [==============================] - 37s 742ms/step - loss: 0.1764 - accuracy: 0.9348 - f1_score: 0.6667 - precision_1: 0.9391 - recall_1: 0.9298 - val_loss: 0.3700 - val_accuracy: 0.8592 - val_f1_score: 0.6667 - val_precision_1: 0.8140 - val_recall_1: 0.9314\n",
      "Epoch 22/40\n",
      "50/50 [==============================] - 38s 758ms/step - loss: 0.1685 - accuracy: 0.9373 - f1_score: 0.6667 - precision_1: 0.9395 - recall_1: 0.9348 - val_loss: 0.3607 - val_accuracy: 0.8624 - val_f1_score: 0.6667 - val_precision_1: 0.9149 - val_recall_1: 0.7991\n",
      "Epoch 23/40\n",
      "50/50 [==============================] - 38s 754ms/step - loss: 0.1618 - accuracy: 0.9401 - f1_score: 0.6667 - precision_1: 0.9436 - recall_1: 0.9362 - val_loss: 0.3251 - val_accuracy: 0.8679 - val_f1_score: 0.6667 - val_precision_1: 0.8781 - val_recall_1: 0.8544\n",
      "Epoch 24/40\n",
      "50/50 [==============================] - 37s 745ms/step - loss: 0.1521 - accuracy: 0.9439 - f1_score: 0.6667 - precision_1: 0.9496 - recall_1: 0.9375 - val_loss: 0.3735 - val_accuracy: 0.8486 - val_f1_score: 0.6667 - val_precision_1: 0.8056 - val_recall_1: 0.9191\n",
      "Epoch 25/40\n",
      "50/50 [==============================] - 38s 762ms/step - loss: 0.1491 - accuracy: 0.9452 - f1_score: 0.6667 - precision_1: 0.9468 - recall_1: 0.9434 - val_loss: 0.3524 - val_accuracy: 0.8704 - val_f1_score: 0.6667 - val_precision_1: 0.8882 - val_recall_1: 0.8475\n",
      "Epoch 26/40\n",
      "50/50 [==============================] - 38s 754ms/step - loss: 0.1382 - accuracy: 0.9483 - f1_score: 0.6667 - precision_1: 0.9496 - recall_1: 0.9469 - val_loss: 0.3649 - val_accuracy: 0.8706 - val_f1_score: 0.6667 - val_precision_1: 0.8893 - val_recall_1: 0.8467\n",
      "Epoch 27/40\n",
      "50/50 [==============================] - 38s 771ms/step - loss: 0.1360 - accuracy: 0.9502 - f1_score: 0.6667 - precision_1: 0.9535 - recall_1: 0.9466 - val_loss: 0.3606 - val_accuracy: 0.8695 - val_f1_score: 0.6667 - val_precision_1: 0.8567 - val_recall_1: 0.8874\n",
      "Epoch 28/40\n",
      "50/50 [==============================] - 37s 734ms/step - loss: 0.1321 - accuracy: 0.9508 - f1_score: 0.6667 - precision_1: 0.9527 - recall_1: 0.9486 - val_loss: 0.4414 - val_accuracy: 0.8424 - val_f1_score: 0.6667 - val_precision_1: 0.9267 - val_recall_1: 0.7436\n",
      "Epoch 29/40\n",
      "50/50 [==============================] - 39s 784ms/step - loss: 0.1226 - accuracy: 0.9557 - f1_score: 0.6667 - precision_1: 0.9586 - recall_1: 0.9525 - val_loss: 0.3935 - val_accuracy: 0.8707 - val_f1_score: 0.6667 - val_precision_1: 0.8708 - val_recall_1: 0.8706\n",
      "Epoch 30/40\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 0.1192 - accuracy: 0.9588 - f1_score: 0.6667 - precision_1: 0.9621 - recall_1: 0.9552 - val_loss: 0.3988 - val_accuracy: 0.8696 - val_f1_score: 0.6667 - val_precision_1: 0.8599 - val_recall_1: 0.8830\n",
      "Epoch 31/40\n",
      "50/50 [==============================] - 38s 757ms/step - loss: 0.1106 - accuracy: 0.9601 - f1_score: 0.6667 - precision_1: 0.9613 - recall_1: 0.9587 - val_loss: 0.4627 - val_accuracy: 0.8520 - val_f1_score: 0.6667 - val_precision_1: 0.9145 - val_recall_1: 0.7766\n",
      "Epoch 32/40\n",
      "50/50 [==============================] - 38s 758ms/step - loss: 0.1124 - accuracy: 0.9599 - f1_score: 0.6667 - precision_1: 0.9615 - recall_1: 0.9581 - val_loss: 0.4206 - val_accuracy: 0.8675 - val_f1_score: 0.6667 - val_precision_1: 0.8737 - val_recall_1: 0.8593\n",
      "Epoch 33/40\n",
      "50/50 [==============================] - 37s 735ms/step - loss: 0.1086 - accuracy: 0.9599 - f1_score: 0.6667 - precision_1: 0.9639 - recall_1: 0.9556 - val_loss: 0.3972 - val_accuracy: 0.8649 - val_f1_score: 0.6667 - val_precision_1: 0.8710 - val_recall_1: 0.8566\n",
      "Epoch 34/40\n",
      "50/50 [==============================] - 37s 750ms/step - loss: 0.0948 - accuracy: 0.9686 - f1_score: 0.6667 - precision_1: 0.9723 - recall_1: 0.9646 - val_loss: 0.4398 - val_accuracy: 0.8664 - val_f1_score: 0.6667 - val_precision_1: 0.8652 - val_recall_1: 0.8680\n",
      "Epoch 35/40\n",
      "50/50 [==============================] - 38s 769ms/step - loss: 0.1015 - accuracy: 0.9644 - f1_score: 0.6667 - precision_1: 0.9663 - recall_1: 0.9624 - val_loss: 0.4378 - val_accuracy: 0.8671 - val_f1_score: 0.6667 - val_precision_1: 0.8698 - val_recall_1: 0.8635\n",
      "Epoch 36/40\n",
      "50/50 [==============================] - 38s 762ms/step - loss: 0.0889 - accuracy: 0.9704 - f1_score: 0.6667 - precision_1: 0.9723 - recall_1: 0.9685 - val_loss: 0.5212 - val_accuracy: 0.8450 - val_f1_score: 0.6667 - val_precision_1: 0.7931 - val_recall_1: 0.9334\n",
      "Epoch 37/40\n",
      "50/50 [==============================] - 37s 735ms/step - loss: 0.0925 - accuracy: 0.9681 - f1_score: 0.6667 - precision_1: 0.9701 - recall_1: 0.9660 - val_loss: 0.4166 - val_accuracy: 0.8589 - val_f1_score: 0.6667 - val_precision_1: 0.8664 - val_recall_1: 0.8486\n",
      "Epoch 38/40\n",
      "50/50 [==============================] - 37s 739ms/step - loss: 0.0808 - accuracy: 0.9733 - f1_score: 0.6667 - precision_1: 0.9750 - recall_1: 0.9715 - val_loss: 0.4843 - val_accuracy: 0.8645 - val_f1_score: 0.6667 - val_precision_1: 0.8742 - val_recall_1: 0.8516\n",
      "Epoch 39/40\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 0.0917 - accuracy: 0.9697 - f1_score: 0.6667 - precision_1: 0.9715 - recall_1: 0.9678 - val_loss: 0.4240 - val_accuracy: 0.8535 - val_f1_score: 0.6667 - val_precision_1: 0.8513 - val_recall_1: 0.8567\n",
      "Epoch 40/40\n",
      "50/50 [==============================] - 39s 785ms/step - loss: 0.0802 - accuracy: 0.9733 - f1_score: 0.6667 - precision_1: 0.9760 - recall_1: 0.9705 - val_loss: 0.4397 - val_accuracy: 0.8496 - val_f1_score: 0.6667 - val_precision_1: 0.8288 - val_recall_1: 0.8811\n",
      "50/50 [==============================] - 9s 175ms/step - loss: 0.4397 - accuracy: 0.8496 - f1_score: 0.6667 - precision_1: 0.8288 - recall_1: 0.8811\n",
      "\n",
      "Test score: 0.43966394662857056\n",
      "Test accuracy: 0.849560022354126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 20s 25ms/step\n",
      "результат: 0\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[0.46335655]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from keras.utils import pad_sequences\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "imdb = datasets.imdb\n",
    "num_words = 20000\n",
    "max_len = 200\n",
    "n_words = 10000\n",
    "dim_embedding = 128\n",
    "EPOCHS = 40 #если ты видишь, что обучаться может дальше (не вышли на плато или переобучение), то увеличь количество эпох\n",
    "BATCH_SIZE = 500 #вылетает по памяти? Пробуй уменьшить batch_size\n",
    "def load_data():\n",
    "        # Load data.\n",
    "        (X_train, y_train), (X_test, y_test) = datasets.imdb.load_data(num_words=n_words)\n",
    "        # Pad sequences with max_len.\n",
    "        X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "        X_test = pad_sequences(X_test, maxlen=max_len)\n",
    "        y_train = y_train.astype(np.float64)\n",
    "        y_test = y_test.astype(np.float64)\n",
    "        return (X_train, y_train), (X_test, y_test)\n",
    "    \n",
    "def build_model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(n_words, \n",
    "    dim_embedding, input_length=max_len))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.LSTM(128))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model   \n",
    "\n",
    "def build_model2():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(n_words, \n",
    "    dim_embedding, input_length=max_len))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Bidirectional(layers.LSTM(128))) #сюда можно добавить kernel_regularizer='l2',recurrent_regularizer='l2',dropout=0.1, recurrent_dropout=0.1. В Bidirectional - merge='sum'\n",
    "    #model.add(layers.GlobalMaxPooling1D())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model  \n",
    "\n",
    "def build_model3():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(n_words, \n",
    "    dim_embedding, input_length=max_len))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.LSTM(128,return_sequences=True)) #return sequences не уменьшает размерность, что надо для глобал макс пулинга\n",
    "    model.add(layers.GlobalMaxPooling1D())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model  \n",
    "\n",
    "def build_model4():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(n_words, \n",
    "    dim_embedding, input_length=max_len))\n",
    "    #model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.LSTM(128,activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model  \n",
    "\n",
    "def build_model5():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(n_words, \n",
    "    dim_embedding, input_length=max_len))\n",
    "    #model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Bidirectional(layers.GRU(64,activation='relu')))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model  \n",
    "\n",
    "def build_model6():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(n_words, \n",
    "    dim_embedding, input_length=max_len))\n",
    "    #model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.GRU(128,activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model  \n",
    "\n",
    "\n",
    "def build_model7():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(n_words, \n",
    "    dim_embedding, input_length=max_len))\n",
    "    model.add(TransformerEncoder(dim_embedding, 128, 2))\n",
    "    #model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.GRU(128,activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model  \n",
    "\n",
    "def build_model8():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(n_words, \n",
    "    dim_embedding, input_length=max_len))\n",
    "    model.add(TransformerEncoder(dim_embedding, 128, 2))\n",
    "    #model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Conv1D(128,kernel_size=2,activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model  \n",
    "\n",
    "def build_model8():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(n_words, \n",
    "    dim_embedding, input_length=max_len))\n",
    "    model.add(TransformerEncoder(dim_embedding, 128, 2))\n",
    "    #model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Conv1D(128,kernel_size=2,activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model  \n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_data()\n",
    "model = build_model5()\n",
    "model.summary()\n",
    "model.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\", keras.metrics.F1Score(), keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "score = model.fit(X_train, y_train,\n",
    " epochs = EPOCHS,\n",
    " batch_size = BATCH_SIZE,\n",
    " validation_data = (X_test, y_test)\n",
    ")\n",
    "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save(\"imdb9.h5\")\n",
    "\n",
    "val = model.predict(X_train)\n",
    "print(f'результат: {np.argmax(val[0])}')\n",
    "word2index = imdb.get_word_index()\n",
    "test=[]\n",
    "for word in word_tokenize( \"i love this movie\"):\n",
    "     test.append(word2index[word])\n",
    "\n",
    "test=pad_sequences([test],maxlen=200)\n",
    "print(model.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 200, 128)          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1428225 (5.45 MB)\n",
      "Trainable params: 1428225 (5.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "50/50 [==============================] - 49s 957ms/step - loss: 0.6915 - accuracy: 0.5357 - f1_score: 0.6667 - precision_3: 0.5358 - recall_3: 0.5337 - val_loss: 0.6857 - val_accuracy: 0.5906 - val_f1_score: 0.6667 - val_precision_3: 0.5622 - val_recall_3: 0.8184\n",
      "Epoch 2/40\n",
      "50/50 [==============================] - 46s 919ms/step - loss: 0.6611 - accuracy: 0.6464 - f1_score: 0.6667 - precision_3: 0.6554 - recall_3: 0.6177 - val_loss: 0.5731 - val_accuracy: 0.7343 - val_f1_score: 0.6667 - val_precision_3: 0.7336 - val_recall_3: 0.7358\n",
      "Epoch 3/40\n",
      "50/50 [==============================] - 46s 936ms/step - loss: 0.5082 - accuracy: 0.7642 - f1_score: 0.6667 - precision_3: 0.7665 - recall_3: 0.7600 - val_loss: 0.4056 - val_accuracy: 0.8180 - val_f1_score: 0.6667 - val_precision_3: 0.8001 - val_recall_3: 0.8477\n",
      "Epoch 4/40\n",
      "50/50 [==============================] - 46s 924ms/step - loss: 0.4137 - accuracy: 0.8188 - f1_score: 0.6667 - precision_3: 0.8196 - recall_3: 0.8175 - val_loss: 0.3437 - val_accuracy: 0.8542 - val_f1_score: 0.6667 - val_precision_3: 0.8397 - val_recall_3: 0.8755\n",
      "Epoch 5/40\n",
      "50/50 [==============================] - 47s 937ms/step - loss: 0.3690 - accuracy: 0.8430 - f1_score: 0.6667 - precision_3: 0.8436 - recall_3: 0.8422 - val_loss: 0.3348 - val_accuracy: 0.8568 - val_f1_score: 0.6667 - val_precision_3: 0.8436 - val_recall_3: 0.8761\n",
      "Epoch 6/40\n",
      "50/50 [==============================] - 47s 950ms/step - loss: 0.3319 - accuracy: 0.8640 - f1_score: 0.6667 - precision_3: 0.8578 - recall_3: 0.8726 - val_loss: 0.3199 - val_accuracy: 0.8659 - val_f1_score: 0.6667 - val_precision_3: 0.8602 - val_recall_3: 0.8738\n",
      "Epoch 7/40\n",
      "50/50 [==============================] - 47s 955ms/step - loss: 0.2972 - accuracy: 0.8802 - f1_score: 0.6667 - precision_3: 0.8797 - recall_3: 0.8810 - val_loss: 0.3670 - val_accuracy: 0.8406 - val_f1_score: 0.6667 - val_precision_3: 0.8322 - val_recall_3: 0.8532\n",
      "Epoch 8/40\n",
      "50/50 [==============================] - 48s 962ms/step - loss: 0.2750 - accuracy: 0.8918 - f1_score: 0.6667 - precision_3: 0.8961 - recall_3: 0.8864 - val_loss: 0.3927 - val_accuracy: 0.8568 - val_f1_score: 0.6667 - val_precision_3: 0.8085 - val_recall_3: 0.9352\n",
      "Epoch 9/40\n",
      "50/50 [==============================] - 47s 953ms/step - loss: 0.2667 - accuracy: 0.8935 - f1_score: 0.6667 - precision_3: 0.8972 - recall_3: 0.8889 - val_loss: 0.4456 - val_accuracy: 0.8240 - val_f1_score: 0.6667 - val_precision_3: 0.9451 - val_recall_3: 0.6880\n",
      "Epoch 10/40\n",
      "50/50 [==============================] - 48s 966ms/step - loss: 0.2517 - accuracy: 0.9019 - f1_score: 0.6667 - precision_3: 0.9037 - recall_3: 0.8997 - val_loss: 0.3142 - val_accuracy: 0.8705 - val_f1_score: 0.6667 - val_precision_3: 0.8591 - val_recall_3: 0.8864\n",
      "Epoch 11/40\n",
      "50/50 [==============================] - 48s 960ms/step - loss: 0.2327 - accuracy: 0.9095 - f1_score: 0.6667 - precision_3: 0.9094 - recall_3: 0.9097 - val_loss: 0.3341 - val_accuracy: 0.8690 - val_f1_score: 0.6667 - val_precision_3: 0.9020 - val_recall_3: 0.8280\n",
      "Epoch 12/40\n",
      "50/50 [==============================] - 49s 982ms/step - loss: 0.2321 - accuracy: 0.9070 - f1_score: 0.6667 - precision_3: 0.9057 - recall_3: 0.9087 - val_loss: 0.3843 - val_accuracy: 0.8686 - val_f1_score: 0.6667 - val_precision_3: 0.8582 - val_recall_3: 0.8833\n",
      "Epoch 13/40\n",
      "50/50 [==============================] - 49s 995ms/step - loss: 0.2102 - accuracy: 0.9205 - f1_score: 0.6667 - precision_3: 0.9195 - recall_3: 0.9217 - val_loss: 0.3451 - val_accuracy: 0.8704 - val_f1_score: 0.6667 - val_precision_3: 0.8446 - val_recall_3: 0.9077\n",
      "Epoch 14/40\n",
      "50/50 [==============================] - 48s 971ms/step - loss: 0.2048 - accuracy: 0.9226 - f1_score: 0.6667 - precision_3: 0.9206 - recall_3: 0.9249 - val_loss: 0.3904 - val_accuracy: 0.8401 - val_f1_score: 0.6667 - val_precision_3: 0.9261 - val_recall_3: 0.7392\n",
      "Epoch 15/40\n",
      "50/50 [==============================] - 48s 960ms/step - loss: 0.1935 - accuracy: 0.9265 - f1_score: 0.6667 - precision_3: 0.9274 - recall_3: 0.9254 - val_loss: 0.3689 - val_accuracy: 0.8714 - val_f1_score: 0.6667 - val_precision_3: 0.8629 - val_recall_3: 0.8830\n",
      "Epoch 16/40\n",
      "50/50 [==============================] - 48s 960ms/step - loss: 0.1901 - accuracy: 0.9281 - f1_score: 0.6667 - precision_3: 0.9275 - recall_3: 0.9288 - val_loss: 0.3500 - val_accuracy: 0.8587 - val_f1_score: 0.6667 - val_precision_3: 0.8982 - val_recall_3: 0.8092\n",
      "Epoch 17/40\n",
      "50/50 [==============================] - 48s 976ms/step - loss: 0.1697 - accuracy: 0.9357 - f1_score: 0.6667 - precision_3: 0.9381 - recall_3: 0.9330 - val_loss: 0.3454 - val_accuracy: 0.8688 - val_f1_score: 0.6667 - val_precision_3: 0.8518 - val_recall_3: 0.8929\n",
      "Epoch 18/40\n",
      "50/50 [==============================] - 49s 979ms/step - loss: 0.1625 - accuracy: 0.9396 - f1_score: 0.6667 - precision_3: 0.9399 - recall_3: 0.9394 - val_loss: 0.4338 - val_accuracy: 0.8615 - val_f1_score: 0.6667 - val_precision_3: 0.8232 - val_recall_3: 0.9208\n",
      "Epoch 19/40\n",
      "50/50 [==============================] - 48s 971ms/step - loss: 0.1572 - accuracy: 0.9428 - f1_score: 0.6667 - precision_3: 0.9451 - recall_3: 0.9402 - val_loss: 0.3575 - val_accuracy: 0.8680 - val_f1_score: 0.6667 - val_precision_3: 0.8621 - val_recall_3: 0.8760\n",
      "Epoch 20/40\n",
      "50/50 [==============================] - 46s 928ms/step - loss: 0.1468 - accuracy: 0.9452 - f1_score: 0.6667 - precision_3: 0.9453 - recall_3: 0.9450 - val_loss: 0.4556 - val_accuracy: 0.8610 - val_f1_score: 0.6667 - val_precision_3: 0.8260 - val_recall_3: 0.9148\n",
      "Epoch 21/40\n",
      "50/50 [==============================] - 48s 969ms/step - loss: 0.1332 - accuracy: 0.9526 - f1_score: 0.6667 - precision_3: 0.9532 - recall_3: 0.9518 - val_loss: 0.4091 - val_accuracy: 0.8534 - val_f1_score: 0.6667 - val_precision_3: 0.8154 - val_recall_3: 0.9136\n",
      "Epoch 22/40\n",
      "50/50 [==============================] - 50s 1s/step - loss: 0.1324 - accuracy: 0.9514 - f1_score: 0.6667 - precision_3: 0.9539 - recall_3: 0.9486 - val_loss: 0.5674 - val_accuracy: 0.8364 - val_f1_score: 0.6667 - val_precision_3: 0.7730 - val_recall_3: 0.9526\n",
      "Epoch 23/40\n",
      "50/50 [==============================] - 53s 1s/step - loss: 0.1291 - accuracy: 0.9526 - f1_score: 0.6667 - precision_3: 0.9525 - recall_3: 0.9527 - val_loss: 0.4368 - val_accuracy: 0.8226 - val_f1_score: 0.6667 - val_precision_3: 0.7797 - val_recall_3: 0.8991\n",
      "Epoch 24/40\n",
      "50/50 [==============================] - 50s 998ms/step - loss: 0.1196 - accuracy: 0.9572 - f1_score: 0.6667 - precision_3: 0.9562 - recall_3: 0.9582 - val_loss: 0.4096 - val_accuracy: 0.8599 - val_f1_score: 0.6667 - val_precision_3: 0.8516 - val_recall_3: 0.8717\n",
      "Epoch 25/40\n",
      "50/50 [==============================] - 49s 997ms/step - loss: 0.1155 - accuracy: 0.9583 - f1_score: 0.6667 - precision_3: 0.9569 - recall_3: 0.9598 - val_loss: 0.4814 - val_accuracy: 0.8549 - val_f1_score: 0.6667 - val_precision_3: 0.8969 - val_recall_3: 0.8020\n",
      "Epoch 26/40\n",
      "50/50 [==============================] - 48s 967ms/step - loss: 0.1004 - accuracy: 0.9633 - f1_score: 0.6667 - precision_3: 0.9622 - recall_3: 0.9644 - val_loss: 0.5638 - val_accuracy: 0.8451 - val_f1_score: 0.6667 - val_precision_3: 0.9127 - val_recall_3: 0.7632\n",
      "Epoch 27/40\n",
      "50/50 [==============================] - 48s 970ms/step - loss: 0.0957 - accuracy: 0.9643 - f1_score: 0.6667 - precision_3: 0.9656 - recall_3: 0.9630 - val_loss: 0.5713 - val_accuracy: 0.8586 - val_f1_score: 0.6667 - val_precision_3: 0.8284 - val_recall_3: 0.9045\n",
      "Epoch 28/40\n",
      "50/50 [==============================] - 47s 950ms/step - loss: 0.0919 - accuracy: 0.9679 - f1_score: 0.6667 - precision_3: 0.9675 - recall_3: 0.9683 - val_loss: 0.5495 - val_accuracy: 0.8334 - val_f1_score: 0.6667 - val_precision_3: 0.9012 - val_recall_3: 0.7490\n",
      "Epoch 29/40\n",
      "50/50 [==============================] - 49s 978ms/step - loss: 0.0890 - accuracy: 0.9678 - f1_score: 0.6667 - precision_3: 0.9683 - recall_3: 0.9672 - val_loss: 0.5268 - val_accuracy: 0.8608 - val_f1_score: 0.6667 - val_precision_3: 0.8568 - val_recall_3: 0.8666\n",
      "Epoch 30/40\n",
      "50/50 [==============================] - 49s 989ms/step - loss: 0.0766 - accuracy: 0.9734 - f1_score: 0.6667 - precision_3: 0.9747 - recall_3: 0.9722 - val_loss: 0.5851 - val_accuracy: 0.8147 - val_f1_score: 0.6667 - val_precision_3: 0.7606 - val_recall_3: 0.9185\n",
      "Epoch 31/40\n",
      "50/50 [==============================] - 49s 987ms/step - loss: 0.0733 - accuracy: 0.9740 - f1_score: 0.6667 - precision_3: 0.9724 - recall_3: 0.9758 - val_loss: 0.5411 - val_accuracy: 0.8577 - val_f1_score: 0.6667 - val_precision_3: 0.8672 - val_recall_3: 0.8448\n",
      "Epoch 32/40\n",
      "50/50 [==============================] - 48s 977ms/step - loss: 0.0709 - accuracy: 0.9750 - f1_score: 0.6667 - precision_3: 0.9760 - recall_3: 0.9740 - val_loss: 0.5896 - val_accuracy: 0.8576 - val_f1_score: 0.6667 - val_precision_3: 0.8655 - val_recall_3: 0.8467\n",
      "Epoch 33/40\n",
      "50/50 [==============================] - 48s 963ms/step - loss: 0.0661 - accuracy: 0.9768 - f1_score: 0.6668 - precision_3: 0.9756 - recall_3: 0.9780 - val_loss: 0.5814 - val_accuracy: 0.8549 - val_f1_score: 0.6667 - val_precision_3: 0.8701 - val_recall_3: 0.8343\n",
      "Epoch 34/40\n",
      "50/50 [==============================] - 47s 949ms/step - loss: 0.0590 - accuracy: 0.9789 - f1_score: 0.6668 - precision_3: 0.9806 - recall_3: 0.9770 - val_loss: 0.6218 - val_accuracy: 0.8552 - val_f1_score: 0.6667 - val_precision_3: 0.8391 - val_recall_3: 0.8789\n",
      "Epoch 35/40\n",
      "50/50 [==============================] - 48s 966ms/step - loss: 0.0542 - accuracy: 0.9803 - f1_score: 0.6669 - precision_3: 0.9803 - recall_3: 0.9803 - val_loss: 0.6765 - val_accuracy: 0.8560 - val_f1_score: 0.6667 - val_precision_3: 0.8631 - val_recall_3: 0.8462\n",
      "Epoch 36/40\n",
      "50/50 [==============================] - 49s 990ms/step - loss: 0.0603 - accuracy: 0.9786 - f1_score: 0.6668 - precision_3: 0.9786 - recall_3: 0.9785 - val_loss: 0.6732 - val_accuracy: 0.8508 - val_f1_score: 0.6667 - val_precision_3: 0.8822 - val_recall_3: 0.8097\n",
      "Epoch 37/40\n",
      "50/50 [==============================] - 48s 962ms/step - loss: 0.0554 - accuracy: 0.9809 - f1_score: 0.6668 - precision_3: 0.9799 - recall_3: 0.9820 - val_loss: 0.7310 - val_accuracy: 0.8013 - val_f1_score: 0.6667 - val_precision_3: 0.8705 - val_recall_3: 0.7080\n",
      "Epoch 38/40\n",
      "50/50 [==============================] - 48s 973ms/step - loss: 0.0451 - accuracy: 0.9838 - f1_score: 0.6670 - precision_3: 0.9855 - recall_3: 0.9822 - val_loss: 0.7884 - val_accuracy: 0.8485 - val_f1_score: 0.6667 - val_precision_3: 0.8910 - val_recall_3: 0.7942\n",
      "Epoch 39/40\n",
      "50/50 [==============================] - 48s 976ms/step - loss: 0.0414 - accuracy: 0.9854 - f1_score: 0.6672 - precision_3: 0.9865 - recall_3: 0.9842 - val_loss: 0.6614 - val_accuracy: 0.8490 - val_f1_score: 0.6667 - val_precision_3: 0.8222 - val_recall_3: 0.8906\n",
      "Epoch 40/40\n",
      "50/50 [==============================] - 49s 985ms/step - loss: 0.0401 - accuracy: 0.9868 - f1_score: 0.6673 - precision_3: 0.9864 - recall_3: 0.9873 - val_loss: 0.8286 - val_accuracy: 0.8454 - val_f1_score: 0.6667 - val_precision_3: 0.8014 - val_recall_3: 0.9184\n",
      "50/50 [==============================] - 16s 311ms/step - loss: 0.8286 - accuracy: 0.8454 - f1_score: 0.6667 - precision_3: 0.8014 - recall_3: 0.9184\n",
      "\n",
      "Test score: 0.8286404013633728\n",
      "Test accuracy: 0.8453999757766724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 35s 44ms/step\n",
      "результат: 0\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[[0.00269105]]\n"
     ]
    }
   ],
   "source": [
    "model = build_model1()\n",
    "model.summary()\n",
    "model.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\", keras.metrics.F1Score(), keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "score = model.fit(X_train, y_train,\n",
    " epochs = EPOCHS,\n",
    " batch_size = BATCH_SIZE,\n",
    " validation_data = (X_test, y_test)\n",
    ")\n",
    "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save(\"imdb1.h5\")\n",
    "\n",
    "val = model.predict(X_train)\n",
    "print(f'результат: {np.argmax(val[0])}')\n",
    "word2index = imdb.get_word_index()\n",
    "test=[]\n",
    "for word in word_tokenize( \"i love this movie\"):\n",
    "     test.append(word2index[word])\n",
    "\n",
    "test=pad_sequences([test],maxlen=200)\n",
    "print(model.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 200, 128)          0         \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirecti  (None, 256)               263168    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1576193 (6.01 MB)\n",
      "Trainable params: 1576193 (6.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "50/50 [==============================] - 60s 1s/step - loss: 0.6914 - accuracy: 0.5247 - f1_score: 0.6667 - precision_4: 0.5208 - recall_4: 0.6172 - val_loss: 0.6857 - val_accuracy: 0.5662 - val_f1_score: 0.6667 - val_precision_4: 0.7285 - val_recall_4: 0.2112\n",
      "Epoch 2/40\n",
      "50/50 [==============================] - 58s 1s/step - loss: 0.6231 - accuracy: 0.6640 - f1_score: 0.6667 - precision_4: 0.6712 - recall_4: 0.6432 - val_loss: 0.4990 - val_accuracy: 0.7746 - val_f1_score: 0.6667 - val_precision_4: 0.7725 - val_recall_4: 0.7786\n",
      "Epoch 3/40\n",
      "50/50 [==============================] - 58s 1s/step - loss: 0.4780 - accuracy: 0.7774 - f1_score: 0.6667 - precision_4: 0.7751 - recall_4: 0.7818 - val_loss: 0.3758 - val_accuracy: 0.8363 - val_f1_score: 0.6667 - val_precision_4: 0.8325 - val_recall_4: 0.8421\n",
      "Epoch 4/40\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.3971 - accuracy: 0.8275 - f1_score: 0.6667 - precision_4: 0.8296 - recall_4: 0.8243 - val_loss: 0.3500 - val_accuracy: 0.8572 - val_f1_score: 0.6667 - val_precision_4: 0.8321 - val_recall_4: 0.8949\n",
      "Epoch 5/40\n",
      "50/50 [==============================] - 54s 1s/step - loss: 0.3565 - accuracy: 0.8498 - f1_score: 0.6667 - precision_4: 0.8503 - recall_4: 0.8492 - val_loss: 0.3893 - val_accuracy: 0.8308 - val_f1_score: 0.6667 - val_precision_4: 0.8600 - val_recall_4: 0.7902\n",
      "Epoch 6/40\n",
      "50/50 [==============================] - 54s 1s/step - loss: 0.3168 - accuracy: 0.8695 - f1_score: 0.6667 - precision_4: 0.8711 - recall_4: 0.8674 - val_loss: 0.3858 - val_accuracy: 0.8523 - val_f1_score: 0.6667 - val_precision_4: 0.9163 - val_recall_4: 0.7754\n",
      "Epoch 7/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.2923 - accuracy: 0.8835 - f1_score: 0.6667 - precision_4: 0.8801 - recall_4: 0.8879 - val_loss: 0.4099 - val_accuracy: 0.8275 - val_f1_score: 0.6667 - val_precision_4: 0.9453 - val_recall_4: 0.6952\n",
      "Epoch 8/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.2761 - accuracy: 0.8920 - f1_score: 0.6667 - precision_4: 0.8964 - recall_4: 0.8865 - val_loss: 0.3419 - val_accuracy: 0.8592 - val_f1_score: 0.6667 - val_precision_4: 0.8144 - val_recall_4: 0.9305\n",
      "Epoch 9/40\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.2600 - accuracy: 0.8987 - f1_score: 0.6667 - precision_4: 0.9023 - recall_4: 0.8943 - val_loss: 0.3097 - val_accuracy: 0.8702 - val_f1_score: 0.6667 - val_precision_4: 0.8739 - val_recall_4: 0.8652\n",
      "Epoch 10/40\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.2474 - accuracy: 0.9020 - f1_score: 0.6667 - precision_4: 0.9023 - recall_4: 0.9017 - val_loss: 0.3122 - val_accuracy: 0.8723 - val_f1_score: 0.6667 - val_precision_4: 0.8879 - val_recall_4: 0.8522\n",
      "Epoch 11/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.2185 - accuracy: 0.9152 - f1_score: 0.6667 - precision_4: 0.9149 - recall_4: 0.9156 - val_loss: 0.3892 - val_accuracy: 0.8339 - val_f1_score: 0.6667 - val_precision_4: 0.9233 - val_recall_4: 0.7283\n",
      "Epoch 12/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.2160 - accuracy: 0.9168 - f1_score: 0.6667 - precision_4: 0.9177 - recall_4: 0.9156 - val_loss: 0.3427 - val_accuracy: 0.8702 - val_f1_score: 0.6667 - val_precision_4: 0.9018 - val_recall_4: 0.8310\n",
      "Epoch 13/40\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.2112 - accuracy: 0.9212 - f1_score: 0.6667 - precision_4: 0.9245 - recall_4: 0.9173 - val_loss: 0.3481 - val_accuracy: 0.8718 - val_f1_score: 0.6667 - val_precision_4: 0.8799 - val_recall_4: 0.8613\n",
      "Epoch 14/40\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.1980 - accuracy: 0.9245 - f1_score: 0.6667 - precision_4: 0.9266 - recall_4: 0.9220 - val_loss: 0.3880 - val_accuracy: 0.8484 - val_f1_score: 0.6667 - val_precision_4: 0.7972 - val_recall_4: 0.9346\n",
      "Epoch 15/40\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.1828 - accuracy: 0.9315 - f1_score: 0.6667 - precision_4: 0.9310 - recall_4: 0.9321 - val_loss: 0.4390 - val_accuracy: 0.8434 - val_f1_score: 0.6667 - val_precision_4: 0.9322 - val_recall_4: 0.7408\n",
      "Epoch 16/40\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.1808 - accuracy: 0.9325 - f1_score: 0.6667 - precision_4: 0.9330 - recall_4: 0.9318 - val_loss: 0.3604 - val_accuracy: 0.8712 - val_f1_score: 0.6667 - val_precision_4: 0.8665 - val_recall_4: 0.8777\n",
      "Epoch 17/40\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.1790 - accuracy: 0.9328 - f1_score: 0.6667 - precision_4: 0.9316 - recall_4: 0.9342 - val_loss: 0.3633 - val_accuracy: 0.8470 - val_f1_score: 0.6667 - val_precision_4: 0.8823 - val_recall_4: 0.8010\n",
      "Epoch 18/40\n",
      "50/50 [==============================] - 54s 1s/step - loss: 0.1609 - accuracy: 0.9417 - f1_score: 0.6667 - precision_4: 0.9437 - recall_4: 0.9394 - val_loss: 0.3912 - val_accuracy: 0.8692 - val_f1_score: 0.6667 - val_precision_4: 0.8785 - val_recall_4: 0.8568\n",
      "Epoch 19/40\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.1506 - accuracy: 0.9435 - f1_score: 0.6667 - precision_4: 0.9435 - recall_4: 0.9435 - val_loss: 0.3542 - val_accuracy: 0.8668 - val_f1_score: 0.6667 - val_precision_4: 0.8718 - val_recall_4: 0.8601\n",
      "Epoch 20/40\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.1389 - accuracy: 0.9484 - f1_score: 0.6667 - precision_4: 0.9486 - recall_4: 0.9482 - val_loss: 0.3791 - val_accuracy: 0.8500 - val_f1_score: 0.6667 - val_precision_4: 0.8436 - val_recall_4: 0.8592\n",
      "Epoch 21/40\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.1394 - accuracy: 0.9482 - f1_score: 0.6667 - precision_4: 0.9503 - recall_4: 0.9460 - val_loss: 0.4108 - val_accuracy: 0.8402 - val_f1_score: 0.6667 - val_precision_4: 0.7997 - val_recall_4: 0.9077\n",
      "Epoch 22/40\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.1269 - accuracy: 0.9544 - f1_score: 0.6667 - precision_4: 0.9535 - recall_4: 0.9554 - val_loss: 0.5254 - val_accuracy: 0.8162 - val_f1_score: 0.6667 - val_precision_4: 0.9273 - val_recall_4: 0.6862\n",
      "Epoch 23/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.1156 - accuracy: 0.9579 - f1_score: 0.6667 - precision_4: 0.9582 - recall_4: 0.9575 - val_loss: 0.5064 - val_accuracy: 0.8565 - val_f1_score: 0.6667 - val_precision_4: 0.8173 - val_recall_4: 0.9184\n",
      "Epoch 24/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.1116 - accuracy: 0.9583 - f1_score: 0.6667 - precision_4: 0.9599 - recall_4: 0.9566 - val_loss: 0.4389 - val_accuracy: 0.8630 - val_f1_score: 0.6667 - val_precision_4: 0.8491 - val_recall_4: 0.8830\n",
      "Epoch 25/40\n",
      "50/50 [==============================] - 53s 1s/step - loss: 0.0997 - accuracy: 0.9637 - f1_score: 0.6667 - precision_4: 0.9651 - recall_4: 0.9622 - val_loss: 0.5365 - val_accuracy: 0.8373 - val_f1_score: 0.6667 - val_precision_4: 0.9198 - val_recall_4: 0.7390\n",
      "Epoch 26/40\n",
      "50/50 [==============================] - 58s 1s/step - loss: 0.0935 - accuracy: 0.9658 - f1_score: 0.6667 - precision_4: 0.9675 - recall_4: 0.9640 - val_loss: 0.4895 - val_accuracy: 0.8600 - val_f1_score: 0.6667 - val_precision_4: 0.8454 - val_recall_4: 0.8812\n",
      "Epoch 27/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.0912 - accuracy: 0.9682 - f1_score: 0.6667 - precision_4: 0.9681 - recall_4: 0.9682 - val_loss: 0.5207 - val_accuracy: 0.8524 - val_f1_score: 0.6667 - val_precision_4: 0.8940 - val_recall_4: 0.7995\n",
      "Epoch 28/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.0828 - accuracy: 0.9696 - f1_score: 0.6667 - precision_4: 0.9713 - recall_4: 0.9679 - val_loss: 0.5531 - val_accuracy: 0.8616 - val_f1_score: 0.6667 - val_precision_4: 0.8700 - val_recall_4: 0.8503\n",
      "Epoch 29/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.0768 - accuracy: 0.9726 - f1_score: 0.6667 - precision_4: 0.9729 - recall_4: 0.9723 - val_loss: 0.6446 - val_accuracy: 0.8511 - val_f1_score: 0.6667 - val_precision_4: 0.8096 - val_recall_4: 0.9182\n",
      "Epoch 30/40\n",
      "50/50 [==============================] - 54s 1s/step - loss: 0.0675 - accuracy: 0.9762 - f1_score: 0.6667 - precision_4: 0.9756 - recall_4: 0.9769 - val_loss: 0.5770 - val_accuracy: 0.8525 - val_f1_score: 0.6667 - val_precision_4: 0.8900 - val_recall_4: 0.8043\n",
      "Epoch 31/40\n",
      "50/50 [==============================] - 59s 1s/step - loss: 0.0638 - accuracy: 0.9777 - f1_score: 0.6667 - precision_4: 0.9797 - recall_4: 0.9756 - val_loss: 0.5879 - val_accuracy: 0.8544 - val_f1_score: 0.6667 - val_precision_4: 0.8755 - val_recall_4: 0.8262\n",
      "Epoch 32/40\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.0684 - accuracy: 0.9760 - f1_score: 0.6667 - precision_4: 0.9749 - recall_4: 0.9772 - val_loss: 0.5680 - val_accuracy: 0.8548 - val_f1_score: 0.6667 - val_precision_4: 0.8625 - val_recall_4: 0.8441\n",
      "Epoch 33/40\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.0541 - accuracy: 0.9818 - f1_score: 0.6667 - precision_4: 0.9817 - recall_4: 0.9819 - val_loss: 0.6508 - val_accuracy: 0.8588 - val_f1_score: 0.6667 - val_precision_4: 0.8608 - val_recall_4: 0.8561\n",
      "Epoch 34/40\n",
      "50/50 [==============================] - 65s 1s/step - loss: 0.0486 - accuracy: 0.9836 - f1_score: 0.6667 - precision_4: 0.9842 - recall_4: 0.9830 - val_loss: 0.7311 - val_accuracy: 0.8481 - val_f1_score: 0.6667 - val_precision_4: 0.8095 - val_recall_4: 0.9105\n",
      "Epoch 35/40\n",
      "50/50 [==============================] - 65s 1s/step - loss: 0.0569 - accuracy: 0.9806 - f1_score: 0.6668 - precision_4: 0.9810 - recall_4: 0.9801 - val_loss: 0.6282 - val_accuracy: 0.8390 - val_f1_score: 0.6667 - val_precision_4: 0.8854 - val_recall_4: 0.7789\n",
      "Epoch 36/40\n",
      "50/50 [==============================] - 65s 1s/step - loss: 0.0435 - accuracy: 0.9847 - f1_score: 0.6667 - precision_4: 0.9846 - recall_4: 0.9849 - val_loss: 0.6487 - val_accuracy: 0.8514 - val_f1_score: 0.6667 - val_precision_4: 0.8750 - val_recall_4: 0.8201\n",
      "Epoch 37/40\n",
      "50/50 [==============================] - 58s 1s/step - loss: 0.0417 - accuracy: 0.9862 - f1_score: 0.6668 - precision_4: 0.9867 - recall_4: 0.9858 - val_loss: 0.6863 - val_accuracy: 0.8559 - val_f1_score: 0.6667 - val_precision_4: 0.8637 - val_recall_4: 0.8451\n",
      "Epoch 38/40\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.0420 - accuracy: 0.9859 - f1_score: 0.6671 - precision_4: 0.9863 - recall_4: 0.9854 - val_loss: 0.6915 - val_accuracy: 0.8554 - val_f1_score: 0.6667 - val_precision_4: 0.8583 - val_recall_4: 0.8514\n",
      "Epoch 39/40\n",
      "50/50 [==============================] - 59s 1s/step - loss: 0.0391 - accuracy: 0.9861 - f1_score: 0.6673 - precision_4: 0.9865 - recall_4: 0.9857 - val_loss: 0.7324 - val_accuracy: 0.8422 - val_f1_score: 0.6667 - val_precision_4: 0.8807 - val_recall_4: 0.7918\n",
      "Epoch 40/40\n",
      "50/50 [==============================] - 53s 1s/step - loss: 0.0396 - accuracy: 0.9867 - f1_score: 0.6672 - precision_4: 0.9865 - recall_4: 0.9870 - val_loss: 0.7086 - val_accuracy: 0.8536 - val_f1_score: 0.6667 - val_precision_4: 0.8572 - val_recall_4: 0.8486\n",
      "50/50 [==============================] - 16s 314ms/step - loss: 0.7086 - accuracy: 0.8536 - f1_score: 0.6667 - precision_4: 0.8572 - recall_4: 0.8486\n",
      "\n",
      "Test score: 0.7086004614830017\n",
      "Test accuracy: 0.8536400198936462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 47s 59ms/step\n",
      "результат: 0\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "[[0.01985721]]\n"
     ]
    }
   ],
   "source": [
    "model = build_model2()\n",
    "model.summary()\n",
    "model.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\", keras.metrics.F1Score(), keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "score = model.fit(X_train, y_train,\n",
    " epochs = EPOCHS,\n",
    " batch_size = BATCH_SIZE,\n",
    " validation_data = (X_test, y_test)\n",
    ")\n",
    "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save(\"imdb2.h5\")\n",
    "\n",
    "val = model.predict(X_train)\n",
    "print(f'результат: {np.argmax(val[0])}')\n",
    "word2index = imdb.get_word_index()\n",
    "test=[]\n",
    "for word in word_tokenize( \"i love this movie\"):\n",
    "     test.append(word2index[word])\n",
    "\n",
    "test=pad_sequences([test],maxlen=200)\n",
    "print(model.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 200, 128)          0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 200, 128)          131584    \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 128)               0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1428225 (5.45 MB)\n",
      "Trainable params: 1428225 (5.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "50/50 [==============================] - 48s 945ms/step - loss: 0.6928 - accuracy: 0.5122 - f1_score: 0.6667 - precision_5: 0.5126 - recall_5: 0.4962 - val_loss: 0.6917 - val_accuracy: 0.5404 - val_f1_score: 0.6667 - val_precision_5: 0.5219 - val_recall_5: 0.9626\n",
      "Epoch 2/40\n",
      "50/50 [==============================] - 49s 994ms/step - loss: 0.6897 - accuracy: 0.5688 - f1_score: 0.6667 - precision_5: 0.5711 - recall_5: 0.5524 - val_loss: 0.6671 - val_accuracy: 0.6249 - val_f1_score: 0.6667 - val_precision_5: 0.5779 - val_recall_5: 0.9265\n",
      "Epoch 3/40\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.6049 - accuracy: 0.6970 - f1_score: 0.6667 - precision_5: 0.6910 - recall_5: 0.7127 - val_loss: 0.5275 - val_accuracy: 0.7822 - val_f1_score: 0.6667 - val_precision_5: 0.7643 - val_recall_5: 0.8160\n",
      "Epoch 4/40\n",
      "50/50 [==============================] - 50s 1s/step - loss: 0.4728 - accuracy: 0.7860 - f1_score: 0.6667 - precision_5: 0.7799 - recall_5: 0.7968 - val_loss: 0.4916 - val_accuracy: 0.7516 - val_f1_score: 0.6667 - val_precision_5: 0.6757 - val_recall_5: 0.9675\n",
      "Epoch 5/40\n",
      "50/50 [==============================] - 48s 963ms/step - loss: 0.3940 - accuracy: 0.8295 - f1_score: 0.6667 - precision_5: 0.8276 - recall_5: 0.8324 - val_loss: 0.4060 - val_accuracy: 0.8122 - val_f1_score: 0.6667 - val_precision_5: 0.7449 - val_recall_5: 0.9498\n",
      "Epoch 6/40\n",
      "50/50 [==============================] - 50s 1s/step - loss: 0.3498 - accuracy: 0.8531 - f1_score: 0.6667 - precision_5: 0.8485 - recall_5: 0.8596 - val_loss: 0.3206 - val_accuracy: 0.8611 - val_f1_score: 0.6667 - val_precision_5: 0.8518 - val_recall_5: 0.8742\n",
      "Epoch 7/40\n",
      "50/50 [==============================] - 50s 1s/step - loss: 0.3135 - accuracy: 0.8700 - f1_score: 0.6667 - precision_5: 0.8690 - recall_5: 0.8713 - val_loss: 0.3318 - val_accuracy: 0.8609 - val_f1_score: 0.6667 - val_precision_5: 0.8302 - val_recall_5: 0.9075\n",
      "Epoch 8/40\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.2843 - accuracy: 0.8852 - f1_score: 0.6667 - precision_5: 0.8859 - recall_5: 0.8842 - val_loss: 0.4382 - val_accuracy: 0.8142 - val_f1_score: 0.6667 - val_precision_5: 0.9494 - val_recall_5: 0.6638\n",
      "Epoch 9/40\n",
      "50/50 [==============================] - 49s 978ms/step - loss: 0.2788 - accuracy: 0.8900 - f1_score: 0.6667 - precision_5: 0.8901 - recall_5: 0.8898 - val_loss: 0.3428 - val_accuracy: 0.8513 - val_f1_score: 0.6667 - val_precision_5: 0.7989 - val_recall_5: 0.9390\n",
      "Epoch 10/40\n",
      "50/50 [==============================] - 49s 981ms/step - loss: 0.2536 - accuracy: 0.8995 - f1_score: 0.6667 - precision_5: 0.8975 - recall_5: 0.9020 - val_loss: 0.3116 - val_accuracy: 0.8671 - val_f1_score: 0.6667 - val_precision_5: 0.8947 - val_recall_5: 0.8322\n",
      "Epoch 11/40\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.2314 - accuracy: 0.9103 - f1_score: 0.6667 - precision_5: 0.9095 - recall_5: 0.9113 - val_loss: 0.3156 - val_accuracy: 0.8698 - val_f1_score: 0.6667 - val_precision_5: 0.8668 - val_recall_5: 0.8738\n",
      "Epoch 12/40\n",
      "50/50 [==============================] - 49s 979ms/step - loss: 0.2219 - accuracy: 0.9130 - f1_score: 0.6667 - precision_5: 0.9142 - recall_5: 0.9114 - val_loss: 0.3824 - val_accuracy: 0.8346 - val_f1_score: 0.6667 - val_precision_5: 0.7671 - val_recall_5: 0.9610\n",
      "Epoch 13/40\n",
      "50/50 [==============================] - 48s 971ms/step - loss: 0.2113 - accuracy: 0.9198 - f1_score: 0.6667 - precision_5: 0.9177 - recall_5: 0.9223 - val_loss: 0.3699 - val_accuracy: 0.8566 - val_f1_score: 0.6667 - val_precision_5: 0.9247 - val_recall_5: 0.7763\n",
      "Epoch 14/40\n",
      "50/50 [==============================] - 48s 961ms/step - loss: 0.1973 - accuracy: 0.9263 - f1_score: 0.6667 - precision_5: 0.9274 - recall_5: 0.9250 - val_loss: 0.3295 - val_accuracy: 0.8706 - val_f1_score: 0.6667 - val_precision_5: 0.8499 - val_recall_5: 0.9002\n",
      "Epoch 15/40\n",
      "50/50 [==============================] - 49s 984ms/step - loss: 0.1855 - accuracy: 0.9320 - f1_score: 0.6667 - precision_5: 0.9315 - recall_5: 0.9326 - val_loss: 0.3419 - val_accuracy: 0.8706 - val_f1_score: 0.6667 - val_precision_5: 0.8479 - val_recall_5: 0.9033\n",
      "Epoch 16/40\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.1768 - accuracy: 0.9340 - f1_score: 0.6667 - precision_5: 0.9330 - recall_5: 0.9350 - val_loss: 0.3491 - val_accuracy: 0.8590 - val_f1_score: 0.6667 - val_precision_5: 0.9159 - val_recall_5: 0.7906\n",
      "Epoch 17/40\n",
      "50/50 [==============================] - 49s 978ms/step - loss: 0.1632 - accuracy: 0.9411 - f1_score: 0.6667 - precision_5: 0.9415 - recall_5: 0.9406 - val_loss: 0.3459 - val_accuracy: 0.8724 - val_f1_score: 0.6667 - val_precision_5: 0.8737 - val_recall_5: 0.8706\n",
      "Epoch 18/40\n",
      "50/50 [==============================] - 49s 986ms/step - loss: 0.1547 - accuracy: 0.9419 - f1_score: 0.6667 - precision_5: 0.9416 - recall_5: 0.9422 - val_loss: 0.3819 - val_accuracy: 0.8542 - val_f1_score: 0.6667 - val_precision_5: 0.9179 - val_recall_5: 0.7780\n",
      "Epoch 19/40\n",
      "50/50 [==============================] - 48s 971ms/step - loss: 0.1429 - accuracy: 0.9501 - f1_score: 0.6667 - precision_5: 0.9507 - recall_5: 0.9494 - val_loss: 0.3495 - val_accuracy: 0.8694 - val_f1_score: 0.6667 - val_precision_5: 0.8902 - val_recall_5: 0.8427\n",
      "Epoch 20/40\n",
      "50/50 [==============================] - 52s 1s/step - loss: 0.1361 - accuracy: 0.9514 - f1_score: 0.6667 - precision_5: 0.9516 - recall_5: 0.9513 - val_loss: 0.4474 - val_accuracy: 0.8382 - val_f1_score: 0.6667 - val_precision_5: 0.9325 - val_recall_5: 0.7292\n",
      "Epoch 21/40\n",
      "50/50 [==============================] - 50s 1s/step - loss: 0.1286 - accuracy: 0.9547 - f1_score: 0.6667 - precision_5: 0.9551 - recall_5: 0.9543 - val_loss: 0.3734 - val_accuracy: 0.8697 - val_f1_score: 0.6667 - val_precision_5: 0.8789 - val_recall_5: 0.8575\n",
      "Epoch 22/40\n",
      "50/50 [==============================] - 49s 987ms/step - loss: 0.1301 - accuracy: 0.9556 - f1_score: 0.6667 - precision_5: 0.9538 - recall_5: 0.9577 - val_loss: 0.3564 - val_accuracy: 0.8687 - val_f1_score: 0.6667 - val_precision_5: 0.8701 - val_recall_5: 0.8669\n",
      "Epoch 23/40\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.1062 - accuracy: 0.9647 - f1_score: 0.6667 - precision_5: 0.9641 - recall_5: 0.9653 - val_loss: 0.3788 - val_accuracy: 0.8660 - val_f1_score: 0.6667 - val_precision_5: 0.8910 - val_recall_5: 0.8340\n",
      "Epoch 24/40\n",
      "50/50 [==============================] - 49s 992ms/step - loss: 0.0999 - accuracy: 0.9663 - f1_score: 0.6667 - precision_5: 0.9665 - recall_5: 0.9661 - val_loss: 0.4001 - val_accuracy: 0.8688 - val_f1_score: 0.6667 - val_precision_5: 0.8515 - val_recall_5: 0.8934\n",
      "Epoch 25/40\n",
      "50/50 [==============================] - 50s 1s/step - loss: 0.0960 - accuracy: 0.9678 - f1_score: 0.6667 - precision_5: 0.9681 - recall_5: 0.9674 - val_loss: 0.3908 - val_accuracy: 0.8684 - val_f1_score: 0.6667 - val_precision_5: 0.8579 - val_recall_5: 0.8832\n",
      "Epoch 26/40\n",
      "50/50 [==============================] - 54s 1s/step - loss: 0.0869 - accuracy: 0.9697 - f1_score: 0.6667 - precision_5: 0.9699 - recall_5: 0.9695 - val_loss: 0.4556 - val_accuracy: 0.8600 - val_f1_score: 0.6667 - val_precision_5: 0.8982 - val_recall_5: 0.8121\n",
      "Epoch 27/40\n",
      "50/50 [==============================] - 49s 984ms/step - loss: 0.0774 - accuracy: 0.9739 - f1_score: 0.6667 - precision_5: 0.9738 - recall_5: 0.9741 - val_loss: 0.4614 - val_accuracy: 0.8666 - val_f1_score: 0.6667 - val_precision_5: 0.8716 - val_recall_5: 0.8598\n",
      "Epoch 28/40\n",
      "50/50 [==============================] - 53s 1s/step - loss: 0.0819 - accuracy: 0.9718 - f1_score: 0.6667 - precision_5: 0.9718 - recall_5: 0.9718 - val_loss: 0.4269 - val_accuracy: 0.8596 - val_f1_score: 0.6667 - val_precision_5: 0.8907 - val_recall_5: 0.8198\n",
      "Epoch 29/40\n",
      "50/50 [==============================] - 49s 976ms/step - loss: 0.0670 - accuracy: 0.9778 - f1_score: 0.6667 - precision_5: 0.9767 - recall_5: 0.9790 - val_loss: 0.4887 - val_accuracy: 0.8570 - val_f1_score: 0.6667 - val_precision_5: 0.8959 - val_recall_5: 0.8079\n",
      "Epoch 30/40\n",
      "50/50 [==============================] - 48s 969ms/step - loss: 0.0745 - accuracy: 0.9752 - f1_score: 0.6667 - precision_5: 0.9750 - recall_5: 0.9754 - val_loss: 0.4370 - val_accuracy: 0.8616 - val_f1_score: 0.6667 - val_precision_5: 0.8769 - val_recall_5: 0.8414\n",
      "Epoch 31/40\n",
      "50/50 [==============================] - 49s 983ms/step - loss: 0.0619 - accuracy: 0.9805 - f1_score: 0.6667 - precision_5: 0.9800 - recall_5: 0.9810 - val_loss: 0.4832 - val_accuracy: 0.8620 - val_f1_score: 0.6667 - val_precision_5: 0.8807 - val_recall_5: 0.8374\n",
      "Epoch 32/40\n",
      "50/50 [==============================] - 49s 986ms/step - loss: 0.0567 - accuracy: 0.9807 - f1_score: 0.6667 - precision_5: 0.9800 - recall_5: 0.9814 - val_loss: 0.4756 - val_accuracy: 0.8658 - val_f1_score: 0.6667 - val_precision_5: 0.8701 - val_recall_5: 0.8598\n",
      "Epoch 33/40\n",
      "50/50 [==============================] - 48s 961ms/step - loss: 0.0520 - accuracy: 0.9831 - f1_score: 0.6667 - precision_5: 0.9844 - recall_5: 0.9818 - val_loss: 0.5332 - val_accuracy: 0.8592 - val_f1_score: 0.6667 - val_precision_5: 0.8898 - val_recall_5: 0.8199\n",
      "Epoch 34/40\n",
      "50/50 [==============================] - 52s 1s/step - loss: 0.0464 - accuracy: 0.9852 - f1_score: 0.6667 - precision_5: 0.9860 - recall_5: 0.9845 - val_loss: 0.5531 - val_accuracy: 0.8636 - val_f1_score: 0.6667 - val_precision_5: 0.8709 - val_recall_5: 0.8538\n",
      "Epoch 35/40\n",
      "50/50 [==============================] - 47s 941ms/step - loss: 0.0455 - accuracy: 0.9848 - f1_score: 0.6667 - precision_5: 0.9844 - recall_5: 0.9853 - val_loss: 0.5835 - val_accuracy: 0.8557 - val_f1_score: 0.6667 - val_precision_5: 0.8906 - val_recall_5: 0.8110\n",
      "Epoch 36/40\n",
      "50/50 [==============================] - 49s 988ms/step - loss: 0.0514 - accuracy: 0.9831 - f1_score: 0.6668 - precision_5: 0.9823 - recall_5: 0.9839 - val_loss: 0.5116 - val_accuracy: 0.8606 - val_f1_score: 0.6667 - val_precision_5: 0.8592 - val_recall_5: 0.8624\n",
      "Epoch 37/40\n",
      "50/50 [==============================] - 52s 1s/step - loss: 0.0301 - accuracy: 0.9907 - f1_score: 0.6668 - precision_5: 0.9902 - recall_5: 0.9911 - val_loss: 0.6530 - val_accuracy: 0.8520 - val_f1_score: 0.6667 - val_precision_5: 0.8983 - val_recall_5: 0.7938\n",
      "Epoch 38/40\n",
      "50/50 [==============================] - 53s 1s/step - loss: 0.0426 - accuracy: 0.9858 - f1_score: 0.6670 - precision_5: 0.9863 - recall_5: 0.9852 - val_loss: 0.6143 - val_accuracy: 0.8625 - val_f1_score: 0.6667 - val_precision_5: 0.8473 - val_recall_5: 0.8844\n",
      "Epoch 39/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.0404 - accuracy: 0.9872 - f1_score: 0.6672 - precision_5: 0.9884 - recall_5: 0.9861 - val_loss: 0.5801 - val_accuracy: 0.8640 - val_f1_score: 0.6667 - val_precision_5: 0.8593 - val_recall_5: 0.8705\n",
      "Epoch 40/40\n",
      "50/50 [==============================] - 53s 1s/step - loss: 0.0357 - accuracy: 0.9890 - f1_score: 0.6673 - precision_5: 0.9895 - recall_5: 0.9885 - val_loss: 0.5541 - val_accuracy: 0.8602 - val_f1_score: 0.6667 - val_precision_5: 0.8635 - val_recall_5: 0.8556\n",
      "50/50 [==============================] - 18s 360ms/step - loss: 0.5541 - accuracy: 0.8602 - f1_score: 0.6667 - precision_5: 0.8635 - recall_5: 0.8556\n",
      "\n",
      "Test score: 0.554085373878479\n",
      "Test accuracy: 0.8601999878883362\n",
      "782/782 [==============================] - 52s 66ms/step\n",
      "результат: 0\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "[[0.46780217]]\n"
     ]
    }
   ],
   "source": [
    "model = build_model3()\n",
    "model.summary()\n",
    "model.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\", keras.metrics.F1Score(), keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "score = model.fit(X_train, y_train,\n",
    " epochs = EPOCHS,\n",
    " batch_size = BATCH_SIZE,\n",
    " validation_data = (X_test, y_test)\n",
    ")\n",
    "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save(\"imdb3.h5\")\n",
    "\n",
    "val = model.predict(X_train)\n",
    "print(f'результат: {np.argmax(val[0])}')\n",
    "word2index = imdb.get_word_index()\n",
    "test=[]\n",
    "for word in word_tokenize( \"i love this movie\"):\n",
    "     test.append(word2index[word])\n",
    "\n",
    "test=pad_sequences([test],maxlen=200)\n",
    "print(model.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1411713 (5.39 MB)\n",
      "Trainable params: 1411713 (5.39 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "50/50 [==============================] - 47s 925ms/step - loss: 0.6920 - accuracy: 0.5342 - f1_score: 0.6667 - precision_7: 0.5519 - recall_7: 0.3633 - val_loss: 0.6903 - val_accuracy: 0.5909 - val_f1_score: 0.6667 - val_precision_7: 0.5723 - val_recall_7: 0.7193\n",
      "Epoch 2/40\n",
      "50/50 [==============================] - 46s 920ms/step - loss: 25817010208226934784.0000 - accuracy: 0.5906 - f1_score: 0.6594 - precision_7: 0.5990 - recall_7: 0.5481 - val_loss: 1985667052792671371264.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 3/40\n",
      "50/50 [==============================] - 45s 896ms/step - loss: 1359110791509168881664.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1291459688231646265344.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 4/40\n",
      "50/50 [==============================] - 44s 881ms/step - loss: 1312284192171119083520.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1285025451739017379840.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 5/40\n",
      "50/50 [==============================] - 44s 883ms/step - loss: 1310148360047838625792.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1316807354309370970112.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 6/40\n",
      "50/50 [==============================] - 45s 906ms/step - loss: 1310657266805731491840.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1283891811270315212800.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 7/40\n",
      "50/50 [==============================] - 48s 975ms/step - loss: 1325775569279837536256.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1269064272447151276032.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 8/40\n",
      "50/50 [==============================] - 45s 902ms/step - loss: 1309190359964603908096.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1278209675915457200128.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 9/40\n",
      "50/50 [==============================] - 47s 940ms/step - loss: 1323677877015901372416.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1290152799914778689536.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 10/40\n",
      "50/50 [==============================] - 41s 828ms/step - loss: 1318599224011111006208.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1281129415848876834816.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 11/40\n",
      "50/50 [==============================] - 38s 773ms/step - loss: 1329372397269734653952.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1295087196994004844544.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 12/40\n",
      "50/50 [==============================] - 39s 784ms/step - loss: 1323266923549903814656.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1290809199560467939328.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 13/40\n",
      "50/50 [==============================] - 38s 766ms/step - loss: 1324674298433457094656.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1292758554511677587456.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 14/40\n",
      "50/50 [==============================] - 40s 803ms/step - loss: 1320168728481249624064.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1295422574428755591168.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 15/40\n",
      "50/50 [==============================] - 39s 782ms/step - loss: 1319703731819723620352.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1284675578342966034432.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 16/40\n",
      "50/50 [==============================] - 39s 776ms/step - loss: 1322374929348707745792.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1298645462912092602368.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 17/40\n",
      "50/50 [==============================] - 38s 770ms/step - loss: 1317035349040506601472.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1281173466682732052480.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 18/40\n",
      "50/50 [==============================] - 38s 775ms/step - loss: 1315067557478322405376.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1281311248683831918592.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 19/40\n",
      "50/50 [==============================] - 38s 771ms/step - loss: 1318523366504887484416.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1281397661501682089984.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 20/40\n",
      "50/50 [==============================] - 38s 758ms/step - loss: 1315343965905452269568.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1284093488091128397824.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 21/40\n",
      "50/50 [==============================] - 38s 761ms/step - loss: 1324398593693769007104.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1281098031388973596672.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 22/40\n",
      "50/50 [==============================] - 39s 777ms/step - loss: 1319232683446198337536.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1284086169741733920768.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 23/40\n",
      "50/50 [==============================] - 40s 798ms/step - loss: 1321312642786601730048.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1279751314362901463040.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 24/40\n",
      "50/50 [==============================] - 39s 775ms/step - loss: 1316465502950155878400.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1279193712434037653504.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 25/40\n",
      "50/50 [==============================] - 39s 783ms/step - loss: 1311643132911660564480.0000 - accuracy: 0.5000 - f1_score: 1.5999e-04 - precision_7: 1.0000 - recall_7: 8.0000e-05 - val_loss: 1280484697414721077248.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 26/40\n",
      "50/50 [==============================] - 39s 777ms/step - loss: 1306991618184028618752.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1286502632416794902528.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 27/40\n",
      "50/50 [==============================] - 39s 785ms/step - loss: 1314716839657340928000.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1267540226185751429120.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 28/40\n",
      "50/50 [==============================] - 38s 759ms/step - loss: 1306255420382441897984.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1260377954665860431872.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 29/40\n",
      "50/50 [==============================] - 38s 768ms/step - loss: 1306781778588890824704.0000 - accuracy: 0.5000 - f1_score: 1.5997e-04 - precision_7: 0.5000 - recall_7: 8.0000e-05 - val_loss: 1262506046227281346560.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 30/40\n",
      "50/50 [==============================] - 38s 764ms/step - loss: 1296995878811079802880.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1266344661222172917760.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 31/40\n",
      "50/50 [==============================] - 38s 759ms/step - loss: 1305862059102488756224.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1266720430316081643520.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 32/40\n",
      "50/50 [==============================] - 39s 785ms/step - loss: 1301464857016314888192.0000 - accuracy: 0.5001 - f1_score: 3.1995e-04 - precision_7: 1.0000 - recall_7: 1.6000e-04 - val_loss: 1267167975529051586560.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 33/40\n",
      "50/50 [==============================] - 38s 772ms/step - loss: 1303573526804342767616.0000 - accuracy: 0.4999 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1258974238957004390400.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 34/40\n",
      "50/50 [==============================] - 39s 785ms/step - loss: 1300094214617222348800.0000 - accuracy: 0.5000 - f1_score: 1.5996e-04 - precision_7: 0.3333 - recall_7: 8.0000e-05 - val_loss: 1258335009284894490624.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 35/40\n",
      "50/50 [==============================] - 38s 775ms/step - loss: 1300483494510013186048.0000 - accuracy: 0.5000 - f1_score: 1.5997e-04 - precision_7: 0.5000 - recall_7: 8.0000e-05 - val_loss: 1258249159416997740544.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 36/40\n",
      "50/50 [==============================] - 38s 768ms/step - loss: 1302995236464690724864.0000 - accuracy: 0.5000 - f1_score: 1.5999e-04 - precision_7: 1.0000 - recall_7: 8.0000e-05 - val_loss: 1260066221129153380352.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 37/40\n",
      "50/50 [==============================] - 38s 761ms/step - loss: 1301994874397461053440.0000 - accuracy: 0.5000 - f1_score: 1.5996e-04 - precision_7: 0.3333 - recall_7: 8.0000e-05 - val_loss: 1257729275135013158912.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 38/40\n",
      "50/50 [==============================] - 39s 791ms/step - loss: 1305236340229260967936.0000 - accuracy: 0.5000 - f1_score: 1.5997e-04 - precision_7: 0.5000 - recall_7: 8.0000e-05 - val_loss: 1257470599631416066048.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 39/40\n",
      "50/50 [==============================] - 38s 764ms/step - loss: 1288990871210917101568.0000 - accuracy: 0.4999 - f1_score: 3.1985e-04 - precision_7: 0.3333 - recall_7: 1.6000e-04 - val_loss: 1249460525481672572928.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 40/40\n",
      "50/50 [==============================] - 39s 786ms/step - loss: 1291716252672918028288.0000 - accuracy: 0.4998 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1245902822513538236416.0000 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "50/50 [==============================] - 12s 241ms/step - loss: 1245902822513538236416.0000 - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
      "\n",
      "Test score: 1.2459028225135382e+21\n",
      "Test accuracy: 0.5\n",
      "782/782 [==============================] - 30s 39ms/step\n",
      "результат: 0\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "model = build_model4()\n",
    "model.summary()\n",
    "model.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\", keras.metrics.F1Score(), keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "score = model.fit(X_train, y_train,\n",
    " epochs = EPOCHS,\n",
    " batch_size = BATCH_SIZE,\n",
    " validation_data = (X_test, y_test)\n",
    ")\n",
    "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save(\"imdb4.h5\")\n",
    "\n",
    "val = model.predict(X_train)\n",
    "print(f'результат: {np.argmax(val[0])}')\n",
    "word2index = imdb.get_word_index()\n",
    "test=[]\n",
    "for word in word_tokenize( \"i love this movie\"):\n",
    "     test.append(word2index[word])\n",
    "\n",
    "test=pad_sequences([test],maxlen=200)\n",
    "print(model.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 128)               99072     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1379201 (5.26 MB)\n",
      "Trainable params: 1379201 (5.26 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "50/50 [==============================] - 37s 724ms/step - loss: 0.6905 - accuracy: 0.5365 - f1_score: 0.6667 - precision_8: 0.5542 - recall_8: 0.3733 - val_loss: 0.6865 - val_accuracy: 0.5815 - val_f1_score: 0.6667 - val_precision_8: 0.5927 - val_recall_8: 0.5211\n",
      "Epoch 2/40\n",
      "50/50 [==============================] - 39s 784ms/step - loss: 0.6713 - accuracy: 0.5994 - f1_score: 0.6667 - precision_8: 0.6032 - recall_8: 0.5809 - val_loss: 0.6365 - val_accuracy: 0.6483 - val_f1_score: 0.6667 - val_precision_8: 0.6473 - val_recall_8: 0.6517\n",
      "Epoch 3/40\n",
      "50/50 [==============================] - 35s 701ms/step - loss: 0.5691 - accuracy: 0.7039 - f1_score: 0.6667 - precision_8: 0.6967 - recall_8: 0.7222 - val_loss: 0.5157 - val_accuracy: 0.7450 - val_f1_score: 0.6667 - val_precision_8: 0.6840 - val_recall_8: 0.9107\n",
      "Epoch 4/40\n",
      "50/50 [==============================] - 35s 696ms/step - loss: 0.4678 - accuracy: 0.7839 - f1_score: 0.6667 - precision_8: 0.7873 - recall_8: 0.7780 - val_loss: 0.6379 - val_accuracy: 0.7020 - val_f1_score: 0.6667 - val_precision_8: 0.6299 - val_recall_8: 0.9794\n",
      "Epoch 5/40\n",
      "50/50 [==============================] - 36s 735ms/step - loss: 0.4501 - accuracy: 0.8090 - f1_score: 0.6680 - precision_8: 0.8197 - recall_8: 0.7924 - val_loss: 0.4334 - val_accuracy: 0.8078 - val_f1_score: 0.6667 - val_precision_8: 0.8278 - val_recall_8: 0.7773\n",
      "Epoch 6/40\n",
      "50/50 [==============================] - 36s 717ms/step - loss: 0.3653 - accuracy: 0.8488 - f1_score: 0.6675 - precision_8: 0.8460 - recall_8: 0.8530 - val_loss: 0.4018 - val_accuracy: 0.8230 - val_f1_score: 0.6667 - val_precision_8: 0.7657 - val_recall_8: 0.9308\n",
      "Epoch 7/40\n",
      "50/50 [==============================] - 36s 719ms/step - loss: 0.4954 - accuracy: 0.8476 - f1_score: 0.6685 - precision_8: 0.8755 - recall_8: 0.8105 - val_loss: 0.3548 - val_accuracy: 0.8478 - val_f1_score: 0.6672 - val_precision_8: 0.8492 - val_recall_8: 0.8459\n",
      "Epoch 8/40\n",
      "50/50 [==============================] - 36s 728ms/step - loss: 0.3266 - accuracy: 0.8654 - f1_score: 0.6673 - precision_8: 0.8551 - recall_8: 0.8798 - val_loss: 0.3526 - val_accuracy: 0.8558 - val_f1_score: 0.6723 - val_precision_8: 0.8950 - val_recall_8: 0.8062\n",
      "Epoch 9/40\n",
      "50/50 [==============================] - 35s 705ms/step - loss: 0.3328 - accuracy: 0.8665 - f1_score: 0.6670 - precision_8: 0.8661 - recall_8: 0.8670 - val_loss: 0.3748 - val_accuracy: 0.8375 - val_f1_score: 0.6667 - val_precision_8: 0.8423 - val_recall_8: 0.8305\n",
      "Epoch 10/40\n",
      "50/50 [==============================] - 35s 705ms/step - loss: 0.3021 - accuracy: 0.8830 - f1_score: 0.6667 - precision_8: 0.8861 - recall_8: 0.8790 - val_loss: 0.3459 - val_accuracy: 0.8575 - val_f1_score: 0.6667 - val_precision_8: 0.8304 - val_recall_8: 0.8985\n",
      "Epoch 11/40\n",
      "50/50 [==============================] - 36s 718ms/step - loss: 0.2995 - accuracy: 0.8793 - f1_score: 0.6667 - precision_8: 0.8783 - recall_8: 0.8806 - val_loss: 0.3275 - val_accuracy: 0.8624 - val_f1_score: 0.6667 - val_precision_8: 0.8688 - val_recall_8: 0.8536\n",
      "Epoch 12/40\n",
      "50/50 [==============================] - 35s 707ms/step - loss: 0.2726 - accuracy: 0.8903 - f1_score: 0.6667 - precision_8: 0.8891 - recall_8: 0.8919 - val_loss: 0.3359 - val_accuracy: 0.8535 - val_f1_score: 0.6667 - val_precision_8: 0.8752 - val_recall_8: 0.8245\n",
      "Epoch 13/40\n",
      "50/50 [==============================] - 35s 708ms/step - loss: 0.2703 - accuracy: 0.8946 - f1_score: 0.6667 - precision_8: 0.8956 - recall_8: 0.8934 - val_loss: 0.3274 - val_accuracy: 0.8592 - val_f1_score: 0.6667 - val_precision_8: 0.8816 - val_recall_8: 0.8298\n",
      "Epoch 14/40\n",
      "50/50 [==============================] - 36s 722ms/step - loss: 0.2536 - accuracy: 0.9050 - f1_score: 0.6667 - precision_8: 0.9147 - recall_8: 0.8934 - val_loss: 0.3158 - val_accuracy: 0.8696 - val_f1_score: 0.6667 - val_precision_8: 0.8652 - val_recall_8: 0.8758\n",
      "Epoch 15/40\n",
      "50/50 [==============================] - 36s 719ms/step - loss: 0.2305 - accuracy: 0.9108 - f1_score: 0.6667 - precision_8: 0.9147 - recall_8: 0.9061 - val_loss: 0.3384 - val_accuracy: 0.8574 - val_f1_score: 0.6667 - val_precision_8: 0.9154 - val_recall_8: 0.7876\n",
      "Epoch 16/40\n",
      "50/50 [==============================] - 43s 872ms/step - loss: 0.2349 - accuracy: 0.9078 - f1_score: 0.6667 - precision_8: 0.9119 - recall_8: 0.9029 - val_loss: 0.3244 - val_accuracy: 0.8674 - val_f1_score: 0.6667 - val_precision_8: 0.8495 - val_recall_8: 0.8931\n",
      "Epoch 17/40\n",
      "50/50 [==============================] - 41s 831ms/step - loss: 0.2187 - accuracy: 0.9162 - f1_score: 0.6667 - precision_8: 0.9194 - recall_8: 0.9124 - val_loss: 0.3536 - val_accuracy: 0.8671 - val_f1_score: 0.6667 - val_precision_8: 0.8319 - val_recall_8: 0.9202\n",
      "Epoch 18/40\n",
      "50/50 [==============================] - 35s 699ms/step - loss: 0.2132 - accuracy: 0.9170 - f1_score: 0.6667 - precision_8: 0.9231 - recall_8: 0.9098 - val_loss: 0.3730 - val_accuracy: 0.8431 - val_f1_score: 0.6667 - val_precision_8: 0.7980 - val_recall_8: 0.9188\n",
      "Epoch 19/40\n",
      "50/50 [==============================] - 35s 712ms/step - loss: 0.1948 - accuracy: 0.9265 - f1_score: 0.6667 - precision_8: 0.9287 - recall_8: 0.9239 - val_loss: 0.3315 - val_accuracy: 0.8701 - val_f1_score: 0.6667 - val_precision_8: 0.8972 - val_recall_8: 0.8360\n",
      "Epoch 20/40\n",
      "50/50 [==============================] - 35s 700ms/step - loss: 0.1938 - accuracy: 0.9265 - f1_score: 0.6667 - precision_8: 0.9311 - recall_8: 0.9211 - val_loss: 0.3684 - val_accuracy: 0.8513 - val_f1_score: 0.6667 - val_precision_8: 0.9208 - val_recall_8: 0.7687\n",
      "Epoch 21/40\n",
      "50/50 [==============================] - 35s 703ms/step - loss: 0.1853 - accuracy: 0.9288 - f1_score: 0.6667 - precision_8: 0.9330 - recall_8: 0.9240 - val_loss: 0.3288 - val_accuracy: 0.8696 - val_f1_score: 0.6667 - val_precision_8: 0.8593 - val_recall_8: 0.8839\n",
      "Epoch 22/40\n",
      "50/50 [==============================] - 36s 721ms/step - loss: 0.1807 - accuracy: 0.9318 - f1_score: 0.6667 - precision_8: 0.9355 - recall_8: 0.9275 - val_loss: 0.3658 - val_accuracy: 0.8552 - val_f1_score: 0.6667 - val_precision_8: 0.9163 - val_recall_8: 0.7818\n",
      "Epoch 23/40\n",
      "50/50 [==============================] - 35s 705ms/step - loss: 0.1712 - accuracy: 0.9343 - f1_score: 0.6667 - precision_8: 0.9385 - recall_8: 0.9296 - val_loss: 0.3320 - val_accuracy: 0.8674 - val_f1_score: 0.6667 - val_precision_8: 0.8691 - val_recall_8: 0.8650\n",
      "Epoch 24/40\n",
      "50/50 [==============================] - 35s 713ms/step - loss: 0.1582 - accuracy: 0.9411 - f1_score: 0.6667 - precision_8: 0.9453 - recall_8: 0.9364 - val_loss: 0.3409 - val_accuracy: 0.8696 - val_f1_score: 0.6667 - val_precision_8: 0.8809 - val_recall_8: 0.8547\n",
      "Epoch 25/40\n",
      "50/50 [==============================] - 34s 695ms/step - loss: 0.1579 - accuracy: 0.9436 - f1_score: 0.6667 - precision_8: 0.9462 - recall_8: 0.9408 - val_loss: 0.3565 - val_accuracy: 0.8716 - val_f1_score: 0.6667 - val_precision_8: 0.8619 - val_recall_8: 0.8849\n",
      "Epoch 26/40\n",
      "50/50 [==============================] - 34s 688ms/step - loss: 0.1556 - accuracy: 0.9417 - f1_score: 0.6667 - precision_8: 0.9433 - recall_8: 0.9398 - val_loss: 0.3546 - val_accuracy: 0.8581 - val_f1_score: 0.6667 - val_precision_8: 0.8844 - val_recall_8: 0.8238\n",
      "Epoch 27/40\n",
      "50/50 [==============================] - 34s 681ms/step - loss: 0.1415 - accuracy: 0.9484 - f1_score: 0.6667 - precision_8: 0.9506 - recall_8: 0.9460 - val_loss: 0.3927 - val_accuracy: 0.8503 - val_f1_score: 0.6667 - val_precision_8: 0.8124 - val_recall_8: 0.9109\n",
      "Epoch 28/40\n",
      "50/50 [==============================] - 35s 713ms/step - loss: 0.1437 - accuracy: 0.9443 - f1_score: 0.6667 - precision_8: 0.9467 - recall_8: 0.9416 - val_loss: 0.3699 - val_accuracy: 0.8547 - val_f1_score: 0.6667 - val_precision_8: 0.8852 - val_recall_8: 0.8150\n",
      "Epoch 29/40\n",
      "50/50 [==============================] - 36s 724ms/step - loss: 0.1271 - accuracy: 0.9552 - f1_score: 0.6667 - precision_8: 0.9577 - recall_8: 0.9524 - val_loss: 0.3965 - val_accuracy: 0.8681 - val_f1_score: 0.6667 - val_precision_8: 0.8807 - val_recall_8: 0.8515\n",
      "Epoch 30/40\n",
      "50/50 [==============================] - 35s 702ms/step - loss: 0.1282 - accuracy: 0.9527 - f1_score: 0.6667 - precision_8: 0.9554 - recall_8: 0.9497 - val_loss: 0.4053 - val_accuracy: 0.8637 - val_f1_score: 0.6667 - val_precision_8: 0.8350 - val_recall_8: 0.9066\n",
      "Epoch 31/40\n",
      "50/50 [==============================] - 36s 722ms/step - loss: 0.1215 - accuracy: 0.9562 - f1_score: 0.6667 - precision_8: 0.9567 - recall_8: 0.9556 - val_loss: 0.5219 - val_accuracy: 0.8345 - val_f1_score: 0.6667 - val_precision_8: 0.9296 - val_recall_8: 0.7238\n",
      "Epoch 32/40\n",
      "50/50 [==============================] - 35s 701ms/step - loss: 0.1241 - accuracy: 0.9559 - f1_score: 0.6667 - precision_8: 0.9584 - recall_8: 0.9532 - val_loss: 0.3862 - val_accuracy: 0.8622 - val_f1_score: 0.6667 - val_precision_8: 0.8597 - val_recall_8: 0.8658\n",
      "Epoch 33/40\n",
      "50/50 [==============================] - 35s 707ms/step - loss: 0.1093 - accuracy: 0.9617 - f1_score: 0.6667 - precision_8: 0.9641 - recall_8: 0.9591 - val_loss: 0.4138 - val_accuracy: 0.8642 - val_f1_score: 0.6667 - val_precision_8: 0.8817 - val_recall_8: 0.8413\n",
      "Epoch 34/40\n",
      "50/50 [==============================] - 36s 723ms/step - loss: 0.1070 - accuracy: 0.9628 - f1_score: 0.6667 - precision_8: 0.9651 - recall_8: 0.9604 - val_loss: 0.4582 - val_accuracy: 0.8586 - val_f1_score: 0.6667 - val_precision_8: 0.8953 - val_recall_8: 0.8121\n",
      "Epoch 35/40\n",
      "50/50 [==============================] - 36s 724ms/step - loss: 0.1076 - accuracy: 0.9608 - f1_score: 0.6667 - precision_8: 0.9631 - recall_8: 0.9583 - val_loss: 0.4290 - val_accuracy: 0.8654 - val_f1_score: 0.6667 - val_precision_8: 0.8721 - val_recall_8: 0.8564\n",
      "Epoch 36/40\n",
      "50/50 [==============================] - 35s 707ms/step - loss: 0.0978 - accuracy: 0.9671 - f1_score: 0.6667 - precision_8: 0.9705 - recall_8: 0.9635 - val_loss: 0.4764 - val_accuracy: 0.8624 - val_f1_score: 0.6667 - val_precision_8: 0.8379 - val_recall_8: 0.8987\n",
      "Epoch 37/40\n",
      "50/50 [==============================] - 35s 711ms/step - loss: 0.0976 - accuracy: 0.9650 - f1_score: 0.6667 - precision_8: 0.9684 - recall_8: 0.9614 - val_loss: 0.4629 - val_accuracy: 0.8572 - val_f1_score: 0.6667 - val_precision_8: 0.8921 - val_recall_8: 0.8128\n",
      "Epoch 38/40\n",
      "50/50 [==============================] - 34s 690ms/step - loss: 0.0951 - accuracy: 0.9663 - f1_score: 0.6667 - precision_8: 0.9686 - recall_8: 0.9639 - val_loss: 0.4604 - val_accuracy: 0.8625 - val_f1_score: 0.6667 - val_precision_8: 0.8611 - val_recall_8: 0.8645\n",
      "Epoch 39/40\n",
      "50/50 [==============================] - 33s 655ms/step - loss: 0.0930 - accuracy: 0.9684 - f1_score: 0.6667 - precision_8: 0.9698 - recall_8: 0.9669 - val_loss: 0.4362 - val_accuracy: 0.8502 - val_f1_score: 0.6667 - val_precision_8: 0.8701 - val_recall_8: 0.8234\n",
      "Epoch 40/40\n",
      "50/50 [==============================] - 32s 652ms/step - loss: 0.0781 - accuracy: 0.9747 - f1_score: 0.6667 - precision_8: 0.9768 - recall_8: 0.9725 - val_loss: 0.5003 - val_accuracy: 0.8461 - val_f1_score: 0.6667 - val_precision_8: 0.9030 - val_recall_8: 0.7756\n",
      "50/50 [==============================] - 12s 236ms/step - loss: 0.5003 - accuracy: 0.8461 - f1_score: 0.6667 - precision_8: 0.9030 - recall_8: 0.7756\n",
      "\n",
      "Test score: 0.5002724528312683\n",
      "Test accuracy: 0.8461199998855591\n",
      "782/782 [==============================] - 30s 38ms/step\n",
      "результат: 0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[0.48242223]]\n"
     ]
    }
   ],
   "source": [
    "model = build_model6()\n",
    "model.summary()\n",
    "model.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\", keras.metrics.F1Score(), keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "score = model.fit(X_train, y_train,\n",
    " epochs = EPOCHS,\n",
    " batch_size = BATCH_SIZE,\n",
    " validation_data = (X_test, y_test)\n",
    ")\n",
    "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save(\"imdb6.h5\")\n",
    "\n",
    "val = model.predict(X_train)\n",
    "print(f'результат: {np.argmax(val[0])}')\n",
    "word2index = imdb.get_word_index()\n",
    "test=[]\n",
    "for word in word_tokenize( \"i love this movie\"):\n",
    "     test.append(word2index[word])\n",
    "\n",
    "test=pad_sequences([test],maxlen=200)\n",
    "print(model.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " transformer_encoder (Trans  (None, 200, 128)          165504    \n",
      " formerEncoder)                                                  \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 128)               99072     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1544705 (5.89 MB)\n",
      "Trainable params: 1544705 (5.89 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "50/50 [==============================] - 122s 2s/step - loss: 0.6416 - accuracy: 0.6233 - f1_score: 0.6667 - precision_9: 0.6231 - recall_9: 0.6238 - val_loss: 0.5372 - val_accuracy: 0.7313 - val_f1_score: 0.6667 - val_precision_9: 0.7560 - val_recall_9: 0.6830\n",
      "Epoch 2/40\n",
      "50/50 [==============================] - 124s 2s/step - loss: 0.4549 - accuracy: 0.7854 - f1_score: 0.6667 - precision_9: 0.7774 - recall_9: 0.7999 - val_loss: 0.3590 - val_accuracy: 0.8366 - val_f1_score: 0.6667 - val_precision_9: 0.8123 - val_recall_9: 0.8757\n",
      "Epoch 3/40\n",
      "50/50 [==============================] - 118s 2s/step - loss: 0.3400 - accuracy: 0.8529 - f1_score: 0.6667 - precision_9: 0.8460 - recall_9: 0.8629 - val_loss: 0.3159 - val_accuracy: 0.8616 - val_f1_score: 0.6667 - val_precision_9: 0.8333 - val_recall_9: 0.9042\n",
      "Epoch 4/40\n",
      "50/50 [==============================] - 123s 2s/step - loss: 0.2658 - accuracy: 0.8888 - f1_score: 0.6667 - precision_9: 0.8869 - recall_9: 0.8912 - val_loss: 0.3166 - val_accuracy: 0.8635 - val_f1_score: 0.6667 - val_precision_9: 0.8197 - val_recall_9: 0.9320\n",
      "Epoch 5/40\n",
      "50/50 [==============================] - 118s 2s/step - loss: 0.2077 - accuracy: 0.9152 - f1_score: 0.6667 - precision_9: 0.9132 - recall_9: 0.9178 - val_loss: 0.2999 - val_accuracy: 0.8792 - val_f1_score: 0.6667 - val_precision_9: 0.8669 - val_recall_9: 0.8960\n",
      "Epoch 6/40\n",
      "50/50 [==============================] - 113s 2s/step - loss: 0.1528 - accuracy: 0.9424 - f1_score: 0.6667 - precision_9: 0.9416 - recall_9: 0.9434 - val_loss: 0.3941 - val_accuracy: 0.8613 - val_f1_score: 0.6667 - val_precision_9: 0.8115 - val_recall_9: 0.9412\n",
      "Epoch 7/40\n",
      "50/50 [==============================] - 116s 2s/step - loss: 0.1156 - accuracy: 0.9587 - f1_score: 0.6667 - precision_9: 0.9578 - recall_9: 0.9596 - val_loss: 0.4110 - val_accuracy: 0.8590 - val_f1_score: 0.6667 - val_precision_9: 0.8117 - val_recall_9: 0.9350\n",
      "Epoch 8/40\n",
      "50/50 [==============================] - 112s 2s/step - loss: 0.0767 - accuracy: 0.9736 - f1_score: 0.6667 - precision_9: 0.9725 - recall_9: 0.9748 - val_loss: 0.4190 - val_accuracy: 0.8694 - val_f1_score: 0.6667 - val_precision_9: 0.8723 - val_recall_9: 0.8656\n",
      "Epoch 9/40\n",
      "50/50 [==============================] - 113s 2s/step - loss: 0.0526 - accuracy: 0.9822 - f1_score: 0.6670 - precision_9: 0.9829 - recall_9: 0.9814 - val_loss: 0.5012 - val_accuracy: 0.8680 - val_f1_score: 0.6667 - val_precision_9: 0.8493 - val_recall_9: 0.8948\n",
      "Epoch 10/40\n",
      "50/50 [==============================] - 115s 2s/step - loss: 0.0361 - accuracy: 0.9890 - f1_score: 0.6682 - precision_9: 0.9891 - recall_9: 0.9888 - val_loss: 0.5913 - val_accuracy: 0.8620 - val_f1_score: 0.6680 - val_precision_9: 0.8934 - val_recall_9: 0.8222\n",
      "Epoch 11/40\n",
      "50/50 [==============================] - 120s 2s/step - loss: 0.0271 - accuracy: 0.9916 - f1_score: 0.6699 - precision_9: 0.9930 - recall_9: 0.9902 - val_loss: 0.6558 - val_accuracy: 0.8643 - val_f1_score: 0.6708 - val_precision_9: 0.8870 - val_recall_9: 0.8350\n",
      "Epoch 12/40\n",
      "50/50 [==============================] - 120s 2s/step - loss: 0.0271 - accuracy: 0.9915 - f1_score: 0.6734 - precision_9: 0.9926 - recall_9: 0.9903 - val_loss: 0.6600 - val_accuracy: 0.8660 - val_f1_score: 0.6712 - val_precision_9: 0.8698 - val_recall_9: 0.8608\n",
      "Epoch 13/40\n",
      "50/50 [==============================] - 114s 2s/step - loss: 0.0247 - accuracy: 0.9922 - f1_score: 0.6766 - precision_9: 0.9908 - recall_9: 0.9936 - val_loss: 0.6294 - val_accuracy: 0.8663 - val_f1_score: 0.6712 - val_precision_9: 0.8627 - val_recall_9: 0.8714\n",
      "Epoch 14/40\n",
      "50/50 [==============================] - 117s 2s/step - loss: 0.0220 - accuracy: 0.9935 - f1_score: 0.6760 - precision_9: 0.9954 - recall_9: 0.9915 - val_loss: 0.7256 - val_accuracy: 0.8670 - val_f1_score: 0.6737 - val_precision_9: 0.8582 - val_recall_9: 0.8793\n",
      "Epoch 15/40\n",
      "50/50 [==============================] - 122s 2s/step - loss: 0.0192 - accuracy: 0.9944 - f1_score: 0.6822 - precision_9: 0.9947 - recall_9: 0.9942 - val_loss: 0.6569 - val_accuracy: 0.8679 - val_f1_score: 0.6733 - val_precision_9: 0.8702 - val_recall_9: 0.8648\n",
      "Epoch 16/40\n",
      "50/50 [==============================] - 118s 2s/step - loss: 0.0036 - accuracy: 0.9994 - f1_score: 0.6851 - precision_9: 0.9993 - recall_9: 0.9996 - val_loss: 0.8706 - val_accuracy: 0.8654 - val_f1_score: 0.6944 - val_precision_9: 0.8671 - val_recall_9: 0.8632\n",
      "Epoch 17/40\n",
      "50/50 [==============================] - 111s 2s/step - loss: 0.0175 - accuracy: 0.9948 - f1_score: 0.6967 - precision_9: 0.9948 - recall_9: 0.9949 - val_loss: 0.7925 - val_accuracy: 0.8652 - val_f1_score: 0.6858 - val_precision_9: 0.8575 - val_recall_9: 0.8760\n",
      "Epoch 18/40\n",
      "50/50 [==============================] - 114s 2s/step - loss: 0.0144 - accuracy: 0.9959 - f1_score: 0.7105 - precision_9: 0.9964 - recall_9: 0.9954 - val_loss: 0.6569 - val_accuracy: 0.8587 - val_f1_score: 0.6760 - val_precision_9: 0.8780 - val_recall_9: 0.8331\n",
      "Epoch 19/40\n",
      "50/50 [==============================] - 111s 2s/step - loss: 0.0017 - accuracy: 0.9997 - f1_score: 0.7043 - precision_9: 0.9997 - recall_9: 0.9997 - val_loss: 0.9467 - val_accuracy: 0.8640 - val_f1_score: 0.7091 - val_precision_9: 0.8637 - val_recall_9: 0.8645\n",
      "Epoch 20/40\n",
      "50/50 [==============================] - 115s 2s/step - loss: 0.0146 - accuracy: 0.9955 - f1_score: 0.7026 - precision_9: 0.9949 - recall_9: 0.9962 - val_loss: 0.9524 - val_accuracy: 0.8659 - val_f1_score: 0.7187 - val_precision_9: 0.8669 - val_recall_9: 0.8645\n",
      "Epoch 21/40\n",
      "50/50 [==============================] - 110s 2s/step - loss: 0.0145 - accuracy: 0.9956 - f1_score: 0.7251 - precision_9: 0.9957 - recall_9: 0.9954 - val_loss: 0.8201 - val_accuracy: 0.8663 - val_f1_score: 0.7019 - val_precision_9: 0.8755 - val_recall_9: 0.8540\n",
      "Epoch 22/40\n",
      "50/50 [==============================] - 115s 2s/step - loss: 8.0200e-04 - accuracy: 0.9999 - f1_score: 0.7204 - precision_9: 0.9998 - recall_9: 0.9999 - val_loss: 0.9905 - val_accuracy: 0.8670 - val_f1_score: 0.7248 - val_precision_9: 0.8618 - val_recall_9: 0.8742\n",
      "Epoch 23/40\n",
      "50/50 [==============================] - 115s 2s/step - loss: 0.0173 - accuracy: 0.9950 - f1_score: 0.7160 - precision_9: 0.9950 - recall_9: 0.9950 - val_loss: 0.7919 - val_accuracy: 0.8657 - val_f1_score: 0.6937 - val_precision_9: 0.8670 - val_recall_9: 0.8639\n",
      "Epoch 24/40\n",
      "50/50 [==============================] - 114s 2s/step - loss: 0.0037 - accuracy: 0.9989 - f1_score: 0.7125 - precision_9: 0.9992 - recall_9: 0.9986 - val_loss: 0.8910 - val_accuracy: 0.8659 - val_f1_score: 0.7183 - val_precision_9: 0.8642 - val_recall_9: 0.8683\n",
      "Epoch 25/40\n",
      "50/50 [==============================] - 117s 2s/step - loss: 0.0077 - accuracy: 0.9979 - f1_score: 0.7263 - precision_9: 0.9979 - recall_9: 0.9978 - val_loss: 0.9394 - val_accuracy: 0.8654 - val_f1_score: 0.7203 - val_precision_9: 0.8637 - val_recall_9: 0.8678\n",
      "Epoch 26/40\n",
      "50/50 [==============================] - 117s 2s/step - loss: 3.7134e-04 - accuracy: 1.0000 - f1_score: 0.7445 - precision_9: 0.9999 - recall_9: 1.0000 - val_loss: 1.0943 - val_accuracy: 0.8650 - val_f1_score: 0.7542 - val_precision_9: 0.8757 - val_recall_9: 0.8507\n",
      "Epoch 27/40\n",
      "50/50 [==============================] - 113s 2s/step - loss: 0.0069 - accuracy: 0.9981 - f1_score: 0.7335 - precision_9: 0.9979 - recall_9: 0.9983 - val_loss: 1.0366 - val_accuracy: 0.8653 - val_f1_score: 0.7408 - val_precision_9: 0.8662 - val_recall_9: 0.8642\n",
      "Epoch 28/40\n",
      "50/50 [==============================] - 114s 2s/step - loss: 0.0078 - accuracy: 0.9975 - f1_score: 0.7445 - precision_9: 0.9974 - recall_9: 0.9976 - val_loss: 0.9219 - val_accuracy: 0.8640 - val_f1_score: 0.7192 - val_precision_9: 0.8692 - val_recall_9: 0.8570\n",
      "Epoch 29/40\n",
      "50/50 [==============================] - 114s 2s/step - loss: 3.9708e-04 - accuracy: 1.0000 - f1_score: 0.7470 - precision_9: 1.0000 - recall_9: 0.9999 - val_loss: 1.1313 - val_accuracy: 0.8650 - val_f1_score: 0.7541 - val_precision_9: 0.8701 - val_recall_9: 0.8581\n",
      "Epoch 30/40\n",
      "50/50 [==============================] - 111s 2s/step - loss: 8.5823e-05 - accuracy: 1.0000 - f1_score: 0.7790 - precision_9: 1.0000 - recall_9: 1.0000 - val_loss: 1.2216 - val_accuracy: 0.8651 - val_f1_score: 0.7652 - val_precision_9: 0.8659 - val_recall_9: 0.8641\n",
      "Epoch 31/40\n",
      "50/50 [==============================] - 115s 2s/step - loss: 3.9849e-05 - accuracy: 1.0000 - f1_score: 0.8022 - precision_9: 1.0000 - recall_9: 1.0000 - val_loss: 1.2708 - val_accuracy: 0.8645 - val_f1_score: 0.7757 - val_precision_9: 0.8723 - val_recall_9: 0.8541\n",
      "Epoch 32/40\n",
      "50/50 [==============================] - 114s 2s/step - loss: 4.4864e-05 - accuracy: 1.0000 - f1_score: 0.8085 - precision_9: 1.0000 - recall_9: 1.0000 - val_loss: 1.3725 - val_accuracy: 0.8490 - val_f1_score: 0.7917 - val_precision_9: 0.9046 - val_recall_9: 0.7803\n",
      "Epoch 33/40\n",
      "50/50 [==============================] - 113s 2s/step - loss: 0.0134 - accuracy: 0.9960 - f1_score: 0.7367 - precision_9: 0.9970 - recall_9: 0.9950 - val_loss: 1.0989 - val_accuracy: 0.8648 - val_f1_score: 0.7383 - val_precision_9: 0.8573 - val_recall_9: 0.8754\n",
      "Epoch 34/40\n",
      "50/50 [==============================] - 113s 2s/step - loss: 1.0945e-04 - accuracy: 1.0000 - f1_score: 0.7721 - precision_9: 1.0000 - recall_9: 1.0000 - val_loss: 1.1793 - val_accuracy: 0.8640 - val_f1_score: 0.7531 - val_precision_9: 0.8642 - val_recall_9: 0.8638\n",
      "Epoch 35/40\n",
      "50/50 [==============================] - 111s 2s/step - loss: 0.0178 - accuracy: 0.9950 - f1_score: 0.7415 - precision_9: 0.9958 - recall_9: 0.9942 - val_loss: 1.0358 - val_accuracy: 0.8657 - val_f1_score: 0.7415 - val_precision_9: 0.8655 - val_recall_9: 0.8660\n",
      "Epoch 36/40\n",
      "50/50 [==============================] - 114s 2s/step - loss: 0.0068 - accuracy: 0.9982 - f1_score: 0.7606 - precision_9: 0.9980 - recall_9: 0.9984 - val_loss: 0.9502 - val_accuracy: 0.8650 - val_f1_score: 0.7294 - val_precision_9: 0.8674 - val_recall_9: 0.8616\n",
      "Epoch 37/40\n",
      "50/50 [==============================] - 113s 2s/step - loss: 0.0032 - accuracy: 0.9991 - f1_score: 0.7485 - precision_9: 0.9993 - recall_9: 0.9990 - val_loss: 0.9571 - val_accuracy: 0.8607 - val_f1_score: 0.7138 - val_precision_9: 0.8400 - val_recall_9: 0.8911\n",
      "Epoch 38/40\n",
      "50/50 [==============================] - 113s 2s/step - loss: 0.0025 - accuracy: 0.9994 - f1_score: 0.7614 - precision_9: 0.9994 - recall_9: 0.9994 - val_loss: 0.9973 - val_accuracy: 0.8636 - val_f1_score: 0.7402 - val_precision_9: 0.8639 - val_recall_9: 0.8630\n",
      "Epoch 39/40\n",
      "50/50 [==============================] - 114s 2s/step - loss: 0.0080 - accuracy: 0.9976 - f1_score: 0.7653 - precision_9: 0.9974 - recall_9: 0.9978 - val_loss: 0.9840 - val_accuracy: 0.8603 - val_f1_score: 0.7374 - val_precision_9: 0.8703 - val_recall_9: 0.8469\n",
      "Epoch 40/40\n",
      "50/50 [==============================] - 113s 2s/step - loss: 6.5428e-04 - accuracy: 0.9999 - f1_score: 0.7692 - precision_9: 0.9998 - recall_9: 0.9999 - val_loss: 1.1094 - val_accuracy: 0.8651 - val_f1_score: 0.7568 - val_precision_9: 0.8547 - val_recall_9: 0.8797\n",
      "50/50 [==============================] - 31s 612ms/step - loss: 1.1094 - accuracy: 0.8651 - f1_score: 0.7568 - precision_9: 0.8547 - recall_9: 0.8797\n",
      "\n",
      "Test score: 1.1093703508377075\n",
      "Test accuracy: 0.8650799989700317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 54s 69ms/step\n",
      "результат: 0\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[0.20231257]]\n"
     ]
    }
   ],
   "source": [
    "model = build_model7()\n",
    "model.summary()\n",
    "model.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\", keras.metrics.F1Score(), keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "score = model.fit(X_train, y_train,\n",
    " epochs = EPOCHS,\n",
    " batch_size = BATCH_SIZE,\n",
    " validation_data = (X_test, y_test)\n",
    ")\n",
    "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save(\"imdb6.h5\")\n",
    "\n",
    "val = model.predict(X_train)\n",
    "print(f'результат: {np.argmax(val[0])}')\n",
    "word2index = imdb.get_word_index()\n",
    "test=[]\n",
    "for word in word_tokenize( \"i love this movie\"):\n",
    "     test.append(word2index[word])\n",
    "\n",
    "test=pad_sequences([test],maxlen=200)\n",
    "print(model.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " transformer_encoder_1 (Tra  (None, 200, 128)          165504    \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 199, 128)          32896     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25472)             0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 25472)             0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 25473     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1503873 (5.74 MB)\n",
      "Trainable params: 1503873 (5.74 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "50/50 [==============================] - 102s 2s/step - loss: 0.9545 - accuracy: 0.5215 - f1_score: 0.6620 - precision_10: 0.5237 - recall_10: 0.4747 - val_loss: 0.6857 - val_accuracy: 0.5444 - val_f1_score: 0.6667 - val_precision_10: 0.5398 - val_recall_10: 0.6021\n",
      "Epoch 2/40\n",
      "50/50 [==============================] - 96s 2s/step - loss: 0.7087 - accuracy: 0.5981 - f1_score: 0.6667 - precision_10: 0.6152 - recall_10: 0.5237 - val_loss: 0.6422 - val_accuracy: 0.6194 - val_f1_score: 0.6667 - val_precision_10: 0.7518 - val_recall_10: 0.3565\n",
      "Epoch 3/40\n",
      "50/50 [==============================] - 97s 2s/step - loss: 0.6231 - accuracy: 0.6920 - f1_score: 0.6667 - precision_10: 0.6927 - recall_10: 0.6900 - val_loss: 0.6747 - val_accuracy: 0.5612 - val_f1_score: 0.6667 - val_precision_10: 0.9670 - val_recall_10: 0.1266\n",
      "Epoch 4/40\n",
      "50/50 [==============================] - 97s 2s/step - loss: 0.4917 - accuracy: 0.7918 - f1_score: 0.6667 - precision_10: 0.7958 - recall_10: 0.7852 - val_loss: 0.4097 - val_accuracy: 0.8102 - val_f1_score: 0.6667 - val_precision_10: 0.7683 - val_recall_10: 0.8884\n",
      "Epoch 5/40\n",
      "50/50 [==============================] - 92s 2s/step - loss: 0.3304 - accuracy: 0.8605 - f1_score: 0.6667 - precision_10: 0.8580 - recall_10: 0.8640 - val_loss: 0.3832 - val_accuracy: 0.8262 - val_f1_score: 0.6667 - val_precision_10: 0.8980 - val_recall_10: 0.7360\n",
      "Epoch 6/40\n",
      "50/50 [==============================] - 88s 2s/step - loss: 0.2331 - accuracy: 0.9076 - f1_score: 0.6667 - precision_10: 0.9055 - recall_10: 0.9102 - val_loss: 0.4501 - val_accuracy: 0.8068 - val_f1_score: 0.6667 - val_precision_10: 0.7337 - val_recall_10: 0.9632\n",
      "Epoch 7/40\n",
      "50/50 [==============================] - 84s 2s/step - loss: 0.1672 - accuracy: 0.9365 - f1_score: 0.6667 - precision_10: 0.9350 - recall_10: 0.9383 - val_loss: 0.3734 - val_accuracy: 0.8340 - val_f1_score: 0.6667 - val_precision_10: 0.8984 - val_recall_10: 0.7532\n",
      "Epoch 8/40\n",
      "50/50 [==============================] - 77s 2s/step - loss: 0.1076 - accuracy: 0.9657 - f1_score: 0.6669 - precision_10: 0.9651 - recall_10: 0.9663 - val_loss: 0.3992 - val_accuracy: 0.8390 - val_f1_score: 0.6667 - val_precision_10: 0.7859 - val_recall_10: 0.9319\n",
      "Epoch 9/40\n",
      "50/50 [==============================] - 82s 2s/step - loss: 0.0739 - accuracy: 0.9763 - f1_score: 0.6673 - precision_10: 0.9753 - recall_10: 0.9773 - val_loss: 0.4007 - val_accuracy: 0.8364 - val_f1_score: 0.6667 - val_precision_10: 0.7832 - val_recall_10: 0.9304\n",
      "Epoch 10/40\n",
      "50/50 [==============================] - 80s 2s/step - loss: 0.0415 - accuracy: 0.9888 - f1_score: 0.6680 - precision_10: 0.9890 - recall_10: 0.9885 - val_loss: 0.6614 - val_accuracy: 0.7826 - val_f1_score: 0.6667 - val_precision_10: 0.7040 - val_recall_10: 0.9754\n",
      "Epoch 11/40\n",
      "50/50 [==============================] - 93s 2s/step - loss: 0.0298 - accuracy: 0.9917 - f1_score: 0.6693 - precision_10: 0.9913 - recall_10: 0.9922 - val_loss: 0.4677 - val_accuracy: 0.8462 - val_f1_score: 0.6680 - val_precision_10: 0.8039 - val_recall_10: 0.9158\n",
      "Epoch 12/40\n",
      "50/50 [==============================] - 92s 2s/step - loss: 0.0177 - accuracy: 0.9960 - f1_score: 0.6720 - precision_10: 0.9958 - recall_10: 0.9962 - val_loss: 0.4700 - val_accuracy: 0.8520 - val_f1_score: 0.6705 - val_precision_10: 0.8221 - val_recall_10: 0.8985\n",
      "Epoch 13/40\n",
      "50/50 [==============================] - 92s 2s/step - loss: 0.0207 - accuracy: 0.9936 - f1_score: 0.6744 - precision_10: 0.9939 - recall_10: 0.9932 - val_loss: 0.4229 - val_accuracy: 0.8547 - val_f1_score: 0.6709 - val_precision_10: 0.8598 - val_recall_10: 0.8477\n",
      "Epoch 14/40\n",
      "50/50 [==============================] - 98s 2s/step - loss: 0.0173 - accuracy: 0.9940 - f1_score: 0.6758 - precision_10: 0.9933 - recall_10: 0.9946 - val_loss: 0.4894 - val_accuracy: 0.8532 - val_f1_score: 0.6738 - val_precision_10: 0.8378 - val_recall_10: 0.8759\n",
      "Epoch 15/40\n",
      "50/50 [==============================] - 99s 2s/step - loss: 0.0102 - accuracy: 0.9968 - f1_score: 0.6794 - precision_10: 0.9973 - recall_10: 0.9962 - val_loss: 0.4965 - val_accuracy: 0.8545 - val_f1_score: 0.6771 - val_precision_10: 0.8651 - val_recall_10: 0.8399\n",
      "Epoch 16/40\n",
      "50/50 [==============================] - 83s 2s/step - loss: 0.0091 - accuracy: 0.9972 - f1_score: 0.6829 - precision_10: 0.9980 - recall_10: 0.9965 - val_loss: 0.5426 - val_accuracy: 0.8535 - val_f1_score: 0.6780 - val_precision_10: 0.8305 - val_recall_10: 0.8883\n",
      "Epoch 17/40\n",
      "50/50 [==============================] - 88s 2s/step - loss: 0.0070 - accuracy: 0.9979 - f1_score: 0.6834 - precision_10: 0.9982 - recall_10: 0.9977 - val_loss: 0.5610 - val_accuracy: 0.8509 - val_f1_score: 0.6774 - val_precision_10: 0.8225 - val_recall_10: 0.8950\n",
      "Epoch 18/40\n",
      "50/50 [==============================] - 91s 2s/step - loss: 0.0079 - accuracy: 0.9973 - f1_score: 0.6850 - precision_10: 0.9978 - recall_10: 0.9967 - val_loss: 0.5456 - val_accuracy: 0.8551 - val_f1_score: 0.6815 - val_precision_10: 0.8517 - val_recall_10: 0.8600\n",
      "Epoch 19/40\n",
      "50/50 [==============================] - 94s 2s/step - loss: 0.0046 - accuracy: 0.9989 - f1_score: 0.6895 - precision_10: 0.9989 - recall_10: 0.9990 - val_loss: 0.5643 - val_accuracy: 0.8558 - val_f1_score: 0.6847 - val_precision_10: 0.8546 - val_recall_10: 0.8574\n",
      "Epoch 20/40\n",
      "50/50 [==============================] - 93s 2s/step - loss: 0.0077 - accuracy: 0.9975 - f1_score: 0.6890 - precision_10: 0.9974 - recall_10: 0.9975 - val_loss: 0.6220 - val_accuracy: 0.8499 - val_f1_score: 0.6840 - val_precision_10: 0.8236 - val_recall_10: 0.8906\n",
      "Epoch 21/40\n",
      "50/50 [==============================] - 94s 2s/step - loss: 0.0030 - accuracy: 0.9992 - f1_score: 0.6942 - precision_10: 0.9994 - recall_10: 0.9991 - val_loss: 0.5937 - val_accuracy: 0.8539 - val_f1_score: 0.6876 - val_precision_10: 0.8455 - val_recall_10: 0.8662\n",
      "Epoch 22/40\n",
      "50/50 [==============================] - 94s 2s/step - loss: 0.0038 - accuracy: 0.9991 - f1_score: 0.6989 - precision_10: 0.9992 - recall_10: 0.9990 - val_loss: 0.5742 - val_accuracy: 0.8543 - val_f1_score: 0.6897 - val_precision_10: 0.8618 - val_recall_10: 0.8439\n",
      "Epoch 23/40\n",
      "50/50 [==============================] - 94s 2s/step - loss: 0.0061 - accuracy: 0.9980 - f1_score: 0.6960 - precision_10: 0.9982 - recall_10: 0.9978 - val_loss: 0.6085 - val_accuracy: 0.8530 - val_f1_score: 0.6896 - val_precision_10: 0.8402 - val_recall_10: 0.8719\n",
      "Epoch 24/40\n",
      "50/50 [==============================] - 95s 2s/step - loss: 0.0044 - accuracy: 0.9986 - f1_score: 0.7019 - precision_10: 0.9984 - recall_10: 0.9988 - val_loss: 0.6382 - val_accuracy: 0.8543 - val_f1_score: 0.6970 - val_precision_10: 0.8513 - val_recall_10: 0.8586\n",
      "Epoch 25/40\n",
      "50/50 [==============================] - 94s 2s/step - loss: 0.0029 - accuracy: 0.9991 - f1_score: 0.7076 - precision_10: 0.9994 - recall_10: 0.9988 - val_loss: 0.5985 - val_accuracy: 0.8516 - val_f1_score: 0.6860 - val_precision_10: 0.8290 - val_recall_10: 0.8860\n",
      "Epoch 26/40\n",
      "50/50 [==============================] - 94s 2s/step - loss: 8.8495e-04 - accuracy: 0.9999 - f1_score: 0.7099 - precision_10: 0.9998 - recall_10: 1.0000 - val_loss: 0.8738 - val_accuracy: 0.8305 - val_f1_score: 0.7313 - val_precision_10: 0.9152 - val_recall_10: 0.7285\n",
      "Epoch 27/40\n",
      "50/50 [==============================] - 97s 2s/step - loss: 0.0025 - accuracy: 0.9994 - f1_score: 0.7076 - precision_10: 0.9993 - recall_10: 0.9996 - val_loss: 0.6607 - val_accuracy: 0.8551 - val_f1_score: 0.7020 - val_precision_10: 0.8522 - val_recall_10: 0.8593\n",
      "Epoch 28/40\n",
      "50/50 [==============================] - 99s 2s/step - loss: 0.0018 - accuracy: 0.9995 - f1_score: 0.7137 - precision_10: 0.9996 - recall_10: 0.9994 - val_loss: 0.6799 - val_accuracy: 0.8548 - val_f1_score: 0.7056 - val_precision_10: 0.8541 - val_recall_10: 0.8558\n",
      "Epoch 29/40\n",
      "50/50 [==============================] - 97s 2s/step - loss: 0.0010 - accuracy: 0.9997 - f1_score: 0.7183 - precision_10: 0.9997 - recall_10: 0.9998 - val_loss: 0.6751 - val_accuracy: 0.8528 - val_f1_score: 0.7062 - val_precision_10: 0.8611 - val_recall_10: 0.8414\n",
      "Epoch 30/40\n",
      "50/50 [==============================] - 92s 2s/step - loss: 0.0048 - accuracy: 0.9982 - f1_score: 0.7189 - precision_10: 0.9985 - recall_10: 0.9979 - val_loss: 0.6144 - val_accuracy: 0.8526 - val_f1_score: 0.6919 - val_precision_10: 0.8487 - val_recall_10: 0.8582\n",
      "Epoch 31/40\n",
      "50/50 [==============================] - 114s 2s/step - loss: 6.1296e-04 - accuracy: 0.9999 - f1_score: 0.7156 - precision_10: 0.9999 - recall_10: 0.9998 - val_loss: 0.7039 - val_accuracy: 0.8544 - val_f1_score: 0.7046 - val_precision_10: 0.8422 - val_recall_10: 0.8722\n",
      "Epoch 32/40\n",
      "50/50 [==============================] - 113s 2s/step - loss: 0.0030 - accuracy: 0.9988 - f1_score: 0.7174 - precision_10: 0.9989 - recall_10: 0.9988 - val_loss: 0.7049 - val_accuracy: 0.8530 - val_f1_score: 0.7071 - val_precision_10: 0.8509 - val_recall_10: 0.8561\n",
      "Epoch 33/40\n",
      "50/50 [==============================] - 108s 2s/step - loss: 6.5128e-04 - accuracy: 0.9998 - f1_score: 0.7268 - precision_10: 0.9999 - recall_10: 0.9998 - val_loss: 0.6564 - val_accuracy: 0.8543 - val_f1_score: 0.7027 - val_precision_10: 0.8581 - val_recall_10: 0.8489\n",
      "Epoch 34/40\n",
      "50/50 [==============================] - 108s 2s/step - loss: 6.8573e-04 - accuracy: 0.9999 - f1_score: 0.7245 - precision_10: 0.9998 - recall_10: 1.0000 - val_loss: 0.7067 - val_accuracy: 0.8550 - val_f1_score: 0.7107 - val_precision_10: 0.8558 - val_recall_10: 0.8538\n",
      "Epoch 35/40\n",
      "50/50 [==============================] - 102s 2s/step - loss: 0.0018 - accuracy: 0.9994 - f1_score: 0.7295 - precision_10: 0.9997 - recall_10: 0.9992 - val_loss: 0.9784 - val_accuracy: 0.7913 - val_f1_score: 0.6705 - val_precision_10: 0.7158 - val_recall_10: 0.9662\n",
      "Epoch 36/40\n",
      "50/50 [==============================] - 100s 2s/step - loss: 0.0019 - accuracy: 0.9996 - f1_score: 0.7171 - precision_10: 0.9993 - recall_10: 0.9999 - val_loss: 0.7409 - val_accuracy: 0.8535 - val_f1_score: 0.7114 - val_precision_10: 0.8487 - val_recall_10: 0.8603\n",
      "Epoch 37/40\n",
      "50/50 [==============================] - 98s 2s/step - loss: 0.0014 - accuracy: 0.9997 - f1_score: 0.7304 - precision_10: 0.9998 - recall_10: 0.9996 - val_loss: 0.7369 - val_accuracy: 0.8515 - val_f1_score: 0.7122 - val_precision_10: 0.8568 - val_recall_10: 0.8441\n",
      "Epoch 38/40\n",
      "50/50 [==============================] - 98s 2s/step - loss: 0.0011 - accuracy: 0.9998 - f1_score: 0.7348 - precision_10: 0.9998 - recall_10: 0.9998 - val_loss: 0.8609 - val_accuracy: 0.8405 - val_f1_score: 0.6966 - val_precision_10: 0.7945 - val_recall_10: 0.9187\n",
      "Epoch 39/40\n",
      "50/50 [==============================] - 93s 2s/step - loss: 5.4812e-04 - accuracy: 0.9999 - f1_score: 0.7275 - precision_10: 0.9999 - recall_10: 0.9999 - val_loss: 0.7533 - val_accuracy: 0.8519 - val_f1_score: 0.7181 - val_precision_10: 0.8587 - val_recall_10: 0.8423\n",
      "Epoch 40/40\n",
      "50/50 [==============================] - 96s 2s/step - loss: 3.8140e-04 - accuracy: 0.9999 - f1_score: 0.7393 - precision_10: 0.9999 - recall_10: 0.9999 - val_loss: 0.7478 - val_accuracy: 0.8539 - val_f1_score: 0.7151 - val_precision_10: 0.8508 - val_recall_10: 0.8583\n",
      "50/50 [==============================] - 23s 462ms/step - loss: 0.7478 - accuracy: 0.8539 - f1_score: 0.7151 - precision_10: 0.8508 - recall_10: 0.8583\n",
      "\n",
      "Test score: 0.747779130935669\n",
      "Test accuracy: 0.8539199829101562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 31s 39ms/step\n",
      "результат: 0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[0.4550272]]\n"
     ]
    }
   ],
   "source": [
    "model = build_model8()\n",
    "model.summary()\n",
    "model.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\", keras.metrics.F1Score(), keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "score = model.fit(X_train, y_train,\n",
    " epochs = EPOCHS,\n",
    " batch_size = BATCH_SIZE,\n",
    " validation_data = (X_test, y_test)\n",
    ")\n",
    "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save(\"imdb6.h5\")\n",
    "\n",
    "val = model.predict(X_train)\n",
    "print(f'результат: {np.argmax(val[0])}')\n",
    "word2index = imdb.get_word_index()\n",
    "test=[]\n",
    "for word in word_tokenize( \"i love this movie\"):\n",
    "     test.append(word2index[word])\n",
    "\n",
    "test=pad_sequences([test],maxlen=200)\n",
    "print(model.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 200, 128)          0         \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1428225 (5.45 MB)\n",
      "Trainable params: 1428225 (5.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "50/50 [==============================] - 54s 1s/step - loss: 0.6399 - accuracy: 0.6376 - f1_score: 0.6667 - precision_11: 0.6481 - recall_11: 0.6020 - val_loss: 0.5701 - val_accuracy: 0.6963 - val_f1_score: 0.6667 - val_precision_11: 0.9018 - val_recall_11: 0.4406\n",
      "Epoch 2/40\n",
      "50/50 [==============================] - 54s 1s/step - loss: 0.3839 - accuracy: 0.8315 - f1_score: 0.6667 - precision_11: 0.8392 - recall_11: 0.8202 - val_loss: 0.3213 - val_accuracy: 0.8668 - val_f1_score: 0.6667 - val_precision_11: 0.8486 - val_recall_11: 0.8930\n",
      "Epoch 3/40\n",
      "50/50 [==============================] - 54s 1s/step - loss: 0.2272 - accuracy: 0.9118 - f1_score: 0.6667 - precision_11: 0.9115 - recall_11: 0.9122 - val_loss: 0.3060 - val_accuracy: 0.8731 - val_f1_score: 0.6667 - val_precision_11: 0.8674 - val_recall_11: 0.8808\n",
      "Epoch 4/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.1761 - accuracy: 0.9360 - f1_score: 0.6667 - precision_11: 0.9350 - recall_11: 0.9372 - val_loss: 0.3412 - val_accuracy: 0.8689 - val_f1_score: 0.6667 - val_precision_11: 0.8534 - val_recall_11: 0.8908\n",
      "Epoch 5/40\n",
      "50/50 [==============================] - 52s 1s/step - loss: 0.1491 - accuracy: 0.9484 - f1_score: 0.6667 - precision_11: 0.9463 - recall_11: 0.9508 - val_loss: 0.3583 - val_accuracy: 0.8580 - val_f1_score: 0.6667 - val_precision_11: 0.8393 - val_recall_11: 0.8855\n",
      "Epoch 6/40\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.1172 - accuracy: 0.9601 - f1_score: 0.6667 - precision_11: 0.9610 - recall_11: 0.9591 - val_loss: 0.3910 - val_accuracy: 0.8490 - val_f1_score: 0.6667 - val_precision_11: 0.8582 - val_recall_11: 0.8362\n",
      "Epoch 7/40\n",
      "50/50 [==============================] - 52s 1s/step - loss: 0.1046 - accuracy: 0.9640 - f1_score: 0.6667 - precision_11: 0.9663 - recall_11: 0.9616 - val_loss: 0.4310 - val_accuracy: 0.8564 - val_f1_score: 0.6667 - val_precision_11: 0.8432 - val_recall_11: 0.8757\n",
      "Epoch 8/40\n",
      "50/50 [==============================] - 49s 978ms/step - loss: 0.0771 - accuracy: 0.9740 - f1_score: 0.6667 - precision_11: 0.9751 - recall_11: 0.9729 - val_loss: 0.4994 - val_accuracy: 0.8538 - val_f1_score: 0.6667 - val_precision_11: 0.8319 - val_recall_11: 0.8867\n",
      "Epoch 9/40\n",
      "50/50 [==============================] - 49s 993ms/step - loss: 0.0585 - accuracy: 0.9810 - f1_score: 0.6667 - precision_11: 0.9813 - recall_11: 0.9806 - val_loss: 0.6414 - val_accuracy: 0.8500 - val_f1_score: 0.6667 - val_precision_11: 0.8708 - val_recall_11: 0.8219\n",
      "Epoch 10/40\n",
      "50/50 [==============================] - 49s 987ms/step - loss: 0.0637 - accuracy: 0.9786 - f1_score: 0.6667 - precision_11: 0.9791 - recall_11: 0.9781 - val_loss: 0.5918 - val_accuracy: 0.8522 - val_f1_score: 0.6667 - val_precision_11: 0.8572 - val_recall_11: 0.8452\n",
      "Epoch 11/40\n",
      "50/50 [==============================] - 49s 979ms/step - loss: 0.0447 - accuracy: 0.9857 - f1_score: 0.6667 - precision_11: 0.9865 - recall_11: 0.9848 - val_loss: 0.5804 - val_accuracy: 0.8504 - val_f1_score: 0.6667 - val_precision_11: 0.8570 - val_recall_11: 0.8411\n",
      "Epoch 12/40\n",
      "50/50 [==============================] - 48s 974ms/step - loss: 0.0369 - accuracy: 0.9877 - f1_score: 0.6668 - precision_11: 0.9889 - recall_11: 0.9866 - val_loss: 0.6742 - val_accuracy: 0.8502 - val_f1_score: 0.6667 - val_precision_11: 0.8540 - val_recall_11: 0.8450\n",
      "Epoch 13/40\n",
      "50/50 [==============================] - 49s 989ms/step - loss: 0.0329 - accuracy: 0.9892 - f1_score: 0.6668 - precision_11: 0.9899 - recall_11: 0.9886 - val_loss: 0.8641 - val_accuracy: 0.8480 - val_f1_score: 0.6667 - val_precision_11: 0.8460 - val_recall_11: 0.8510\n",
      "Epoch 14/40\n",
      "50/50 [==============================] - 49s 988ms/step - loss: 0.0267 - accuracy: 0.9915 - f1_score: 0.6673 - precision_11: 0.9923 - recall_11: 0.9907 - val_loss: 0.7951 - val_accuracy: 0.8474 - val_f1_score: 0.6668 - val_precision_11: 0.8568 - val_recall_11: 0.8343\n",
      "Epoch 15/40\n",
      "50/50 [==============================] - 50s 1s/step - loss: 0.0216 - accuracy: 0.9938 - f1_score: 0.6684 - precision_11: 0.9943 - recall_11: 0.9932 - val_loss: 0.9198 - val_accuracy: 0.8468 - val_f1_score: 0.6678 - val_precision_11: 0.8617 - val_recall_11: 0.8262\n",
      "Epoch 16/40\n",
      "50/50 [==============================] - 49s 990ms/step - loss: 0.0241 - accuracy: 0.9920 - f1_score: 0.6692 - precision_11: 0.9928 - recall_11: 0.9912 - val_loss: 0.8458 - val_accuracy: 0.8470 - val_f1_score: 0.6673 - val_precision_11: 0.8505 - val_recall_11: 0.8422\n",
      "Epoch 17/40\n",
      "50/50 [==============================] - 49s 984ms/step - loss: 0.0300 - accuracy: 0.9901 - f1_score: 0.6684 - precision_11: 0.9905 - recall_11: 0.9897 - val_loss: 0.8015 - val_accuracy: 0.8420 - val_f1_score: 0.6668 - val_precision_11: 0.8675 - val_recall_11: 0.8074\n",
      "Epoch 18/40\n",
      "50/50 [==============================] - 49s 979ms/step - loss: 0.0307 - accuracy: 0.9895 - f1_score: 0.6679 - precision_11: 0.9902 - recall_11: 0.9888 - val_loss: 0.7845 - val_accuracy: 0.8423 - val_f1_score: 0.6668 - val_precision_11: 0.8553 - val_recall_11: 0.8240\n",
      "Epoch 19/40\n",
      "50/50 [==============================] - 48s 963ms/step - loss: 0.0171 - accuracy: 0.9945 - f1_score: 0.6693 - precision_11: 0.9944 - recall_11: 0.9946 - val_loss: 0.8542 - val_accuracy: 0.8439 - val_f1_score: 0.6678 - val_precision_11: 0.8470 - val_recall_11: 0.8394\n",
      "Epoch 20/40\n",
      "50/50 [==============================] - 50s 997ms/step - loss: 0.0140 - accuracy: 0.9958 - f1_score: 0.6725 - precision_11: 0.9957 - recall_11: 0.9959 - val_loss: 0.9904 - val_accuracy: 0.8427 - val_f1_score: 0.6702 - val_precision_11: 0.8494 - val_recall_11: 0.8330\n",
      "Epoch 21/40\n",
      "50/50 [==============================] - 50s 1s/step - loss: 0.0107 - accuracy: 0.9965 - f1_score: 0.6758 - precision_11: 0.9966 - recall_11: 0.9964 - val_loss: 1.1906 - val_accuracy: 0.8418 - val_f1_score: 0.6766 - val_precision_11: 0.8759 - val_recall_11: 0.7964\n",
      "Epoch 22/40\n",
      "50/50 [==============================] - 48s 965ms/step - loss: 0.0126 - accuracy: 0.9964 - f1_score: 0.6761 - precision_11: 0.9963 - recall_11: 0.9964 - val_loss: 1.1261 - val_accuracy: 0.8438 - val_f1_score: 0.6754 - val_precision_11: 0.8465 - val_recall_11: 0.8398\n",
      "Epoch 23/40\n",
      "50/50 [==============================] - 47s 953ms/step - loss: 0.0199 - accuracy: 0.9939 - f1_score: 0.6807 - precision_11: 0.9937 - recall_11: 0.9942 - val_loss: 1.0190 - val_accuracy: 0.8411 - val_f1_score: 0.6693 - val_precision_11: 0.8661 - val_recall_11: 0.8070\n",
      "Epoch 24/40\n",
      "50/50 [==============================] - 50s 998ms/step - loss: 0.0164 - accuracy: 0.9948 - f1_score: 0.6730 - precision_11: 0.9952 - recall_11: 0.9944 - val_loss: 1.1107 - val_accuracy: 0.8431 - val_f1_score: 0.6691 - val_precision_11: 0.8345 - val_recall_11: 0.8559\n",
      "Epoch 25/40\n",
      "50/50 [==============================] - 49s 979ms/step - loss: 0.0190 - accuracy: 0.9941 - f1_score: 0.6754 - precision_11: 0.9944 - recall_11: 0.9938 - val_loss: 1.1071 - val_accuracy: 0.8392 - val_f1_score: 0.6741 - val_precision_11: 0.8635 - val_recall_11: 0.8058\n",
      "Epoch 26/40\n",
      "50/50 [==============================] - 49s 997ms/step - loss: 0.0127 - accuracy: 0.9966 - f1_score: 0.6749 - precision_11: 0.9966 - recall_11: 0.9966 - val_loss: 1.1513 - val_accuracy: 0.8438 - val_f1_score: 0.6766 - val_precision_11: 0.8539 - val_recall_11: 0.8295\n",
      "Epoch 27/40\n",
      "50/50 [==============================] - 49s 981ms/step - loss: 0.0146 - accuracy: 0.9955 - f1_score: 0.6790 - precision_11: 0.9956 - recall_11: 0.9954 - val_loss: 1.0517 - val_accuracy: 0.8256 - val_f1_score: 0.6785 - val_precision_11: 0.8731 - val_recall_11: 0.7621\n",
      "Epoch 28/40\n",
      "50/50 [==============================] - 48s 958ms/step - loss: 0.0230 - accuracy: 0.9922 - f1_score: 0.6736 - precision_11: 0.9927 - recall_11: 0.9916 - val_loss: 1.0656 - val_accuracy: 0.8438 - val_f1_score: 0.6704 - val_precision_11: 0.8429 - val_recall_11: 0.8453\n",
      "Epoch 29/40\n",
      "50/50 [==============================] - 48s 965ms/step - loss: 0.0161 - accuracy: 0.9946 - f1_score: 0.6733 - precision_11: 0.9942 - recall_11: 0.9950 - val_loss: 1.0030 - val_accuracy: 0.8427 - val_f1_score: 0.6720 - val_precision_11: 0.8605 - val_recall_11: 0.8181\n",
      "Epoch 30/40\n",
      "50/50 [==============================] - 49s 987ms/step - loss: 0.0098 - accuracy: 0.9970 - f1_score: 0.6775 - precision_11: 0.9970 - recall_11: 0.9970 - val_loss: 1.0912 - val_accuracy: 0.8446 - val_f1_score: 0.6768 - val_precision_11: 0.8460 - val_recall_11: 0.8426\n",
      "Epoch 31/40\n",
      "50/50 [==============================] - 48s 967ms/step - loss: 0.0103 - accuracy: 0.9966 - f1_score: 0.6790 - precision_11: 0.9965 - recall_11: 0.9967 - val_loss: 1.1435 - val_accuracy: 0.8433 - val_f1_score: 0.6783 - val_precision_11: 0.8675 - val_recall_11: 0.8103\n",
      "Epoch 32/40\n",
      "50/50 [==============================] - 47s 954ms/step - loss: 0.0108 - accuracy: 0.9967 - f1_score: 0.6875 - precision_11: 0.9969 - recall_11: 0.9966 - val_loss: 1.1412 - val_accuracy: 0.8455 - val_f1_score: 0.6835 - val_precision_11: 0.8365 - val_recall_11: 0.8589\n",
      "Epoch 33/40\n",
      "50/50 [==============================] - 48s 968ms/step - loss: 0.0065 - accuracy: 0.9981 - f1_score: 0.6901 - precision_11: 0.9980 - recall_11: 0.9982 - val_loss: 1.1884 - val_accuracy: 0.8458 - val_f1_score: 0.6895 - val_precision_11: 0.8561 - val_recall_11: 0.8314\n",
      "Epoch 34/40\n",
      "50/50 [==============================] - 48s 968ms/step - loss: 0.0070 - accuracy: 0.9982 - f1_score: 0.6939 - precision_11: 0.9982 - recall_11: 0.9982 - val_loss: 1.2138 - val_accuracy: 0.8426 - val_f1_score: 0.6882 - val_precision_11: 0.8676 - val_recall_11: 0.8086\n",
      "Epoch 35/40\n",
      "50/50 [==============================] - 50s 1s/step - loss: 0.0069 - accuracy: 0.9981 - f1_score: 0.6995 - precision_11: 0.9981 - recall_11: 0.9981 - val_loss: 1.2952 - val_accuracy: 0.8476 - val_f1_score: 0.7040 - val_precision_11: 0.8479 - val_recall_11: 0.8472\n",
      "Epoch 36/40\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.0096 - accuracy: 0.9974 - f1_score: 0.6948 - precision_11: 0.9970 - recall_11: 0.9979 - val_loss: 1.1582 - val_accuracy: 0.8385 - val_f1_score: 0.6877 - val_precision_11: 0.8676 - val_recall_11: 0.7990\n",
      "Epoch 37/40\n",
      "50/50 [==============================] - 54s 1s/step - loss: 0.0458 - accuracy: 0.9847 - f1_score: 0.6733 - precision_11: 0.9859 - recall_11: 0.9835 - val_loss: 0.8787 - val_accuracy: 0.8464 - val_f1_score: 0.6674 - val_precision_11: 0.8382 - val_recall_11: 0.8585\n",
      "Epoch 38/40\n",
      "50/50 [==============================] - 53s 1s/step - loss: 0.0118 - accuracy: 0.9964 - f1_score: 0.6762 - precision_11: 0.9962 - recall_11: 0.9967 - val_loss: 0.9938 - val_accuracy: 0.8448 - val_f1_score: 0.6741 - val_precision_11: 0.8585 - val_recall_11: 0.8256\n",
      "Epoch 39/40\n",
      "50/50 [==============================] - 50s 1s/step - loss: 0.0043 - accuracy: 0.9989 - f1_score: 0.6841 - precision_11: 0.9989 - recall_11: 0.9989 - val_loss: 1.1692 - val_accuracy: 0.8459 - val_f1_score: 0.6843 - val_precision_11: 0.8394 - val_recall_11: 0.8554\n",
      "Epoch 40/40\n",
      "50/50 [==============================] - 50s 1s/step - loss: 0.0051 - accuracy: 0.9983 - f1_score: 0.6937 - precision_11: 0.9984 - recall_11: 0.9982 - val_loss: 1.2342 - val_accuracy: 0.8453 - val_f1_score: 0.6926 - val_precision_11: 0.8563 - val_recall_11: 0.8299\n",
      "50/50 [==============================] - 17s 334ms/step - loss: 1.2342 - accuracy: 0.8453 - f1_score: 0.6926 - precision_11: 0.8563 - recall_11: 0.8299\n",
      "\n",
      "Test score: 1.2342337369918823\n",
      "Test accuracy: 0.8453199863433838\n",
      "782/782 [==============================] - 35s 45ms/step\n",
      "результат: 0\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[0.00135965]]\n"
     ]
    }
   ],
   "source": [
    "model = build_model1()\n",
    "model.summary()\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\", keras.metrics.F1Score(), keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "score = model.fit(X_train, y_train,\n",
    " epochs = EPOCHS,\n",
    " batch_size = BATCH_SIZE,\n",
    " validation_data = (X_test, y_test)\n",
    ")\n",
    "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save(\"imdb1.h5\")\n",
    "\n",
    "val = model.predict(X_train)\n",
    "print(f'результат: {np.argmax(val[0])}')\n",
    "word2index = imdb.get_word_index()\n",
    "test=[]\n",
    "for word in word_tokenize( \"i love this movie\"):\n",
    "     test.append(word2index[word])\n",
    "\n",
    "test=pad_sequences([test],maxlen=200)\n",
    "print(model.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 200, 128)          0         \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirecti  (None, 256)               263168    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1576193 (6.01 MB)\n",
      "Trainable params: 1576193 (6.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "50/50 [==============================] - 69s 1s/step - loss: 0.6003 - accuracy: 0.6761 - f1_score: 0.6667 - precision_12: 0.6536 - recall_12: 0.7493 - val_loss: 0.3832 - val_accuracy: 0.8406 - val_f1_score: 0.6667 - val_precision_12: 0.8778 - val_recall_12: 0.7913\n",
      "Epoch 2/40\n",
      "50/50 [==============================] - 59s 1s/step - loss: 0.2893 - accuracy: 0.8835 - f1_score: 0.6667 - precision_12: 0.8848 - recall_12: 0.8819 - val_loss: 0.3039 - val_accuracy: 0.8732 - val_f1_score: 0.6667 - val_precision_12: 0.8864 - val_recall_12: 0.8562\n",
      "Epoch 3/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.2137 - accuracy: 0.9214 - f1_score: 0.6667 - precision_12: 0.9246 - recall_12: 0.9176 - val_loss: 0.3621 - val_accuracy: 0.8648 - val_f1_score: 0.6667 - val_precision_12: 0.8428 - val_recall_12: 0.8968\n",
      "Epoch 4/40\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.1626 - accuracy: 0.9425 - f1_score: 0.6667 - precision_12: 0.9445 - recall_12: 0.9402 - val_loss: 0.3407 - val_accuracy: 0.8650 - val_f1_score: 0.6667 - val_precision_12: 0.8575 - val_recall_12: 0.8756\n",
      "Epoch 5/40\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.1377 - accuracy: 0.9531 - f1_score: 0.6667 - precision_12: 0.9544 - recall_12: 0.9517 - val_loss: 0.3595 - val_accuracy: 0.8580 - val_f1_score: 0.6667 - val_precision_12: 0.8398 - val_recall_12: 0.8848\n",
      "Epoch 6/40\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.1203 - accuracy: 0.9597 - f1_score: 0.6667 - precision_12: 0.9601 - recall_12: 0.9592 - val_loss: 0.4111 - val_accuracy: 0.8556 - val_f1_score: 0.6667 - val_precision_12: 0.8900 - val_recall_12: 0.8114\n",
      "Epoch 7/40\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.0876 - accuracy: 0.9715 - f1_score: 0.6667 - precision_12: 0.9728 - recall_12: 0.9701 - val_loss: 0.4353 - val_accuracy: 0.8579 - val_f1_score: 0.6667 - val_precision_12: 0.8542 - val_recall_12: 0.8632\n",
      "Epoch 8/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.0692 - accuracy: 0.9770 - f1_score: 0.6667 - precision_12: 0.9792 - recall_12: 0.9747 - val_loss: 0.5060 - val_accuracy: 0.8486 - val_f1_score: 0.6667 - val_precision_12: 0.8815 - val_recall_12: 0.8055\n",
      "Epoch 9/40\n",
      "50/50 [==============================] - 54s 1s/step - loss: 0.0577 - accuracy: 0.9814 - f1_score: 0.6667 - precision_12: 0.9822 - recall_12: 0.9806 - val_loss: 0.5590 - val_accuracy: 0.8546 - val_f1_score: 0.6667 - val_precision_12: 0.8405 - val_recall_12: 0.8753\n",
      "Epoch 10/40\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.0490 - accuracy: 0.9847 - f1_score: 0.6667 - precision_12: 0.9862 - recall_12: 0.9831 - val_loss: 0.5633 - val_accuracy: 0.8382 - val_f1_score: 0.6667 - val_precision_12: 0.8858 - val_recall_12: 0.7765\n",
      "Epoch 11/40\n",
      "50/50 [==============================] - 54s 1s/step - loss: 0.0451 - accuracy: 0.9852 - f1_score: 0.6667 - precision_12: 0.9870 - recall_12: 0.9834 - val_loss: 0.6398 - val_accuracy: 0.8517 - val_f1_score: 0.6667 - val_precision_12: 0.8561 - val_recall_12: 0.8456\n",
      "Epoch 12/40\n",
      "50/50 [==============================] - 54s 1s/step - loss: 0.0382 - accuracy: 0.9882 - f1_score: 0.6667 - precision_12: 0.9894 - recall_12: 0.9870 - val_loss: 0.6138 - val_accuracy: 0.8481 - val_f1_score: 0.6667 - val_precision_12: 0.8264 - val_recall_12: 0.8814\n",
      "Epoch 13/40\n",
      "50/50 [==============================] - 58s 1s/step - loss: 0.0394 - accuracy: 0.9871 - f1_score: 0.6667 - precision_12: 0.9867 - recall_12: 0.9875 - val_loss: 0.7269 - val_accuracy: 0.8516 - val_f1_score: 0.6667 - val_precision_12: 0.8430 - val_recall_12: 0.8642\n",
      "Epoch 14/40\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.0196 - accuracy: 0.9940 - f1_score: 0.6670 - precision_12: 0.9947 - recall_12: 0.9932 - val_loss: 0.7516 - val_accuracy: 0.8508 - val_f1_score: 0.6667 - val_precision_12: 0.8527 - val_recall_12: 0.8480\n",
      "Epoch 15/40\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.0188 - accuracy: 0.9938 - f1_score: 0.6676 - precision_12: 0.9935 - recall_12: 0.9940 - val_loss: 0.8577 - val_accuracy: 0.8479 - val_f1_score: 0.6668 - val_precision_12: 0.8746 - val_recall_12: 0.8123\n",
      "Epoch 16/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.0202 - accuracy: 0.9936 - f1_score: 0.6682 - precision_12: 0.9947 - recall_12: 0.9925 - val_loss: 0.7899 - val_accuracy: 0.8489 - val_f1_score: 0.6668 - val_precision_12: 0.8404 - val_recall_12: 0.8614\n",
      "Epoch 17/40\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.0170 - accuracy: 0.9951 - f1_score: 0.6678 - precision_12: 0.9951 - recall_12: 0.9951 - val_loss: 1.0322 - val_accuracy: 0.8460 - val_f1_score: 0.6685 - val_precision_12: 0.8737 - val_recall_12: 0.8089\n",
      "Epoch 18/40\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.0261 - accuracy: 0.9916 - f1_score: 0.6676 - precision_12: 0.9916 - recall_12: 0.9916 - val_loss: 0.7491 - val_accuracy: 0.8358 - val_f1_score: 0.6667 - val_precision_12: 0.8729 - val_recall_12: 0.7862\n",
      "Epoch 19/40\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.0228 - accuracy: 0.9930 - f1_score: 0.6670 - precision_12: 0.9931 - recall_12: 0.9928 - val_loss: 0.8890 - val_accuracy: 0.8499 - val_f1_score: 0.6669 - val_precision_12: 0.8636 - val_recall_12: 0.8311\n",
      "Epoch 20/40\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.0182 - accuracy: 0.9944 - f1_score: 0.6679 - precision_12: 0.9952 - recall_12: 0.9937 - val_loss: 0.8641 - val_accuracy: 0.8494 - val_f1_score: 0.6669 - val_precision_12: 0.8383 - val_recall_12: 0.8658\n",
      "Epoch 21/40\n",
      "50/50 [==============================] - 54s 1s/step - loss: 0.0108 - accuracy: 0.9968 - f1_score: 0.6696 - precision_12: 0.9970 - recall_12: 0.9966 - val_loss: 0.9799 - val_accuracy: 0.8490 - val_f1_score: 0.6680 - val_precision_12: 0.8630 - val_recall_12: 0.8298\n",
      "Epoch 22/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.0088 - accuracy: 0.9977 - f1_score: 0.6742 - precision_12: 0.9982 - recall_12: 0.9973 - val_loss: 0.9461 - val_accuracy: 0.8435 - val_f1_score: 0.6703 - val_precision_12: 0.8606 - val_recall_12: 0.8198\n",
      "Epoch 23/40\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.0337 - accuracy: 0.9890 - f1_score: 0.6703 - precision_12: 0.9883 - recall_12: 0.9898 - val_loss: 0.7686 - val_accuracy: 0.8470 - val_f1_score: 0.6668 - val_precision_12: 0.8263 - val_recall_12: 0.8786\n",
      "Epoch 24/40\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.0165 - accuracy: 0.9950 - f1_score: 0.6698 - precision_12: 0.9950 - recall_12: 0.9950 - val_loss: 0.9445 - val_accuracy: 0.8464 - val_f1_score: 0.6708 - val_precision_12: 0.8464 - val_recall_12: 0.8466\n",
      "Epoch 25/40\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.0186 - accuracy: 0.9940 - f1_score: 0.6764 - precision_12: 0.9933 - recall_12: 0.9946 - val_loss: 0.8552 - val_accuracy: 0.8452 - val_f1_score: 0.6695 - val_precision_12: 0.8607 - val_recall_12: 0.8237\n",
      "Epoch 26/40\n",
      "50/50 [==============================] - 72s 1s/step - loss: 0.0120 - accuracy: 0.9963 - f1_score: 0.6715 - precision_12: 0.9963 - recall_12: 0.9962 - val_loss: 0.9067 - val_accuracy: 0.8503 - val_f1_score: 0.6695 - val_precision_12: 0.8531 - val_recall_12: 0.8464\n",
      "Epoch 27/40\n",
      "50/50 [==============================] - 67s 1s/step - loss: 0.0066 - accuracy: 0.9977 - f1_score: 0.6787 - precision_12: 0.9978 - recall_12: 0.9976 - val_loss: 1.0863 - val_accuracy: 0.8504 - val_f1_score: 0.6791 - val_precision_12: 0.8489 - val_recall_12: 0.8526\n",
      "Epoch 28/40\n",
      "50/50 [==============================] - 66s 1s/step - loss: 0.0083 - accuracy: 0.9974 - f1_score: 0.6839 - precision_12: 0.9976 - recall_12: 0.9972 - val_loss: 1.0572 - val_accuracy: 0.8468 - val_f1_score: 0.6779 - val_precision_12: 0.8677 - val_recall_12: 0.8183\n",
      "Epoch 29/40\n",
      "50/50 [==============================] - 66s 1s/step - loss: 0.0096 - accuracy: 0.9971 - f1_score: 0.6805 - precision_12: 0.9971 - recall_12: 0.9970 - val_loss: 1.0465 - val_accuracy: 0.8485 - val_f1_score: 0.6730 - val_precision_12: 0.8299 - val_recall_12: 0.8766\n",
      "Epoch 30/40\n",
      "50/50 [==============================] - 66s 1s/step - loss: 0.0072 - accuracy: 0.9976 - f1_score: 0.6823 - precision_12: 0.9974 - recall_12: 0.9977 - val_loss: 1.1048 - val_accuracy: 0.8464 - val_f1_score: 0.6816 - val_precision_12: 0.8585 - val_recall_12: 0.8296\n",
      "Epoch 31/40\n",
      "50/50 [==============================] - 65s 1s/step - loss: 0.0050 - accuracy: 0.9986 - f1_score: 0.6896 - precision_12: 0.9986 - recall_12: 0.9986 - val_loss: 1.2535 - val_accuracy: 0.8428 - val_f1_score: 0.6912 - val_precision_12: 0.8793 - val_recall_12: 0.7946\n",
      "Epoch 32/40\n",
      "50/50 [==============================] - 66s 1s/step - loss: 0.0085 - accuracy: 0.9972 - f1_score: 0.6834 - precision_12: 0.9970 - recall_12: 0.9974 - val_loss: 1.0657 - val_accuracy: 0.8409 - val_f1_score: 0.6793 - val_precision_12: 0.8655 - val_recall_12: 0.8073\n",
      "Epoch 33/40\n",
      "50/50 [==============================] - 66s 1s/step - loss: 0.0080 - accuracy: 0.9977 - f1_score: 0.6826 - precision_12: 0.9980 - recall_12: 0.9974 - val_loss: 1.1308 - val_accuracy: 0.8454 - val_f1_score: 0.6751 - val_precision_12: 0.8307 - val_recall_12: 0.8677\n",
      "Epoch 34/40\n",
      "50/50 [==============================] - 63s 1s/step - loss: 0.0042 - accuracy: 0.9987 - f1_score: 0.6838 - precision_12: 0.9984 - recall_12: 0.9990 - val_loss: 1.0891 - val_accuracy: 0.8472 - val_f1_score: 0.6771 - val_precision_12: 0.8498 - val_recall_12: 0.8435\n",
      "Epoch 35/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.0103 - accuracy: 0.9966 - f1_score: 0.6867 - precision_12: 0.9957 - recall_12: 0.9974 - val_loss: 1.1863 - val_accuracy: 0.8479 - val_f1_score: 0.6876 - val_precision_12: 0.8603 - val_recall_12: 0.8306\n",
      "Epoch 36/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.0100 - accuracy: 0.9969 - f1_score: 0.6782 - precision_12: 0.9974 - recall_12: 0.9964 - val_loss: 1.0302 - val_accuracy: 0.8421 - val_f1_score: 0.6746 - val_precision_12: 0.8674 - val_recall_12: 0.8077\n",
      "Epoch 37/40\n",
      "50/50 [==============================] - 53s 1s/step - loss: 0.0110 - accuracy: 0.9963 - f1_score: 0.6769 - precision_12: 0.9965 - recall_12: 0.9961 - val_loss: 1.0965 - val_accuracy: 0.8473 - val_f1_score: 0.6789 - val_precision_12: 0.8737 - val_recall_12: 0.8119\n",
      "Epoch 38/40\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.0069 - accuracy: 0.9983 - f1_score: 0.6815 - precision_12: 0.9987 - recall_12: 0.9978 - val_loss: 1.0746 - val_accuracy: 0.8430 - val_f1_score: 0.6771 - val_precision_12: 0.8630 - val_recall_12: 0.8154\n",
      "Epoch 39/40\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.0076 - accuracy: 0.9975 - f1_score: 0.6810 - precision_12: 0.9979 - recall_12: 0.9970 - val_loss: 1.1041 - val_accuracy: 0.8465 - val_f1_score: 0.6811 - val_precision_12: 0.8458 - val_recall_12: 0.8475\n",
      "Epoch 40/40\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.0055 - accuracy: 0.9982 - f1_score: 0.6919 - precision_12: 0.9982 - recall_12: 0.9982 - val_loss: 1.1320 - val_accuracy: 0.8472 - val_f1_score: 0.6780 - val_precision_12: 0.8375 - val_recall_12: 0.8616\n",
      "50/50 [==============================] - 16s 320ms/step - loss: 1.1320 - accuracy: 0.8472 - f1_score: 0.6780 - precision_12: 0.8375 - recall_12: 0.8616\n",
      "\n",
      "Test score: 1.1319948434829712\n",
      "Test accuracy: 0.8472399711608887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 44s 56ms/step\n",
      "результат: 0\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[[0.01304642]]\n"
     ]
    }
   ],
   "source": [
    "model = build_model2()\n",
    "model.summary()\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\", keras.metrics.F1Score(), keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "score = model.fit(X_train, y_train,\n",
    " epochs = EPOCHS,\n",
    " batch_size = BATCH_SIZE,\n",
    " validation_data = (X_test, y_test)\n",
    ")\n",
    "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save(\"imdb2.h5\")\n",
    "\n",
    "val = model.predict(X_train)\n",
    "print(f'результат: {np.argmax(val[0])}')\n",
    "word2index = imdb.get_word_index()\n",
    "test=[]\n",
    "for word in word_tokenize( \"i love this movie\"):\n",
    "     test.append(word2index[word])\n",
    "\n",
    "test=pad_sequences([test],maxlen=200)\n",
    "print(model.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_13 (Embedding)    (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 200, 128)          0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 200, 128)          131584    \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1428225 (5.45 MB)\n",
      "Trainable params: 1428225 (5.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "50/50 [==============================] - 54s 1s/step - loss: 0.6520 - accuracy: 0.6299 - f1_score: 0.6667 - precision_13: 0.6174 - recall_13: 0.6828 - val_loss: 0.4981 - val_accuracy: 0.7518 - val_f1_score: 0.6667 - val_precision_13: 0.6823 - val_recall_13: 0.9422\n",
      "Epoch 2/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.3361 - accuracy: 0.8593 - f1_score: 0.6667 - precision_13: 0.8499 - recall_13: 0.8727 - val_loss: 0.3183 - val_accuracy: 0.8656 - val_f1_score: 0.6667 - val_precision_13: 0.8530 - val_recall_13: 0.8836\n",
      "Epoch 3/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.2303 - accuracy: 0.9119 - f1_score: 0.6667 - precision_13: 0.9097 - recall_13: 0.9146 - val_loss: 0.3354 - val_accuracy: 0.8601 - val_f1_score: 0.6667 - val_precision_13: 0.8537 - val_recall_13: 0.8690\n",
      "Epoch 4/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.1736 - accuracy: 0.9378 - f1_score: 0.6667 - precision_13: 0.9369 - recall_13: 0.9388 - val_loss: 0.3582 - val_accuracy: 0.8570 - val_f1_score: 0.6667 - val_precision_13: 0.8575 - val_recall_13: 0.8562\n",
      "Epoch 5/40\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.1404 - accuracy: 0.9508 - f1_score: 0.6667 - precision_13: 0.9502 - recall_13: 0.9514 - val_loss: 0.4252 - val_accuracy: 0.8513 - val_f1_score: 0.6667 - val_precision_13: 0.8637 - val_recall_13: 0.8342\n",
      "Epoch 6/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.1156 - accuracy: 0.9601 - f1_score: 0.6667 - precision_13: 0.9607 - recall_13: 0.9594 - val_loss: 0.4280 - val_accuracy: 0.8481 - val_f1_score: 0.6667 - val_precision_13: 0.8422 - val_recall_13: 0.8567\n",
      "Epoch 7/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.0885 - accuracy: 0.9722 - f1_score: 0.6667 - precision_13: 0.9721 - recall_13: 0.9722 - val_loss: 0.4960 - val_accuracy: 0.8457 - val_f1_score: 0.6667 - val_precision_13: 0.8374 - val_recall_13: 0.8579\n",
      "Epoch 8/40\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.0744 - accuracy: 0.9779 - f1_score: 0.6667 - precision_13: 0.9775 - recall_13: 0.9782 - val_loss: 0.6025 - val_accuracy: 0.8402 - val_f1_score: 0.6667 - val_precision_13: 0.8629 - val_recall_13: 0.8089\n",
      "Epoch 9/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.0617 - accuracy: 0.9805 - f1_score: 0.6667 - precision_13: 0.9806 - recall_13: 0.9805 - val_loss: 0.6240 - val_accuracy: 0.8385 - val_f1_score: 0.6667 - val_precision_13: 0.8301 - val_recall_13: 0.8513\n",
      "Epoch 10/40\n",
      "50/50 [==============================] - 54s 1s/step - loss: 0.0563 - accuracy: 0.9828 - f1_score: 0.6667 - precision_13: 0.9824 - recall_13: 0.9831 - val_loss: 0.6294 - val_accuracy: 0.8380 - val_f1_score: 0.6667 - val_precision_13: 0.8426 - val_recall_13: 0.8311\n",
      "Epoch 11/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.0422 - accuracy: 0.9876 - f1_score: 0.6667 - precision_13: 0.9871 - recall_13: 0.9881 - val_loss: 0.7415 - val_accuracy: 0.8338 - val_f1_score: 0.6667 - val_precision_13: 0.8233 - val_recall_13: 0.8501\n",
      "Epoch 12/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.0358 - accuracy: 0.9895 - f1_score: 0.6669 - precision_13: 0.9892 - recall_13: 0.9898 - val_loss: 0.7759 - val_accuracy: 0.8339 - val_f1_score: 0.6667 - val_precision_13: 0.8269 - val_recall_13: 0.8447\n",
      "Epoch 13/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.0401 - accuracy: 0.9874 - f1_score: 0.6669 - precision_13: 0.9870 - recall_13: 0.9878 - val_loss: 0.7533 - val_accuracy: 0.8354 - val_f1_score: 0.6667 - val_precision_13: 0.8261 - val_recall_13: 0.8498\n",
      "Epoch 14/40\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.0299 - accuracy: 0.9915 - f1_score: 0.6671 - precision_13: 0.9914 - recall_13: 0.9916 - val_loss: 0.8480 - val_accuracy: 0.8358 - val_f1_score: 0.6667 - val_precision_13: 0.8362 - val_recall_13: 0.8352\n",
      "Epoch 15/40\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.0283 - accuracy: 0.9915 - f1_score: 0.6673 - precision_13: 0.9912 - recall_13: 0.9918 - val_loss: 0.8033 - val_accuracy: 0.8353 - val_f1_score: 0.6667 - val_precision_13: 0.8291 - val_recall_13: 0.8447\n",
      "Epoch 16/40\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.0210 - accuracy: 0.9941 - f1_score: 0.6676 - precision_13: 0.9946 - recall_13: 0.9935 - val_loss: 0.9289 - val_accuracy: 0.8330 - val_f1_score: 0.6667 - val_precision_13: 0.8350 - val_recall_13: 0.8301\n",
      "Epoch 17/40\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.0212 - accuracy: 0.9934 - f1_score: 0.6683 - precision_13: 0.9940 - recall_13: 0.9928 - val_loss: 0.8581 - val_accuracy: 0.8330 - val_f1_score: 0.6667 - val_precision_13: 0.8303 - val_recall_13: 0.8370\n",
      "Epoch 18/40\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.0206 - accuracy: 0.9929 - f1_score: 0.6679 - precision_13: 0.9928 - recall_13: 0.9930 - val_loss: 0.9402 - val_accuracy: 0.8317 - val_f1_score: 0.6667 - val_precision_13: 0.8292 - val_recall_13: 0.8355\n",
      "Epoch 19/40\n",
      "50/50 [==============================] - 50s 1s/step - loss: 0.0207 - accuracy: 0.9929 - f1_score: 0.6687 - precision_13: 0.9934 - recall_13: 0.9923 - val_loss: 0.9321 - val_accuracy: 0.8350 - val_f1_score: 0.6668 - val_precision_13: 0.8306 - val_recall_13: 0.8417\n",
      "Epoch 20/40\n",
      "50/50 [==============================] - 52s 1s/step - loss: 0.0182 - accuracy: 0.9942 - f1_score: 0.6699 - precision_13: 0.9943 - recall_13: 0.9941 - val_loss: 1.0033 - val_accuracy: 0.8289 - val_f1_score: 0.6674 - val_precision_13: 0.8577 - val_recall_13: 0.7887\n",
      "Epoch 21/40\n",
      "50/50 [==============================] - 52s 1s/step - loss: 0.0176 - accuracy: 0.9949 - f1_score: 0.6709 - precision_13: 0.9945 - recall_13: 0.9953 - val_loss: 0.8681 - val_accuracy: 0.8311 - val_f1_score: 0.6667 - val_precision_13: 0.8246 - val_recall_13: 0.8410\n",
      "Epoch 22/40\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.0142 - accuracy: 0.9958 - f1_score: 0.6693 - precision_13: 0.9960 - recall_13: 0.9957 - val_loss: 1.0726 - val_accuracy: 0.8345 - val_f1_score: 0.6679 - val_precision_13: 0.8359 - val_recall_13: 0.8324\n",
      "Epoch 23/40\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.0124 - accuracy: 0.9962 - f1_score: 0.6726 - precision_13: 0.9962 - recall_13: 0.9962 - val_loss: 1.0402 - val_accuracy: 0.8334 - val_f1_score: 0.6690 - val_precision_13: 0.8203 - val_recall_13: 0.8540\n",
      "Epoch 24/40\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.0161 - accuracy: 0.9952 - f1_score: 0.6759 - precision_13: 0.9950 - recall_13: 0.9953 - val_loss: 1.1395 - val_accuracy: 0.8269 - val_f1_score: 0.6688 - val_precision_13: 0.8700 - val_recall_13: 0.7687\n",
      "Epoch 25/40\n",
      "50/50 [==============================] - 50s 1s/step - loss: 0.0200 - accuracy: 0.9939 - f1_score: 0.6722 - precision_13: 0.9938 - recall_13: 0.9941 - val_loss: 0.9860 - val_accuracy: 0.8344 - val_f1_score: 0.6678 - val_precision_13: 0.8540 - val_recall_13: 0.8067\n",
      "Epoch 26/40\n",
      "50/50 [==============================] - 49s 995ms/step - loss: 0.0091 - accuracy: 0.9975 - f1_score: 0.6754 - precision_13: 0.9975 - recall_13: 0.9975 - val_loss: 1.0638 - val_accuracy: 0.8333 - val_f1_score: 0.6717 - val_precision_13: 0.8501 - val_recall_13: 0.8092\n",
      "Epoch 27/40\n",
      "50/50 [==============================] - 49s 995ms/step - loss: 0.0099 - accuracy: 0.9975 - f1_score: 0.6801 - precision_13: 0.9974 - recall_13: 0.9975 - val_loss: 1.1752 - val_accuracy: 0.8358 - val_f1_score: 0.6768 - val_precision_13: 0.8550 - val_recall_13: 0.8088\n",
      "Epoch 28/40\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.0089 - accuracy: 0.9974 - f1_score: 0.6835 - precision_13: 0.9974 - recall_13: 0.9974 - val_loss: 1.1665 - val_accuracy: 0.8353 - val_f1_score: 0.6758 - val_precision_13: 0.8423 - val_recall_13: 0.8250\n",
      "Epoch 29/40\n",
      "50/50 [==============================] - 52s 1s/step - loss: 0.0112 - accuracy: 0.9965 - f1_score: 0.6847 - precision_13: 0.9965 - recall_13: 0.9966 - val_loss: 1.0767 - val_accuracy: 0.8381 - val_f1_score: 0.6747 - val_precision_13: 0.8492 - val_recall_13: 0.8223\n",
      "Epoch 30/40\n",
      "50/50 [==============================] - 54s 1s/step - loss: 0.0095 - accuracy: 0.9974 - f1_score: 0.6853 - precision_13: 0.9972 - recall_13: 0.9975 - val_loss: 1.0658 - val_accuracy: 0.8348 - val_f1_score: 0.6722 - val_precision_13: 0.8373 - val_recall_13: 0.8312\n",
      "Epoch 31/40\n",
      "50/50 [==============================] - 53s 1s/step - loss: 0.0084 - accuracy: 0.9978 - f1_score: 0.6886 - precision_13: 0.9975 - recall_13: 0.9980 - val_loss: 1.1644 - val_accuracy: 0.8355 - val_f1_score: 0.6817 - val_precision_13: 0.8513 - val_recall_13: 0.8130\n",
      "Epoch 32/40\n",
      "50/50 [==============================] - 52s 1s/step - loss: 0.0068 - accuracy: 0.9983 - f1_score: 0.6910 - precision_13: 0.9984 - recall_13: 0.9982 - val_loss: 1.2334 - val_accuracy: 0.8341 - val_f1_score: 0.6821 - val_precision_13: 0.8221 - val_recall_13: 0.8527\n",
      "Epoch 33/40\n",
      "50/50 [==============================] - 53s 1s/step - loss: 0.0103 - accuracy: 0.9970 - f1_score: 0.6937 - precision_13: 0.9970 - recall_13: 0.9970 - val_loss: 1.1769 - val_accuracy: 0.8351 - val_f1_score: 0.6842 - val_precision_13: 0.8464 - val_recall_13: 0.8187\n",
      "Epoch 34/40\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.0069 - accuracy: 0.9979 - f1_score: 0.6980 - precision_13: 0.9978 - recall_13: 0.9979 - val_loss: 1.2933 - val_accuracy: 0.8329 - val_f1_score: 0.7007 - val_precision_13: 0.8564 - val_recall_13: 0.7999\n",
      "Epoch 35/40\n",
      "50/50 [==============================] - 59s 1s/step - loss: 0.0077 - accuracy: 0.9974 - f1_score: 0.7008 - precision_13: 0.9972 - recall_13: 0.9976 - val_loss: 1.1051 - val_accuracy: 0.8332 - val_f1_score: 0.6829 - val_precision_13: 0.8414 - val_recall_13: 0.8212\n",
      "Epoch 36/40\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.0079 - accuracy: 0.9976 - f1_score: 0.6981 - precision_13: 0.9975 - recall_13: 0.9977 - val_loss: 1.2286 - val_accuracy: 0.8298 - val_f1_score: 0.6792 - val_precision_13: 0.8044 - val_recall_13: 0.8714\n",
      "Epoch 37/40\n",
      "50/50 [==============================] - 50s 1s/step - loss: 0.0141 - accuracy: 0.9951 - f1_score: 0.6916 - precision_13: 0.9946 - recall_13: 0.9956 - val_loss: 1.1723 - val_accuracy: 0.8337 - val_f1_score: 0.6884 - val_precision_13: 0.8590 - val_recall_13: 0.7985\n",
      "Epoch 38/40\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.0101 - accuracy: 0.9966 - f1_score: 0.6981 - precision_13: 0.9966 - recall_13: 0.9966 - val_loss: 1.1038 - val_accuracy: 0.8331 - val_f1_score: 0.6771 - val_precision_13: 0.8230 - val_recall_13: 0.8486\n",
      "Epoch 39/40\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.0091 - accuracy: 0.9970 - f1_score: 0.6911 - precision_13: 0.9969 - recall_13: 0.9972 - val_loss: 1.1815 - val_accuracy: 0.8357 - val_f1_score: 0.6938 - val_precision_13: 0.8572 - val_recall_13: 0.8055\n",
      "Epoch 40/40\n",
      "50/50 [==============================] - 52s 1s/step - loss: 0.0053 - accuracy: 0.9984 - f1_score: 0.7012 - precision_13: 0.9986 - recall_13: 0.9983 - val_loss: 1.2608 - val_accuracy: 0.8371 - val_f1_score: 0.6965 - val_precision_13: 0.8371 - val_recall_13: 0.8371\n",
      "50/50 [==============================] - 18s 354ms/step - loss: 1.2608 - accuracy: 0.8371 - f1_score: 0.6965 - precision_13: 0.8371 - recall_13: 0.8371\n",
      "\n",
      "Test score: 1.2608129978179932\n",
      "Test accuracy: 0.837119996547699\n",
      "782/782 [==============================] - 36s 46ms/step\n",
      "результат: 0\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[[0.3120654]]\n"
     ]
    }
   ],
   "source": [
    "model = build_model3()\n",
    "model.summary()\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\", keras.metrics.F1Score(), keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "score = model.fit(X_train, y_train,\n",
    " epochs = EPOCHS,\n",
    " batch_size = BATCH_SIZE,\n",
    " validation_data = (X_test, y_test)\n",
    ")\n",
    "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save(\"imdb2.h5\")\n",
    "\n",
    "val = model.predict(X_train)\n",
    "print(f'результат: {np.argmax(val[0])}')\n",
    "word2index = imdb.get_word_index()\n",
    "test=[]\n",
    "for word in word_tokenize( \"i love this movie\"):\n",
    "     test.append(word2index[word])\n",
    "\n",
    "test=pad_sequences([test],maxlen=200)\n",
    "print(model.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_14 (Embedding)    (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1411713 (5.39 MB)\n",
      "Trainable params: 1411713 (5.39 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "50/50 [==============================] - 43s 852ms/step - loss: nan - accuracy: 0.5610 - f1_score: 0.5274 - precision_14: 0.6357 - recall_14: 0.2860 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 2/40\n",
      "50/50 [==============================] - 40s 800ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 3/40\n",
      "50/50 [==============================] - 39s 792ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 4/40\n",
      "50/50 [==============================] - 39s 795ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 5/40\n",
      "50/50 [==============================] - 45s 901ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 6/40\n",
      "50/50 [==============================] - 47s 944ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 7/40\n",
      "50/50 [==============================] - 47s 946ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 8/40\n",
      "50/50 [==============================] - 45s 898ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 9/40\n",
      "50/50 [==============================] - 42s 850ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 10/40\n",
      "50/50 [==============================] - 42s 836ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 11/40\n",
      "50/50 [==============================] - 43s 867ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 12/40\n",
      "50/50 [==============================] - 42s 850ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 13/40\n",
      "50/50 [==============================] - 44s 895ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 14/40\n",
      "50/50 [==============================] - 46s 927ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 15/40\n",
      "50/50 [==============================] - 42s 843ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 16/40\n",
      "50/50 [==============================] - 40s 806ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 17/40\n",
      "50/50 [==============================] - 43s 875ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 18/40\n",
      "50/50 [==============================] - 43s 865ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 19/40\n",
      "50/50 [==============================] - 40s 806ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 20/40\n",
      "50/50 [==============================] - 40s 796ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 21/40\n",
      "50/50 [==============================] - 40s 811ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 22/40\n",
      "50/50 [==============================] - 43s 863ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 23/40\n",
      "50/50 [==============================] - 41s 832ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 24/40\n",
      "50/50 [==============================] - 42s 841ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 25/40\n",
      "50/50 [==============================] - 41s 833ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 26/40\n",
      "50/50 [==============================] - 40s 809ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 27/40\n",
      "50/50 [==============================] - 40s 804ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 28/40\n",
      "50/50 [==============================] - 38s 771ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 29/40\n",
      "50/50 [==============================] - 39s 796ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 30/40\n",
      "50/50 [==============================] - 40s 798ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 31/40\n",
      "50/50 [==============================] - 40s 796ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 32/40\n",
      "50/50 [==============================] - 39s 784ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 33/40\n",
      "50/50 [==============================] - 40s 811ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 34/40\n",
      "50/50 [==============================] - 42s 848ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 35/40\n",
      "50/50 [==============================] - 40s 796ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 36/40\n",
      "50/50 [==============================] - 41s 828ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 37/40\n",
      "50/50 [==============================] - 41s 820ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 38/40\n",
      "50/50 [==============================] - 41s 827ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 39/40\n",
      "50/50 [==============================] - 40s 801ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 40/40\n",
      "50/50 [==============================] - 41s 820ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: nan - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "50/50 [==============================] - 16s 324ms/step - loss: nan - accuracy: 0.5000 - f1_score: 0.0000e+00 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00\n",
      "\n",
      "Test score: nan\n",
      "Test accuracy: 0.5\n",
      "782/782 [==============================] - 61s 77ms/step\n",
      "результат: 0\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "[[nan]]\n"
     ]
    }
   ],
   "source": [
    "model = build_model4()\n",
    "model.summary()\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\", keras.metrics.F1Score(), keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "score = model.fit(X_train, y_train,\n",
    " epochs = EPOCHS,\n",
    " batch_size = BATCH_SIZE,\n",
    " validation_data = (X_test, y_test)\n",
    ")\n",
    "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save(\"imdb2.h5\")\n",
    "\n",
    "val = model.predict(X_train)\n",
    "print(f'результат: {np.argmax(val[0])}')\n",
    "word2index = imdb.get_word_index()\n",
    "test=[]\n",
    "for word in word_tokenize( \"i love this movie\"):\n",
    "     test.append(word2index[word])\n",
    "\n",
    "test=pad_sequences([test],maxlen=200)\n",
    "print(model.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_15 (Embedding)    (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirecti  (None, 128)               74496     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1354625 (5.17 MB)\n",
      "Trainable params: 1354625 (5.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "50/50 [==============================] - 39s 751ms/step - loss: 0.6690 - accuracy: 0.6007 - f1_score: 0.6667 - precision_15: 0.5957 - recall_15: 0.6271 - val_loss: 0.5077 - val_accuracy: 0.7722 - val_f1_score: 0.6667 - val_precision_15: 0.7532 - val_recall_15: 0.8098\n",
      "Epoch 2/40\n",
      "50/50 [==============================] - 36s 714ms/step - loss: 1.1083 - accuracy: 0.6664 - f1_score: 0.6684 - precision_15: 0.7815 - recall_15: 0.4621 - val_loss: 0.5772 - val_accuracy: 0.7102 - val_f1_score: 0.6667 - val_precision_15: 0.7604 - val_recall_15: 0.6137\n",
      "Epoch 3/40\n",
      "50/50 [==============================] - 45s 904ms/step - loss: 0.5249 - accuracy: 0.7724 - f1_score: 0.6667 - precision_15: 0.7857 - recall_15: 0.7492 - val_loss: 0.5326 - val_accuracy: 0.7411 - val_f1_score: 0.6667 - val_precision_15: 0.7294 - val_recall_15: 0.7666\n",
      "Epoch 4/40\n",
      "50/50 [==============================] - 44s 874ms/step - loss: 0.4922 - accuracy: 0.7778 - f1_score: 0.6667 - precision_15: 0.8456 - recall_15: 0.6798 - val_loss: 0.5164 - val_accuracy: 0.7398 - val_f1_score: 0.6667 - val_precision_15: 0.7725 - val_recall_15: 0.6798\n",
      "Epoch 5/40\n",
      "50/50 [==============================] - 45s 914ms/step - loss: 0.4220 - accuracy: 0.8195 - f1_score: 0.6703 - precision_15: 0.8316 - recall_15: 0.8014 - val_loss: 0.5363 - val_accuracy: 0.7741 - val_f1_score: 0.6667 - val_precision_15: 0.7302 - val_recall_15: 0.8694\n",
      "Epoch 6/40\n",
      "50/50 [==============================] - 48s 965ms/step - loss: 0.3936 - accuracy: 0.8360 - f1_score: 0.6667 - precision_15: 0.8647 - recall_15: 0.7966 - val_loss: 0.4687 - val_accuracy: 0.7704 - val_f1_score: 0.6667 - val_precision_15: 0.7937 - val_recall_15: 0.7306\n",
      "Epoch 7/40\n",
      "50/50 [==============================] - 43s 851ms/step - loss: 0.3211 - accuracy: 0.8698 - f1_score: 0.6698 - precision_15: 0.8781 - recall_15: 0.8589 - val_loss: 0.4392 - val_accuracy: 0.8216 - val_f1_score: 0.6764 - val_precision_15: 0.8287 - val_recall_15: 0.8108\n",
      "Epoch 8/40\n",
      "50/50 [==============================] - 42s 845ms/step - loss: 0.2446 - accuracy: 0.9060 - f1_score: 0.6680 - precision_15: 0.8958 - recall_15: 0.9190 - val_loss: 0.3703 - val_accuracy: 0.8392 - val_f1_score: 0.6668 - val_precision_15: 0.8546 - val_recall_15: 0.8176\n",
      "Epoch 9/40\n",
      "50/50 [==============================] - 40s 794ms/step - loss: 0.1866 - accuracy: 0.9273 - f1_score: 0.6670 - precision_15: 0.9263 - recall_15: 0.9285 - val_loss: 0.3741 - val_accuracy: 0.8508 - val_f1_score: 0.6670 - val_precision_15: 0.8564 - val_recall_15: 0.8430\n",
      "Epoch 10/40\n",
      "50/50 [==============================] - 42s 838ms/step - loss: 0.1470 - accuracy: 0.9446 - f1_score: 0.6677 - precision_15: 0.9454 - recall_15: 0.9437 - val_loss: 0.3899 - val_accuracy: 0.8505 - val_f1_score: 0.6673 - val_precision_15: 0.8479 - val_recall_15: 0.8542\n",
      "Epoch 11/40\n",
      "50/50 [==============================] - 44s 876ms/step - loss: 0.1139 - accuracy: 0.9590 - f1_score: 0.6704 - precision_15: 0.9596 - recall_15: 0.9583 - val_loss: 0.4584 - val_accuracy: 0.8441 - val_f1_score: 0.6715 - val_precision_15: 0.8749 - val_recall_15: 0.8031\n",
      "Epoch 12/40\n",
      "50/50 [==============================] - 40s 794ms/step - loss: 0.0894 - accuracy: 0.9696 - f1_score: 0.6764 - precision_15: 0.9704 - recall_15: 0.9687 - val_loss: 0.4695 - val_accuracy: 0.8468 - val_f1_score: 0.6707 - val_precision_15: 0.8428 - val_recall_15: 0.8525\n",
      "Epoch 13/40\n",
      "50/50 [==============================] - 40s 800ms/step - loss: 0.0714 - accuracy: 0.9767 - f1_score: 0.6781 - precision_15: 0.9794 - recall_15: 0.9739 - val_loss: 0.5433 - val_accuracy: 0.8314 - val_f1_score: 0.6778 - val_precision_15: 0.8788 - val_recall_15: 0.7689\n",
      "Epoch 14/40\n",
      "50/50 [==============================] - 41s 834ms/step - loss: 0.0642 - accuracy: 0.9789 - f1_score: 0.6856 - precision_15: 0.9806 - recall_15: 0.9771 - val_loss: 0.6600 - val_accuracy: 0.8434 - val_f1_score: 0.6908 - val_precision_15: 0.8518 - val_recall_15: 0.8315\n",
      "Epoch 15/40\n",
      "50/50 [==============================] - 40s 797ms/step - loss: 0.0468 - accuracy: 0.9859 - f1_score: 0.6940 - precision_15: 0.9884 - recall_15: 0.9834 - val_loss: 0.7331 - val_accuracy: 0.8415 - val_f1_score: 0.6940 - val_precision_15: 0.8486 - val_recall_15: 0.8312\n",
      "Epoch 16/40\n",
      "50/50 [==============================] - 40s 808ms/step - loss: 0.0421 - accuracy: 0.9878 - f1_score: 0.6990 - precision_15: 0.9886 - recall_15: 0.9869 - val_loss: 0.7623 - val_accuracy: 0.8410 - val_f1_score: 0.6909 - val_precision_15: 0.8332 - val_recall_15: 0.8526\n",
      "Epoch 17/40\n",
      "50/50 [==============================] - 43s 858ms/step - loss: 0.0344 - accuracy: 0.9901 - f1_score: 0.7025 - precision_15: 0.9919 - recall_15: 0.9883 - val_loss: 0.7542 - val_accuracy: 0.8391 - val_f1_score: 0.6947 - val_precision_15: 0.8464 - val_recall_15: 0.8286\n",
      "Epoch 18/40\n",
      "50/50 [==============================] - 42s 847ms/step - loss: 0.0275 - accuracy: 0.9928 - f1_score: 0.7097 - precision_15: 0.9935 - recall_15: 0.9921 - val_loss: 0.8450 - val_accuracy: 0.8333 - val_f1_score: 0.7068 - val_precision_15: 0.8600 - val_recall_15: 0.7963\n",
      "Epoch 19/40\n",
      "50/50 [==============================] - 40s 805ms/step - loss: 0.0245 - accuracy: 0.9937 - f1_score: 0.7162 - precision_15: 0.9942 - recall_15: 0.9932 - val_loss: 0.9882 - val_accuracy: 0.8375 - val_f1_score: 0.7174 - val_precision_15: 0.8437 - val_recall_15: 0.8285\n",
      "Epoch 20/40\n",
      "50/50 [==============================] - 42s 843ms/step - loss: 0.0251 - accuracy: 0.9933 - f1_score: 0.7123 - precision_15: 0.9942 - recall_15: 0.9925 - val_loss: 0.9241 - val_accuracy: 0.8324 - val_f1_score: 0.7152 - val_precision_15: 0.8638 - val_recall_15: 0.7893\n",
      "Epoch 21/40\n",
      "50/50 [==============================] - 39s 792ms/step - loss: 0.0242 - accuracy: 0.9937 - f1_score: 0.7211 - precision_15: 0.9949 - recall_15: 0.9924 - val_loss: 0.8874 - val_accuracy: 0.8296 - val_f1_score: 0.7128 - val_precision_15: 0.8724 - val_recall_15: 0.7721\n",
      "Epoch 22/40\n",
      "50/50 [==============================] - 39s 783ms/step - loss: 0.0202 - accuracy: 0.9950 - f1_score: 0.7213 - precision_15: 0.9955 - recall_15: 0.9944 - val_loss: 1.1782 - val_accuracy: 0.8320 - val_f1_score: 0.7421 - val_precision_15: 0.8660 - val_recall_15: 0.7855\n",
      "Epoch 23/40\n",
      "50/50 [==============================] - 40s 808ms/step - loss: 0.0165 - accuracy: 0.9961 - f1_score: 0.7281 - precision_15: 0.9963 - recall_15: 0.9959 - val_loss: 1.0632 - val_accuracy: 0.8357 - val_f1_score: 0.7121 - val_precision_15: 0.8449 - val_recall_15: 0.8225\n",
      "Epoch 24/40\n",
      "50/50 [==============================] - 42s 841ms/step - loss: 0.0146 - accuracy: 0.9966 - f1_score: 0.7121 - precision_15: 0.9966 - recall_15: 0.9965 - val_loss: 1.0690 - val_accuracy: 0.8356 - val_f1_score: 0.7151 - val_precision_15: 0.8474 - val_recall_15: 0.8186\n",
      "Epoch 25/40\n",
      "50/50 [==============================] - 41s 828ms/step - loss: 0.0115 - accuracy: 0.9976 - f1_score: 0.7188 - precision_15: 0.9977 - recall_15: 0.9976 - val_loss: 1.1625 - val_accuracy: 0.8343 - val_f1_score: 0.7255 - val_precision_15: 0.8419 - val_recall_15: 0.8233\n",
      "Epoch 26/40\n",
      "50/50 [==============================] - 40s 806ms/step - loss: 0.0119 - accuracy: 0.9974 - f1_score: 0.7237 - precision_15: 0.9974 - recall_15: 0.9974 - val_loss: 1.0736 - val_accuracy: 0.8315 - val_f1_score: 0.7090 - val_precision_15: 0.8362 - val_recall_15: 0.8246\n",
      "Epoch 27/40\n",
      "50/50 [==============================] - 42s 841ms/step - loss: 0.0119 - accuracy: 0.9971 - f1_score: 0.7239 - precision_15: 0.9972 - recall_15: 0.9970 - val_loss: 1.0236 - val_accuracy: 0.8320 - val_f1_score: 0.6989 - val_precision_15: 0.8300 - val_recall_15: 0.8350\n",
      "Epoch 28/40\n",
      "50/50 [==============================] - 42s 852ms/step - loss: 0.0168 - accuracy: 0.9954 - f1_score: 0.7164 - precision_15: 0.9953 - recall_15: 0.9955 - val_loss: 1.1822 - val_accuracy: 0.8361 - val_f1_score: 0.7279 - val_precision_15: 0.8414 - val_recall_15: 0.8283\n",
      "Epoch 29/40\n",
      "50/50 [==============================] - 43s 871ms/step - loss: 0.0130 - accuracy: 0.9970 - f1_score: 0.7249 - precision_15: 0.9975 - recall_15: 0.9966 - val_loss: 0.9947 - val_accuracy: 0.8275 - val_f1_score: 0.7146 - val_precision_15: 0.8573 - val_recall_15: 0.7858\n",
      "Epoch 30/40\n",
      "50/50 [==============================] - 39s 776ms/step - loss: 0.0086 - accuracy: 0.9986 - f1_score: 0.7246 - precision_15: 0.9986 - recall_15: 0.9987 - val_loss: 1.1544 - val_accuracy: 0.8321 - val_f1_score: 0.7206 - val_precision_15: 0.8437 - val_recall_15: 0.8152\n",
      "Epoch 31/40\n",
      "50/50 [==============================] - 39s 787ms/step - loss: 0.0067 - accuracy: 0.9989 - f1_score: 0.7368 - precision_15: 0.9986 - recall_15: 0.9991 - val_loss: 1.2020 - val_accuracy: 0.8315 - val_f1_score: 0.7327 - val_precision_15: 0.8446 - val_recall_15: 0.8126\n",
      "Epoch 32/40\n",
      "50/50 [==============================] - 39s 789ms/step - loss: 0.0204 - accuracy: 0.9947 - f1_score: 0.7233 - precision_15: 0.9954 - recall_15: 0.9940 - val_loss: 1.0168 - val_accuracy: 0.8311 - val_f1_score: 0.6910 - val_precision_15: 0.8284 - val_recall_15: 0.8352\n",
      "Epoch 33/40\n",
      "50/50 [==============================] - 43s 870ms/step - loss: 0.0115 - accuracy: 0.9973 - f1_score: 0.7160 - precision_15: 0.9974 - recall_15: 0.9972 - val_loss: 1.1350 - val_accuracy: 0.8326 - val_f1_score: 0.7145 - val_precision_15: 0.8386 - val_recall_15: 0.8238\n",
      "Epoch 34/40\n",
      "50/50 [==============================] - 43s 856ms/step - loss: 0.0072 - accuracy: 0.9990 - f1_score: 0.7295 - precision_15: 0.9989 - recall_15: 0.9991 - val_loss: 1.2360 - val_accuracy: 0.8307 - val_f1_score: 0.7248 - val_precision_15: 0.8396 - val_recall_15: 0.8175\n",
      "Epoch 35/40\n",
      "50/50 [==============================] - 42s 838ms/step - loss: 0.0057 - accuracy: 0.9990 - f1_score: 0.7327 - precision_15: 0.9991 - recall_15: 0.9988 - val_loss: 1.1602 - val_accuracy: 0.8284 - val_f1_score: 0.7235 - val_precision_15: 0.8478 - val_recall_15: 0.8006\n",
      "Epoch 36/40\n",
      "50/50 [==============================] - 40s 805ms/step - loss: 0.0139 - accuracy: 0.9960 - f1_score: 0.7271 - precision_15: 0.9954 - recall_15: 0.9966 - val_loss: 1.1541 - val_accuracy: 0.8250 - val_f1_score: 0.7185 - val_precision_15: 0.8581 - val_recall_15: 0.7788\n",
      "Epoch 37/40\n",
      "50/50 [==============================] - 40s 793ms/step - loss: 0.0154 - accuracy: 0.9960 - f1_score: 0.7132 - precision_15: 0.9961 - recall_15: 0.9960 - val_loss: 1.1337 - val_accuracy: 0.8326 - val_f1_score: 0.7122 - val_precision_15: 0.8423 - val_recall_15: 0.8185\n",
      "Epoch 38/40\n",
      "50/50 [==============================] - 43s 868ms/step - loss: 0.0122 - accuracy: 0.9969 - f1_score: 0.7212 - precision_15: 0.9971 - recall_15: 0.9967 - val_loss: 1.2377 - val_accuracy: 0.8171 - val_f1_score: 0.7335 - val_precision_15: 0.8765 - val_recall_15: 0.7382\n",
      "Epoch 39/40\n",
      "50/50 [==============================] - 42s 845ms/step - loss: 0.0111 - accuracy: 0.9976 - f1_score: 0.7229 - precision_15: 0.9975 - recall_15: 0.9978 - val_loss: 1.0606 - val_accuracy: 0.8292 - val_f1_score: 0.7037 - val_precision_15: 0.8294 - val_recall_15: 0.8289\n",
      "Epoch 40/40\n",
      "50/50 [==============================] - 41s 813ms/step - loss: 0.0089 - accuracy: 0.9983 - f1_score: 0.7238 - precision_15: 0.9982 - recall_15: 0.9985 - val_loss: 1.2738 - val_accuracy: 0.8306 - val_f1_score: 0.7286 - val_precision_15: 0.8505 - val_recall_15: 0.8023\n",
      "50/50 [==============================] - 8s 165ms/step - loss: 1.2738 - accuracy: 0.8306 - f1_score: 0.7286 - precision_15: 0.8505 - recall_15: 0.8023\n",
      "\n",
      "Test score: 1.273809552192688\n",
      "Test accuracy: 0.8306400179862976\n",
      "782/782 [==============================] - 19s 24ms/step\n",
      "результат: 0\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0.08756334]]\n"
     ]
    }
   ],
   "source": [
    "model = build_model5()\n",
    "model.summary()\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\", keras.metrics.F1Score(), keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "score = model.fit(X_train, y_train,\n",
    " epochs = EPOCHS,\n",
    " batch_size = BATCH_SIZE,\n",
    " validation_data = (X_test, y_test)\n",
    ")\n",
    "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save(\"imdb2.h5\")\n",
    "\n",
    "val = model.predict(X_train)\n",
    "print(f'результат: {np.argmax(val[0])}')\n",
    "word2index = imdb.get_word_index()\n",
    "test=[]\n",
    "for word in word_tokenize( \"i love this movie\"):\n",
    "     test.append(word2index[word])\n",
    "\n",
    "test=pad_sequences([test],maxlen=200)\n",
    "print(model.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_16 (Embedding)    (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 128)               99072     \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1379201 (5.26 MB)\n",
      "Trainable params: 1379201 (5.26 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "50/50 [==============================] - 36s 689ms/step - loss: 3963381325234176.0000 - accuracy: 0.5882 - f1_score: 0.6674 - precision_16: 0.5890 - recall_16: 0.5833 - val_loss: 196935.7344 - val_accuracy: 0.5316 - val_f1_score: 0.6667 - val_precision_16: 0.5163 - val_recall_16: 0.9987\n",
      "Epoch 2/40\n",
      "50/50 [==============================] - 35s 707ms/step - loss: 4108.8481 - accuracy: 0.5207 - f1_score: 0.3540 - precision_16: 0.6760 - recall_16: 0.0796 - val_loss: 19.7787 - val_accuracy: 0.5000 - val_f1_score: 0.1229 - val_precision_16: 1.0000 - val_recall_16: 8.0000e-05\n",
      "Epoch 3/40\n",
      "50/50 [==============================] - 35s 714ms/step - loss: 11.1614 - accuracy: 0.4999 - f1_score: 0.4938 - precision_16: 0.4848 - recall_16: 0.0026 - val_loss: 2.6840 - val_accuracy: 0.5007 - val_f1_score: 0.6667 - val_precision_16: 0.8462 - val_recall_16: 0.0018\n",
      "Epoch 4/40\n",
      "50/50 [==============================] - 34s 694ms/step - loss: 1.7096 - accuracy: 0.4980 - f1_score: 0.6667 - precision_16: 0.4980 - recall_16: 0.4965 - val_loss: 0.7166 - val_accuracy: 0.5122 - val_f1_score: 0.6667 - val_precision_16: 0.7004 - val_recall_16: 0.0426\n",
      "Epoch 5/40\n",
      "50/50 [==============================] - 35s 700ms/step - loss: 1.4708 - accuracy: 0.5108 - f1_score: 0.6667 - precision_16: 0.5111 - recall_16: 0.4946 - val_loss: 0.6871 - val_accuracy: 0.5556 - val_f1_score: 0.6667 - val_precision_16: 0.5483 - val_recall_16: 0.6311\n",
      "Epoch 6/40\n",
      "50/50 [==============================] - 34s 694ms/step - loss: 1.3822 - accuracy: 0.5063 - f1_score: 0.6667 - precision_16: 0.5063 - recall_16: 0.5026 - val_loss: 0.6866 - val_accuracy: 0.5819 - val_f1_score: 0.6667 - val_precision_16: 0.6007 - val_recall_16: 0.4883\n",
      "Epoch 7/40\n",
      "50/50 [==============================] - 43s 871ms/step - loss: 1.2902 - accuracy: 0.5069 - f1_score: 0.6667 - precision_16: 0.5071 - recall_16: 0.4976 - val_loss: 0.6908 - val_accuracy: 0.5137 - val_f1_score: 0.6667 - val_precision_16: 0.6647 - val_recall_16: 0.0554\n",
      "Epoch 8/40\n",
      "50/50 [==============================] - 39s 779ms/step - loss: 1.2131 - accuracy: 0.5078 - f1_score: 0.6667 - precision_16: 0.5081 - recall_16: 0.4915 - val_loss: 0.6860 - val_accuracy: 0.5914 - val_f1_score: 0.6667 - val_precision_16: 0.6682 - val_recall_16: 0.3630\n",
      "Epoch 9/40\n",
      "50/50 [==============================] - 34s 682ms/step - loss: 1.1433 - accuracy: 0.5025 - f1_score: 0.6667 - precision_16: 0.5026 - recall_16: 0.4874 - val_loss: 0.6860 - val_accuracy: 0.5322 - val_f1_score: 0.6667 - val_precision_16: 0.7140 - val_recall_16: 0.1074\n",
      "Epoch 10/40\n",
      "50/50 [==============================] - 34s 675ms/step - loss: 1.0849 - accuracy: 0.5093 - f1_score: 0.6667 - precision_16: 0.5096 - recall_16: 0.4913 - val_loss: 0.6867 - val_accuracy: 0.5419 - val_f1_score: 0.6667 - val_precision_16: 0.5236 - val_recall_16: 0.9297\n",
      "Epoch 11/40\n",
      "50/50 [==============================] - 33s 668ms/step - loss: 1.0521 - accuracy: 0.5088 - f1_score: 0.6667 - precision_16: 0.5092 - recall_16: 0.4894 - val_loss: 0.6853 - val_accuracy: 0.5360 - val_f1_score: 0.6667 - val_precision_16: 0.7038 - val_recall_16: 0.1245\n",
      "Epoch 12/40\n",
      "50/50 [==============================] - 35s 697ms/step - loss: 1.0179 - accuracy: 0.5097 - f1_score: 0.6667 - precision_16: 0.5101 - recall_16: 0.4898 - val_loss: 0.6854 - val_accuracy: 0.6177 - val_f1_score: 0.6667 - val_precision_16: 0.5820 - val_recall_16: 0.8354\n",
      "Epoch 13/40\n",
      "50/50 [==============================] - 36s 728ms/step - loss: 0.9836 - accuracy: 0.5157 - f1_score: 0.6667 - precision_16: 0.5164 - recall_16: 0.4942 - val_loss: 0.6852 - val_accuracy: 0.6271 - val_f1_score: 0.6667 - val_precision_16: 0.5913 - val_recall_16: 0.8233\n",
      "Epoch 14/40\n",
      "50/50 [==============================] - 36s 725ms/step - loss: 0.9788 - accuracy: 0.5101 - f1_score: 0.6667 - precision_16: 0.5104 - recall_16: 0.4967 - val_loss: 0.6868 - val_accuracy: 0.5078 - val_f1_score: 0.6667 - val_precision_16: 0.5039 - val_recall_16: 0.9990\n",
      "Epoch 15/40\n",
      "50/50 [==============================] - 34s 689ms/step - loss: 0.9747 - accuracy: 0.5107 - f1_score: 0.6667 - precision_16: 0.5110 - recall_16: 0.4982 - val_loss: 0.6845 - val_accuracy: 0.5910 - val_f1_score: 0.6667 - val_precision_16: 0.7186 - val_recall_16: 0.2990\n",
      "Epoch 16/40\n",
      "50/50 [==============================] - 34s 688ms/step - loss: 0.9639 - accuracy: 0.5111 - f1_score: 0.6667 - precision_16: 0.5112 - recall_16: 0.5063 - val_loss: 0.6870 - val_accuracy: 0.5188 - val_f1_score: 0.6667 - val_precision_16: 0.6315 - val_recall_16: 0.0905\n",
      "Epoch 17/40\n",
      "50/50 [==============================] - 35s 705ms/step - loss: 0.9583 - accuracy: 0.5116 - f1_score: 0.6667 - precision_16: 0.5117 - recall_16: 0.5076 - val_loss: 0.6887 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_precision_16: 0.5000 - val_recall_16: 0.9999\n",
      "Epoch 18/40\n",
      "50/50 [==============================] - 34s 690ms/step - loss: 0.9584 - accuracy: 0.5096 - f1_score: 0.6667 - precision_16: 0.5096 - recall_16: 0.5093 - val_loss: 0.6848 - val_accuracy: 0.6191 - val_f1_score: 0.6667 - val_precision_16: 0.5885 - val_recall_16: 0.7920\n",
      "Epoch 19/40\n",
      "50/50 [==============================] - 34s 690ms/step - loss: 0.9555 - accuracy: 0.5092 - f1_score: 0.6667 - precision_16: 0.5090 - recall_16: 0.5191 - val_loss: 0.6858 - val_accuracy: 0.5228 - val_f1_score: 0.6667 - val_precision_16: 0.6260 - val_recall_16: 0.1134\n",
      "Epoch 20/40\n",
      "50/50 [==============================] - 34s 693ms/step - loss: 0.9511 - accuracy: 0.5117 - f1_score: 0.6667 - precision_16: 0.5116 - recall_16: 0.5153 - val_loss: 0.6844 - val_accuracy: 0.5520 - val_f1_score: 0.6667 - val_precision_16: 0.6554 - val_recall_16: 0.2191\n",
      "Epoch 21/40\n",
      "50/50 [==============================] - 36s 715ms/step - loss: 0.9460 - accuracy: 0.5142 - f1_score: 0.6667 - precision_16: 0.5140 - recall_16: 0.5199 - val_loss: 0.6848 - val_accuracy: 0.5367 - val_f1_score: 0.6667 - val_precision_16: 0.6441 - val_recall_16: 0.1642\n",
      "Epoch 22/40\n",
      "50/50 [==============================] - 36s 723ms/step - loss: 0.9647 - accuracy: 0.5029 - f1_score: 0.6667 - precision_16: 0.5029 - recall_16: 0.5076 - val_loss: 0.6842 - val_accuracy: 0.5656 - val_f1_score: 0.6667 - val_precision_16: 0.6428 - val_recall_16: 0.2950\n",
      "Epoch 23/40\n",
      "50/50 [==============================] - 33s 674ms/step - loss: 0.9472 - accuracy: 0.5116 - f1_score: 0.6667 - precision_16: 0.5115 - recall_16: 0.5184 - val_loss: 0.6887 - val_accuracy: 0.5002 - val_f1_score: 0.6667 - val_precision_16: 0.5001 - val_recall_16: 0.9999\n",
      "Epoch 24/40\n",
      "50/50 [==============================] - 36s 724ms/step - loss: 0.9600 - accuracy: 0.5016 - f1_score: 0.6667 - precision_16: 0.5015 - recall_16: 0.5128 - val_loss: 0.6888 - val_accuracy: 0.5002 - val_f1_score: 0.6667 - val_precision_16: 0.5001 - val_recall_16: 0.9999\n",
      "Epoch 25/40\n",
      "50/50 [==============================] - 41s 819ms/step - loss: 0.9431 - accuracy: 0.5094 - f1_score: 0.6667 - precision_16: 0.5092 - recall_16: 0.5182 - val_loss: 0.6866 - val_accuracy: 0.5148 - val_f1_score: 0.6667 - val_precision_16: 0.5076 - val_recall_16: 0.9957\n",
      "Epoch 26/40\n",
      "50/50 [==============================] - 46s 917ms/step - loss: 0.9498 - accuracy: 0.5102 - f1_score: 0.6667 - precision_16: 0.5100 - recall_16: 0.5214 - val_loss: 0.6859 - val_accuracy: 0.5496 - val_f1_score: 0.6667 - val_precision_16: 0.5269 - val_recall_16: 0.9718\n",
      "Epoch 27/40\n",
      "50/50 [==============================] - 46s 917ms/step - loss: 0.9463 - accuracy: 0.5124 - f1_score: 0.6667 - precision_16: 0.5122 - recall_16: 0.5204 - val_loss: 0.6843 - val_accuracy: 0.5905 - val_f1_score: 0.6667 - val_precision_16: 0.5979 - val_recall_16: 0.5527\n",
      "Epoch 28/40\n",
      "50/50 [==============================] - 33s 668ms/step - loss: 0.9455 - accuracy: 0.5116 - f1_score: 0.6667 - precision_16: 0.5112 - recall_16: 0.5286 - val_loss: 0.6842 - val_accuracy: 0.5615 - val_f1_score: 0.6667 - val_precision_16: 0.6338 - val_recall_16: 0.2914\n",
      "Epoch 29/40\n",
      "50/50 [==============================] - 34s 685ms/step - loss: 0.9587 - accuracy: 0.4997 - f1_score: 0.6667 - precision_16: 0.4997 - recall_16: 0.5148 - val_loss: 0.6855 - val_accuracy: 0.5864 - val_f1_score: 0.6667 - val_precision_16: 0.5531 - val_recall_16: 0.9001\n",
      "Epoch 30/40\n",
      "50/50 [==============================] - 33s 657ms/step - loss: 0.9447 - accuracy: 0.5102 - f1_score: 0.6667 - precision_16: 0.5100 - recall_16: 0.5219 - val_loss: 0.6844 - val_accuracy: 0.5828 - val_f1_score: 0.6667 - val_precision_16: 0.5884 - val_recall_16: 0.5510\n",
      "Epoch 31/40\n",
      "50/50 [==============================] - 33s 670ms/step - loss: 0.9423 - accuracy: 0.5061 - f1_score: 0.6667 - precision_16: 0.5059 - recall_16: 0.5210 - val_loss: 0.6843 - val_accuracy: 0.5696 - val_f1_score: 0.6667 - val_precision_16: 0.5905 - val_recall_16: 0.4544\n",
      "Epoch 32/40\n",
      "50/50 [==============================] - 35s 702ms/step - loss: 0.9375 - accuracy: 0.5149 - f1_score: 0.6667 - precision_16: 0.5144 - recall_16: 0.5318 - val_loss: 0.6875 - val_accuracy: 0.5232 - val_f1_score: 0.6667 - val_precision_16: 0.6146 - val_recall_16: 0.1244\n",
      "Epoch 33/40\n",
      "50/50 [==============================] - 35s 712ms/step - loss: 0.9381 - accuracy: 0.5143 - f1_score: 0.6667 - precision_16: 0.5139 - recall_16: 0.5300 - val_loss: 0.6842 - val_accuracy: 0.5706 - val_f1_score: 0.6667 - val_precision_16: 0.6072 - val_recall_16: 0.3995\n",
      "Epoch 34/40\n",
      "50/50 [==============================] - 37s 737ms/step - loss: 0.9427 - accuracy: 0.5097 - f1_score: 0.6667 - precision_16: 0.5093 - recall_16: 0.5287 - val_loss: 0.6842 - val_accuracy: 0.5624 - val_f1_score: 0.6667 - val_precision_16: 0.6196 - val_recall_16: 0.3234\n",
      "Epoch 35/40\n",
      "50/50 [==============================] - 35s 703ms/step - loss: 0.9417 - accuracy: 0.5099 - f1_score: 0.6667 - precision_16: 0.5096 - recall_16: 0.5266 - val_loss: 0.6841 - val_accuracy: 0.5644 - val_f1_score: 0.6667 - val_precision_16: 0.5933 - val_recall_16: 0.4093\n",
      "Epoch 36/40\n",
      "50/50 [==============================] - 34s 694ms/step - loss: 0.9489 - accuracy: 0.5044 - f1_score: 0.6667 - precision_16: 0.5043 - recall_16: 0.5208 - val_loss: 0.6841 - val_accuracy: 0.5626 - val_f1_score: 0.6667 - val_precision_16: 0.5843 - val_recall_16: 0.4340\n",
      "Epoch 37/40\n",
      "50/50 [==============================] - 35s 694ms/step - loss: 0.9310 - accuracy: 0.5155 - f1_score: 0.6667 - precision_16: 0.5151 - recall_16: 0.5277 - val_loss: 0.6851 - val_accuracy: 0.5994 - val_f1_score: 0.6667 - val_precision_16: 0.5702 - val_recall_16: 0.8081\n",
      "Epoch 38/40\n",
      "50/50 [==============================] - 34s 686ms/step - loss: 0.9355 - accuracy: 0.5091 - f1_score: 0.6667 - precision_16: 0.5087 - recall_16: 0.5311 - val_loss: 0.6843 - val_accuracy: 0.5789 - val_f1_score: 0.6667 - val_precision_16: 0.5802 - val_recall_16: 0.5708\n",
      "Epoch 39/40\n",
      "50/50 [==============================] - 35s 708ms/step - loss: 0.9342 - accuracy: 0.5088 - f1_score: 0.6667 - precision_16: 0.5085 - recall_16: 0.5256 - val_loss: 0.6846 - val_accuracy: 0.5425 - val_f1_score: 0.6667 - val_precision_16: 0.6256 - val_recall_16: 0.2118\n",
      "Epoch 40/40\n",
      "50/50 [==============================] - 35s 696ms/step - loss: 0.9333 - accuracy: 0.5113 - f1_score: 0.6667 - precision_16: 0.5110 - recall_16: 0.5256 - val_loss: 0.6897 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_precision_16: 0.5000 - val_recall_16: 0.9996\n",
      "50/50 [==============================] - 12s 231ms/step - loss: 0.6897 - accuracy: 0.5000 - f1_score: 0.6667 - precision_16: 0.5000 - recall_16: 0.9996\n",
      "\n",
      "Test score: 0.6897148489952087\n",
      "Test accuracy: 0.5000399947166443\n",
      "782/782 [==============================] - 34s 43ms/step\n",
      "результат: 0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[0.581317]]\n"
     ]
    }
   ],
   "source": [
    "model = build_model6()\n",
    "model.summary()\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\", keras.metrics.F1Score(), keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "score = model.fit(X_train, y_train,\n",
    " epochs = EPOCHS,\n",
    " batch_size = BATCH_SIZE,\n",
    " validation_data = (X_test, y_test)\n",
    ")\n",
    "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save(\"imdb2.h5\")\n",
    "\n",
    "val = model.predict(X_train)\n",
    "print(f'результат: {np.argmax(val[0])}')\n",
    "word2index = imdb.get_word_index()\n",
    "test=[]\n",
    "for word in word_tokenize( \"i love this movie\"):\n",
    "     test.append(word2index[word])\n",
    "\n",
    "test=pad_sequences([test],maxlen=200)\n",
    "print(model.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_17 (Embedding)    (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " transformer_encoder_2 (Tra  (None, 200, 128)          165504    \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " gru_6 (GRU)                 (None, 128)               99072     \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1544705 (5.89 MB)\n",
      "Trainable params: 1544705 (5.89 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "50/50 [==============================] - 128s 3s/step - loss: 0.6091 - accuracy: 0.6496 - f1_score: 0.6667 - precision_17: 0.6475 - recall_17: 0.6570 - val_loss: 0.4118 - val_accuracy: 0.8090 - val_f1_score: 0.6667 - val_precision_17: 0.7644 - val_recall_17: 0.8934\n",
      "Epoch 2/40\n",
      "50/50 [==============================] - 129s 3s/step - loss: 0.2777 - accuracy: 0.8832 - f1_score: 0.6667 - precision_17: 0.8810 - recall_17: 0.8862 - val_loss: 0.2946 - val_accuracy: 0.8753 - val_f1_score: 0.6667 - val_precision_17: 0.8951 - val_recall_17: 0.8502\n",
      "Epoch 3/40\n",
      "50/50 [==============================] - 131s 3s/step - loss: 0.1598 - accuracy: 0.9402 - f1_score: 0.6667 - precision_17: 0.9414 - recall_17: 0.9388 - val_loss: 0.3409 - val_accuracy: 0.8677 - val_f1_score: 0.6667 - val_precision_17: 0.8425 - val_recall_17: 0.9046\n",
      "Epoch 4/40\n",
      "50/50 [==============================] - 129s 3s/step - loss: 0.0864 - accuracy: 0.9704 - f1_score: 0.6667 - precision_17: 0.9709 - recall_17: 0.9699 - val_loss: 0.4408 - val_accuracy: 0.8644 - val_f1_score: 0.6667 - val_precision_17: 0.8551 - val_recall_17: 0.8776\n",
      "Epoch 5/40\n",
      "50/50 [==============================] - 130s 3s/step - loss: 0.0472 - accuracy: 0.9839 - f1_score: 0.6670 - precision_17: 0.9832 - recall_17: 0.9846 - val_loss: 0.5275 - val_accuracy: 0.8585 - val_f1_score: 0.6667 - val_precision_17: 0.8505 - val_recall_17: 0.8700\n",
      "Epoch 6/40\n",
      "50/50 [==============================] - 125s 3s/step - loss: 0.0275 - accuracy: 0.9904 - f1_score: 0.6681 - precision_17: 0.9898 - recall_17: 0.9910 - val_loss: 0.6871 - val_accuracy: 0.8546 - val_f1_score: 0.6669 - val_precision_17: 0.8283 - val_recall_17: 0.8947\n",
      "Epoch 7/40\n",
      "50/50 [==============================] - 128s 3s/step - loss: 0.0265 - accuracy: 0.9906 - f1_score: 0.6682 - precision_17: 0.9899 - recall_17: 0.9913 - val_loss: 0.6904 - val_accuracy: 0.8562 - val_f1_score: 0.6671 - val_precision_17: 0.8722 - val_recall_17: 0.8346\n",
      "Epoch 8/40\n",
      "50/50 [==============================] - 130s 3s/step - loss: 0.0177 - accuracy: 0.9940 - f1_score: 0.6716 - precision_17: 0.9939 - recall_17: 0.9940 - val_loss: 0.7994 - val_accuracy: 0.8581 - val_f1_score: 0.6699 - val_precision_17: 0.8524 - val_recall_17: 0.8661\n",
      "Epoch 9/40\n",
      "50/50 [==============================] - 130s 3s/step - loss: 0.0084 - accuracy: 0.9976 - f1_score: 0.6778 - precision_17: 0.9974 - recall_17: 0.9978 - val_loss: 0.9085 - val_accuracy: 0.8561 - val_f1_score: 0.6792 - val_precision_17: 0.8710 - val_recall_17: 0.8360\n",
      "Epoch 10/40\n",
      "50/50 [==============================] - 132s 3s/step - loss: 0.0066 - accuracy: 0.9984 - f1_score: 0.6903 - precision_17: 0.9982 - recall_17: 0.9986 - val_loss: 0.9977 - val_accuracy: 0.8547 - val_f1_score: 0.6967 - val_precision_17: 0.8605 - val_recall_17: 0.8466\n",
      "Epoch 11/40\n",
      "50/50 [==============================] - 132s 3s/step - loss: 0.0082 - accuracy: 0.9978 - f1_score: 0.6993 - precision_17: 0.9975 - recall_17: 0.9980 - val_loss: 0.9325 - val_accuracy: 0.8534 - val_f1_score: 0.6811 - val_precision_17: 0.8380 - val_recall_17: 0.8761\n",
      "Epoch 12/40\n",
      "50/50 [==============================] - 129s 3s/step - loss: 0.0113 - accuracy: 0.9962 - f1_score: 0.6918 - precision_17: 0.9958 - recall_17: 0.9966 - val_loss: 0.8816 - val_accuracy: 0.8529 - val_f1_score: 0.6751 - val_precision_17: 0.8811 - val_recall_17: 0.8159\n",
      "Epoch 13/40\n",
      "50/50 [==============================] - 127s 3s/step - loss: 0.0072 - accuracy: 0.9980 - f1_score: 0.6850 - precision_17: 0.9979 - recall_17: 0.9981 - val_loss: 0.9668 - val_accuracy: 0.8555 - val_f1_score: 0.6844 - val_precision_17: 0.8554 - val_recall_17: 0.8556\n",
      "Epoch 14/40\n",
      "50/50 [==============================] - 128s 3s/step - loss: 0.0027 - accuracy: 0.9993 - f1_score: 0.7078 - precision_17: 0.9993 - recall_17: 0.9993 - val_loss: 1.0978 - val_accuracy: 0.8580 - val_f1_score: 0.7025 - val_precision_17: 0.8492 - val_recall_17: 0.8707\n",
      "Epoch 15/40\n",
      "50/50 [==============================] - 128s 3s/step - loss: 0.0085 - accuracy: 0.9970 - f1_score: 0.7117 - precision_17: 0.9968 - recall_17: 0.9971 - val_loss: 1.0174 - val_accuracy: 0.8506 - val_f1_score: 0.7095 - val_precision_17: 0.8721 - val_recall_17: 0.8218\n",
      "Epoch 16/40\n",
      "50/50 [==============================] - 126s 3s/step - loss: 0.0078 - accuracy: 0.9977 - f1_score: 0.7188 - precision_17: 0.9976 - recall_17: 0.9978 - val_loss: 0.9178 - val_accuracy: 0.8555 - val_f1_score: 0.6881 - val_precision_17: 0.8502 - val_recall_17: 0.8630\n",
      "Epoch 17/40\n",
      "50/50 [==============================] - 130s 3s/step - loss: 0.0033 - accuracy: 0.9992 - f1_score: 0.7125 - precision_17: 0.9993 - recall_17: 0.9992 - val_loss: 1.0400 - val_accuracy: 0.8543 - val_f1_score: 0.7056 - val_precision_17: 0.8538 - val_recall_17: 0.8550\n",
      "Epoch 18/40\n",
      "50/50 [==============================] - 133s 3s/step - loss: 0.0021 - accuracy: 0.9994 - f1_score: 0.7209 - precision_17: 0.9994 - recall_17: 0.9994 - val_loss: 1.1244 - val_accuracy: 0.8544 - val_f1_score: 0.7072 - val_precision_17: 0.8676 - val_recall_17: 0.8363\n",
      "Epoch 19/40\n",
      "50/50 [==============================] - 130s 3s/step - loss: 9.0133e-04 - accuracy: 0.9999 - f1_score: 0.7450 - precision_17: 0.9999 - recall_17: 0.9999 - val_loss: 1.2002 - val_accuracy: 0.8552 - val_f1_score: 0.7311 - val_precision_17: 0.8599 - val_recall_17: 0.8486\n",
      "Epoch 20/40\n",
      "50/50 [==============================] - 129s 3s/step - loss: 6.7243e-04 - accuracy: 0.9999 - f1_score: 0.7526 - precision_17: 0.9999 - recall_17: 0.9999 - val_loss: 1.2112 - val_accuracy: 0.8563 - val_f1_score: 0.7311 - val_precision_17: 0.8522 - val_recall_17: 0.8622\n",
      "Epoch 21/40\n",
      "50/50 [==============================] - 132s 3s/step - loss: 5.1127e-04 - accuracy: 1.0000 - f1_score: 0.7635 - precision_17: 0.9999 - recall_17: 1.0000 - val_loss: 1.2743 - val_accuracy: 0.8560 - val_f1_score: 0.7481 - val_precision_17: 0.8601 - val_recall_17: 0.8504\n",
      "Epoch 22/40\n",
      "50/50 [==============================] - 128s 3s/step - loss: 3.4173e-04 - accuracy: 1.0000 - f1_score: 0.7763 - precision_17: 0.9999 - recall_17: 1.0000 - val_loss: 1.2918 - val_accuracy: 0.8552 - val_f1_score: 0.7495 - val_precision_17: 0.8499 - val_recall_17: 0.8627\n",
      "Epoch 23/40\n",
      "50/50 [==============================] - 123s 2s/step - loss: 3.6114e-04 - accuracy: 1.0000 - f1_score: 0.7828 - precision_17: 0.9999 - recall_17: 1.0000 - val_loss: 1.3425 - val_accuracy: 0.8547 - val_f1_score: 0.7628 - val_precision_17: 0.8610 - val_recall_17: 0.8461\n",
      "Epoch 24/40\n",
      "50/50 [==============================] - 122s 2s/step - loss: 2.4076e-04 - accuracy: 1.0000 - f1_score: 0.7944 - precision_17: 0.9999 - recall_17: 1.0000 - val_loss: 1.3702 - val_accuracy: 0.8548 - val_f1_score: 0.7678 - val_precision_17: 0.8581 - val_recall_17: 0.8503\n",
      "Epoch 25/40\n",
      "50/50 [==============================] - 127s 3s/step - loss: 2.9032e-04 - accuracy: 1.0000 - f1_score: 0.8026 - precision_17: 0.9999 - recall_17: 1.0000 - val_loss: 1.4046 - val_accuracy: 0.8547 - val_f1_score: 0.7710 - val_precision_17: 0.8534 - val_recall_17: 0.8566\n",
      "Epoch 26/40\n",
      "50/50 [==============================] - 123s 2s/step - loss: 3.1595e-04 - accuracy: 1.0000 - f1_score: 0.8091 - precision_17: 0.9999 - recall_17: 1.0000 - val_loss: 1.4415 - val_accuracy: 0.8544 - val_f1_score: 0.7781 - val_precision_17: 0.8618 - val_recall_17: 0.8441\n",
      "Epoch 27/40\n",
      "50/50 [==============================] - 123s 2s/step - loss: 2.6780e-04 - accuracy: 1.0000 - f1_score: 0.8139 - precision_17: 0.9999 - recall_17: 1.0000 - val_loss: 1.4761 - val_accuracy: 0.8551 - val_f1_score: 0.7793 - val_precision_17: 0.8579 - val_recall_17: 0.8512\n",
      "Epoch 28/40\n",
      "50/50 [==============================] - 123s 2s/step - loss: 2.3937e-04 - accuracy: 1.0000 - f1_score: 0.8177 - precision_17: 0.9999 - recall_17: 1.0000 - val_loss: 1.4755 - val_accuracy: 0.8548 - val_f1_score: 0.7788 - val_precision_17: 0.8534 - val_recall_17: 0.8567\n",
      "Epoch 29/40\n",
      "50/50 [==============================] - 125s 3s/step - loss: 1.5099e-04 - accuracy: 1.0000 - f1_score: 0.8252 - precision_17: 0.9999 - recall_17: 1.0000 - val_loss: 1.5389 - val_accuracy: 0.8551 - val_f1_score: 0.7858 - val_precision_17: 0.8573 - val_recall_17: 0.8519\n",
      "Epoch 30/40\n",
      "50/50 [==============================] - 127s 3s/step - loss: 8.1759e-05 - accuracy: 1.0000 - f1_score: 0.8321 - precision_17: 0.9999 - recall_17: 1.0000 - val_loss: 1.5782 - val_accuracy: 0.8546 - val_f1_score: 0.7904 - val_precision_17: 0.8600 - val_recall_17: 0.8472\n",
      "Epoch 31/40\n",
      "50/50 [==============================] - 125s 3s/step - loss: 6.8175e-05 - accuracy: 1.0000 - f1_score: 0.8347 - precision_17: 0.9999 - recall_17: 1.0000 - val_loss: 1.6121 - val_accuracy: 0.8552 - val_f1_score: 0.7898 - val_precision_17: 0.8547 - val_recall_17: 0.8558\n",
      "Epoch 32/40\n",
      "50/50 [==============================] - 124s 2s/step - loss: 3.6049e-05 - accuracy: 1.0000 - f1_score: 0.8414 - precision_17: 1.0000 - recall_17: 1.0000 - val_loss: 1.6455 - val_accuracy: 0.8558 - val_f1_score: 0.7922 - val_precision_17: 0.8555 - val_recall_17: 0.8562\n",
      "Epoch 33/40\n",
      "50/50 [==============================] - 124s 2s/step - loss: 2.7366e-05 - accuracy: 1.0000 - f1_score: 0.8443 - precision_17: 1.0000 - recall_17: 1.0000 - val_loss: 1.6650 - val_accuracy: 0.8550 - val_f1_score: 0.7953 - val_precision_17: 0.8582 - val_recall_17: 0.8506\n",
      "Epoch 34/40\n",
      "50/50 [==============================] - 121s 2s/step - loss: 3.8437e-05 - accuracy: 1.0000 - f1_score: 0.8453 - precision_17: 1.0000 - recall_17: 1.0000 - val_loss: 1.6925 - val_accuracy: 0.8548 - val_f1_score: 0.7967 - val_precision_17: 0.8572 - val_recall_17: 0.8516\n",
      "Epoch 35/40\n",
      "50/50 [==============================] - 111s 2s/step - loss: 2.0124e-05 - accuracy: 1.0000 - f1_score: 0.8510 - precision_17: 1.0000 - recall_17: 1.0000 - val_loss: 1.7200 - val_accuracy: 0.8550 - val_f1_score: 0.7977 - val_precision_17: 0.8564 - val_recall_17: 0.8529\n",
      "Epoch 36/40\n",
      "50/50 [==============================] - 117s 2s/step - loss: 1.1045e-05 - accuracy: 1.0000 - f1_score: 0.8520 - precision_17: 1.0000 - recall_17: 1.0000 - val_loss: 1.7416 - val_accuracy: 0.8549 - val_f1_score: 0.7999 - val_precision_17: 0.8568 - val_recall_17: 0.8522\n",
      "Epoch 37/40\n",
      "50/50 [==============================] - 124s 2s/step - loss: 1.3595e-05 - accuracy: 1.0000 - f1_score: 0.8540 - precision_17: 1.0000 - recall_17: 1.0000 - val_loss: 1.7478 - val_accuracy: 0.8551 - val_f1_score: 0.8004 - val_precision_17: 0.8571 - val_recall_17: 0.8523\n",
      "Epoch 38/40\n",
      "50/50 [==============================] - 149s 3s/step - loss: 8.5365e-06 - accuracy: 1.0000 - f1_score: 0.8559 - precision_17: 1.0000 - recall_17: 1.0000 - val_loss: 1.7699 - val_accuracy: 0.8550 - val_f1_score: 0.8009 - val_precision_17: 0.8553 - val_recall_17: 0.8546\n",
      "Epoch 39/40\n",
      "50/50 [==============================] - 175s 4s/step - loss: 6.0862e-06 - accuracy: 1.0000 - f1_score: 0.8586 - precision_17: 1.0000 - recall_17: 1.0000 - val_loss: 1.7915 - val_accuracy: 0.8548 - val_f1_score: 0.8033 - val_precision_17: 0.8568 - val_recall_17: 0.8522\n",
      "Epoch 40/40\n",
      "50/50 [==============================] - 1068s 22s/step - loss: 1.6240e-05 - accuracy: 1.0000 - f1_score: 0.8623 - precision_17: 1.0000 - recall_17: 1.0000 - val_loss: 1.7920 - val_accuracy: 0.8546 - val_f1_score: 0.8041 - val_precision_17: 0.8571 - val_recall_17: 0.8510\n",
      "50/50 [==============================] - 31s 624ms/step - loss: 1.7920 - accuracy: 0.8546 - f1_score: 0.8041 - precision_17: 0.8571 - recall_17: 0.8510\n",
      "\n",
      "Test score: 1.7920202016830444\n",
      "Test accuracy: 0.8546000123023987\n",
      "782/782 [==============================] - 1014s 1s/step\n",
      "результат: 0\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[[0.7763965]]\n"
     ]
    }
   ],
   "source": [
    "model = build_model7()\n",
    "model.summary()\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\", keras.metrics.F1Score(), keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "score = model.fit(X_train, y_train,\n",
    " epochs = EPOCHS,\n",
    " batch_size = BATCH_SIZE,\n",
    " validation_data = (X_test, y_test)\n",
    ")\n",
    "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save(\"imdb2.h5\")\n",
    "\n",
    "val = model.predict(X_train)\n",
    "print(f'результат: {np.argmax(val[0])}')\n",
    "word2index = imdb.get_word_index()\n",
    "test=[]\n",
    "for word in word_tokenize( \"i love this movie\"):\n",
    "     test.append(word2index[word])\n",
    "\n",
    "test=pad_sequences([test],maxlen=200)\n",
    "print(model.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_18 (Embedding)    (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " transformer_encoder_3 (Tra  (None, 200, 128)          165504    \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 199, 128)          32896     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25472)             0         \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 25472)             0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 25473     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1503873 (5.74 MB)\n",
      "Trainable params: 1503873 (5.74 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "50/50 [==============================] - 98s 2s/step - loss: 0.8610 - accuracy: 0.5030 - f1_score: 0.6667 - precision_18: 0.5020 - recall_18: 0.7561 - val_loss: 0.6931 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_precision_18: 0.5000 - val_recall_18: 0.9998\n",
      "Epoch 2/40\n",
      "50/50 [==============================] - 78s 2s/step - loss: 0.6931 - accuracy: 0.5003 - f1_score: 0.6667 - precision_18: 0.5001 - recall_18: 0.9998 - val_loss: 0.6931 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_precision_18: 0.5000 - val_recall_18: 0.9993\n",
      "Epoch 3/40\n",
      "50/50 [==============================] - 78s 2s/step - loss: 0.6931 - accuracy: 0.5042 - f1_score: 0.6667 - precision_18: 0.5024 - recall_18: 0.8860 - val_loss: 0.6937 - val_accuracy: 0.4996 - val_f1_score: 0.6667 - val_precision_18: 0.4809 - val_recall_18: 0.0101\n",
      "Epoch 4/40\n",
      "50/50 [==============================] - 80s 2s/step - loss: 0.6933 - accuracy: 0.4989 - f1_score: 0.6667 - precision_18: 0.4994 - recall_18: 0.9126 - val_loss: 0.6931 - val_accuracy: 0.5010 - val_f1_score: 0.6667 - val_precision_18: 0.5005 - val_recall_18: 0.9966\n",
      "Epoch 5/40\n",
      "50/50 [==============================] - 87s 2s/step - loss: 0.6931 - accuracy: 0.5009 - f1_score: 0.6667 - precision_18: 0.5005 - recall_18: 0.9962 - val_loss: 0.6932 - val_accuracy: 0.5020 - val_f1_score: 0.6667 - val_precision_18: 0.5010 - val_recall_18: 0.9894\n",
      "Epoch 6/40\n",
      "50/50 [==============================] - 82s 2s/step - loss: 0.6931 - accuracy: 0.5068 - f1_score: 0.6667 - precision_18: 0.5037 - recall_18: 0.9292 - val_loss: 0.6931 - val_accuracy: 0.5126 - val_f1_score: 0.6667 - val_precision_18: 0.5105 - val_recall_18: 0.6159\n",
      "Epoch 7/40\n",
      "50/50 [==============================] - 99s 2s/step - loss: 0.6930 - accuracy: 0.5096 - f1_score: 0.6667 - precision_18: 0.5078 - recall_18: 0.6237 - val_loss: 0.6929 - val_accuracy: 0.5121 - val_f1_score: 0.6667 - val_precision_18: 0.5133 - val_recall_18: 0.4661\n",
      "Epoch 8/40\n",
      "50/50 [==============================] - 92s 2s/step - loss: 0.6895 - accuracy: 0.5429 - f1_score: 0.6667 - precision_18: 0.5514 - recall_18: 0.4607 - val_loss: 0.6773 - val_accuracy: 0.6246 - val_f1_score: 0.6667 - val_precision_18: 0.6429 - val_recall_18: 0.5609\n",
      "Epoch 9/40\n",
      "50/50 [==============================] - 96s 2s/step - loss: 0.5128 - accuracy: 0.7374 - f1_score: 0.6667 - precision_18: 0.7324 - recall_18: 0.7481 - val_loss: 0.3301 - val_accuracy: 0.8563 - val_f1_score: 0.6667 - val_precision_18: 0.9052 - val_recall_18: 0.7960\n",
      "Epoch 10/40\n",
      "50/50 [==============================] - 92s 2s/step - loss: 0.2145 - accuracy: 0.9154 - f1_score: 0.6667 - precision_18: 0.9172 - recall_18: 0.9131 - val_loss: 0.3019 - val_accuracy: 0.8730 - val_f1_score: 0.6667 - val_precision_18: 0.9003 - val_recall_18: 0.8390\n",
      "Epoch 11/40\n",
      "50/50 [==============================] - 94s 2s/step - loss: 0.1064 - accuracy: 0.9630 - f1_score: 0.6667 - precision_18: 0.9639 - recall_18: 0.9621 - val_loss: 0.3499 - val_accuracy: 0.8646 - val_f1_score: 0.6667 - val_precision_18: 0.8395 - val_recall_18: 0.9014\n",
      "Epoch 12/40\n",
      "50/50 [==============================] - 96s 2s/step - loss: 0.0458 - accuracy: 0.9870 - f1_score: 0.6667 - precision_18: 0.9877 - recall_18: 0.9863 - val_loss: 0.4507 - val_accuracy: 0.8622 - val_f1_score: 0.6667 - val_precision_18: 0.8331 - val_recall_18: 0.9058\n",
      "Epoch 13/40\n",
      "50/50 [==============================] - 105s 2s/step - loss: 0.0178 - accuracy: 0.9961 - f1_score: 0.6667 - precision_18: 0.9961 - recall_18: 0.9961 - val_loss: 0.4932 - val_accuracy: 0.8617 - val_f1_score: 0.6667 - val_precision_18: 0.8817 - val_recall_18: 0.8356\n",
      "Epoch 14/40\n",
      "50/50 [==============================] - 104s 2s/step - loss: 0.0084 - accuracy: 0.9985 - f1_score: 0.6671 - precision_18: 0.9986 - recall_18: 0.9984 - val_loss: 0.5697 - val_accuracy: 0.8638 - val_f1_score: 0.6667 - val_precision_18: 0.8788 - val_recall_18: 0.8441\n",
      "Epoch 15/40\n",
      "50/50 [==============================] - 99s 2s/step - loss: 0.0046 - accuracy: 0.9995 - f1_score: 0.6696 - precision_18: 0.9995 - recall_18: 0.9994 - val_loss: 0.6483 - val_accuracy: 0.8642 - val_f1_score: 0.6669 - val_precision_18: 0.8519 - val_recall_18: 0.8818\n",
      "Epoch 16/40\n",
      "50/50 [==============================] - 99s 2s/step - loss: 0.0027 - accuracy: 0.9996 - f1_score: 0.6774 - precision_18: 0.9996 - recall_18: 0.9996 - val_loss: 0.6803 - val_accuracy: 0.8623 - val_f1_score: 0.6676 - val_precision_18: 0.8701 - val_recall_18: 0.8518\n",
      "Epoch 17/40\n",
      "50/50 [==============================] - 90s 2s/step - loss: 0.0019 - accuracy: 0.9998 - f1_score: 0.6796 - precision_18: 0.9999 - recall_18: 0.9998 - val_loss: 0.7796 - val_accuracy: 0.8628 - val_f1_score: 0.6783 - val_precision_18: 0.8687 - val_recall_18: 0.8548\n",
      "Epoch 18/40\n",
      "50/50 [==============================] - 90s 2s/step - loss: 0.0012 - accuracy: 0.9999 - f1_score: 0.6806 - precision_18: 1.0000 - recall_18: 0.9998 - val_loss: 0.7712 - val_accuracy: 0.8620 - val_f1_score: 0.6698 - val_precision_18: 0.8603 - val_recall_18: 0.8642\n",
      "Epoch 19/40\n",
      "50/50 [==============================] - 87s 2s/step - loss: 7.0252e-04 - accuracy: 1.0000 - f1_score: 0.6871 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 0.8177 - val_accuracy: 0.8618 - val_f1_score: 0.6786 - val_precision_18: 0.8718 - val_recall_18: 0.8483\n",
      "Epoch 20/40\n",
      "50/50 [==============================] - 90s 2s/step - loss: 4.8434e-04 - accuracy: 1.0000 - f1_score: 0.7013 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 0.8798 - val_accuracy: 0.8624 - val_f1_score: 0.6895 - val_precision_18: 0.8595 - val_recall_18: 0.8664\n",
      "Epoch 21/40\n",
      "50/50 [==============================] - 87s 2s/step - loss: 4.0534e-04 - accuracy: 1.0000 - f1_score: 0.7063 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 0.9188 - val_accuracy: 0.8615 - val_f1_score: 0.7018 - val_precision_18: 0.8684 - val_recall_18: 0.8522\n",
      "Epoch 22/40\n",
      "50/50 [==============================] - 88s 2s/step - loss: 2.6280e-04 - accuracy: 1.0000 - f1_score: 0.7154 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 0.9547 - val_accuracy: 0.8618 - val_f1_score: 0.7093 - val_precision_18: 0.8680 - val_recall_18: 0.8534\n",
      "Epoch 23/40\n",
      "50/50 [==============================] - 88s 2s/step - loss: 2.0463e-04 - accuracy: 1.0000 - f1_score: 0.7237 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 1.0013 - val_accuracy: 0.8620 - val_f1_score: 0.7200 - val_precision_18: 0.8680 - val_recall_18: 0.8540\n",
      "Epoch 24/40\n",
      "50/50 [==============================] - 88s 2s/step - loss: 1.5651e-04 - accuracy: 1.0000 - f1_score: 0.7313 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.8603 - val_f1_score: 0.7158 - val_precision_18: 0.8676 - val_recall_18: 0.8505\n",
      "Epoch 25/40\n",
      "50/50 [==============================] - 91s 2s/step - loss: 1.2606e-04 - accuracy: 1.0000 - f1_score: 0.7320 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 1.0306 - val_accuracy: 0.8612 - val_f1_score: 0.7250 - val_precision_18: 0.8675 - val_recall_18: 0.8525\n",
      "Epoch 26/40\n",
      "50/50 [==============================] - 88s 2s/step - loss: 1.2381e-04 - accuracy: 1.0000 - f1_score: 0.7421 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 1.0669 - val_accuracy: 0.8606 - val_f1_score: 0.7357 - val_precision_18: 0.8704 - val_recall_18: 0.8474\n",
      "Epoch 27/40\n",
      "50/50 [==============================] - 90s 2s/step - loss: 1.5540e-04 - accuracy: 1.0000 - f1_score: 0.7308 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 1.0374 - val_accuracy: 0.8602 - val_f1_score: 0.7151 - val_precision_18: 0.8594 - val_recall_18: 0.8614\n",
      "Epoch 28/40\n",
      "50/50 [==============================] - 91s 2s/step - loss: 1.0384e-04 - accuracy: 1.0000 - f1_score: 0.7333 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 1.0635 - val_accuracy: 0.8606 - val_f1_score: 0.7306 - val_precision_18: 0.8680 - val_recall_18: 0.8504\n",
      "Epoch 29/40\n",
      "50/50 [==============================] - 104s 2s/step - loss: 9.8150e-05 - accuracy: 1.0000 - f1_score: 0.7464 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 1.0900 - val_accuracy: 0.8608 - val_f1_score: 0.7319 - val_precision_18: 0.8635 - val_recall_18: 0.8571\n",
      "Epoch 30/40\n",
      "50/50 [==============================] - 97s 2s/step - loss: 9.3277e-05 - accuracy: 1.0000 - f1_score: 0.7450 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 1.1018 - val_accuracy: 0.8603 - val_f1_score: 0.7329 - val_precision_18: 0.8602 - val_recall_18: 0.8605\n",
      "Epoch 31/40\n",
      "50/50 [==============================] - 101s 2s/step - loss: 8.0191e-05 - accuracy: 1.0000 - f1_score: 0.7529 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 1.1185 - val_accuracy: 0.8600 - val_f1_score: 0.7369 - val_precision_18: 0.8571 - val_recall_18: 0.8639\n",
      "Epoch 32/40\n",
      "50/50 [==============================] - 100s 2s/step - loss: 1.5001e-04 - accuracy: 1.0000 - f1_score: 0.7483 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 1.0920 - val_accuracy: 0.8606 - val_f1_score: 0.7318 - val_precision_18: 0.8690 - val_recall_18: 0.8493\n",
      "Epoch 33/40\n",
      "50/50 [==============================] - 109s 2s/step - loss: 7.7290e-05 - accuracy: 1.0000 - f1_score: 0.7492 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 1.1136 - val_accuracy: 0.8606 - val_f1_score: 0.7376 - val_precision_18: 0.8674 - val_recall_18: 0.8513\n",
      "Epoch 34/40\n",
      "50/50 [==============================] - 88s 2s/step - loss: 6.7103e-05 - accuracy: 1.0000 - f1_score: 0.7608 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 1.1584 - val_accuracy: 0.8609 - val_f1_score: 0.7495 - val_precision_18: 0.8668 - val_recall_18: 0.8529\n",
      "Epoch 35/40\n",
      "50/50 [==============================] - 85s 2s/step - loss: 4.5941e-05 - accuracy: 1.0000 - f1_score: 0.7654 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 1.1809 - val_accuracy: 0.8602 - val_f1_score: 0.7554 - val_precision_18: 0.8699 - val_recall_18: 0.8470\n",
      "Epoch 36/40\n",
      "50/50 [==============================] - 86s 2s/step - loss: 5.1513e-05 - accuracy: 1.0000 - f1_score: 0.7710 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 1.1853 - val_accuracy: 0.8605 - val_f1_score: 0.7544 - val_precision_18: 0.8651 - val_recall_18: 0.8542\n",
      "Epoch 37/40\n",
      "50/50 [==============================] - 84s 2s/step - loss: 7.8214e-05 - accuracy: 1.0000 - f1_score: 0.7457 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 1.1617 - val_accuracy: 0.8594 - val_f1_score: 0.7424 - val_precision_18: 0.8699 - val_recall_18: 0.8452\n",
      "Epoch 38/40\n",
      "50/50 [==============================] - 84s 2s/step - loss: 5.8421e-05 - accuracy: 1.0000 - f1_score: 0.7618 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 1.1971 - val_accuracy: 0.8589 - val_f1_score: 0.7558 - val_precision_18: 0.8730 - val_recall_18: 0.8399\n",
      "Epoch 39/40\n",
      "50/50 [==============================] - 92s 2s/step - loss: 4.5667e-05 - accuracy: 1.0000 - f1_score: 0.7628 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 1.1817 - val_accuracy: 0.8598 - val_f1_score: 0.7430 - val_precision_18: 0.8658 - val_recall_18: 0.8514\n",
      "Epoch 40/40\n",
      "50/50 [==============================] - 90s 2s/step - loss: 3.4535e-05 - accuracy: 1.0000 - f1_score: 0.7631 - precision_18: 1.0000 - recall_18: 1.0000 - val_loss: 1.2263 - val_accuracy: 0.8605 - val_f1_score: 0.7505 - val_precision_18: 0.8622 - val_recall_18: 0.8582\n",
      "50/50 [==============================] - 24s 470ms/step - loss: 1.2263 - accuracy: 0.8605 - f1_score: 0.7505 - precision_18: 0.8622 - recall_18: 0.8582\n",
      "\n",
      "Test score: 1.2263259887695312\n",
      "Test accuracy: 0.8605200052261353\n",
      "782/782 [==============================] - 33s 42ms/step\n",
      "результат: 0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[0.30167684]]\n"
     ]
    }
   ],
   "source": [
    "model = build_model8()\n",
    "model.summary()\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\", keras.metrics.F1Score(), keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "score = model.fit(X_train, y_train,\n",
    " epochs = EPOCHS,\n",
    " batch_size = BATCH_SIZE,\n",
    " validation_data = (X_test, y_test)\n",
    ")\n",
    "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save(\"imdb2.h5\")\n",
    "\n",
    "val = model.predict(X_train)\n",
    "print(f'результат: {np.argmax(val[0])}')\n",
    "word2index = imdb.get_word_index()\n",
    "test=[]\n",
    "for word in word_tokenize( \"i love this movie\"):\n",
    "     test.append(word2index[word])\n",
    "\n",
    "test=pad_sequences([test],maxlen=200)\n",
    "print(model.predict(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SWITCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ops' from 'keras' (/opt/homebrew/lib/python3.11/site-packages/keras/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[1;32m      5\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m  \u001b[38;5;66;03m# Only consider the top 20k words\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ops' from 'keras' (/opt/homebrew/lib/python3.11/site-packages/keras/__init__.py)"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import ops\n",
    "from keras import layers\n",
    "\n",
    "vocab_size = 10000  # Only consider the top 20k words\n",
    "num_tokens_per_example = 200  # Only consider the first 200 words of each movie review\n",
    "(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(num_words=vocab_size)\n",
    "print(len(x_train), \"Training sequences\")\n",
    "print(len(x_val), \"Validation sequences\")\n",
    "x_train = keras.utils.pad_sequences(x_train, maxlen=num_tokens_per_example)\n",
    "x_val = keras.utils.pad_sequences(x_val, maxlen=num_tokens_per_example)\n",
    "\n",
    "embed_dim = 64  # Embedding size for each token.\n",
    "num_heads = 2  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feedforward network.\n",
    "num_experts = 10  # Number of experts used in the Switch Transformer.\n",
    "batch_size = 50  # Batch size.\n",
    "learning_rate = 0.001  # Learning rate.\n",
    "dropout_rate = 0.3  # Dropout rate.\n",
    "num_epochs = 10 # Number of epochs.\n",
    "num_tokens_per_batch = (\n",
    "    batch_size * num_tokens_per_example\n",
    ")  # Total number of tokens per batch.\n",
    "print(f\"Number of tokens per batch: {num_tokens_per_batch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = ops.shape(x)[-1]\n",
    "        positions = ops.arange(start=0, stop=maxlen, step=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feedforward_network(ff_dim, embed_dim, name=None):\n",
    "    return keras.Sequential(\n",
    "        [layers.Dense(ff_dim, activation=\"gelu\"), layers.Dense(embed_dim)], name=name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_balanced_loss(router_probs, expert_mask):\n",
    "    # router_probs [tokens_per_batch, num_experts] is the probability assigned for\n",
    "    # each expert per token. expert_mask [tokens_per_batch, num_experts] contains\n",
    "    # the expert with the highest router probability in one−hot format.\n",
    "\n",
    "    num_experts = ops.shape(expert_mask)[-1]\n",
    "    # Get the fraction of tokens routed to each expert.\n",
    "    # density is a vector of length num experts that sums to 1.\n",
    "    density = ops.mean(expert_mask, axis=0)\n",
    "    # Get fraction of probability mass assigned to each expert from the router\n",
    "    # across all tokens. density_proxy is a vector of length num experts that sums to 1.\n",
    "    density_proxy = ops.mean(router_probs, axis=0)\n",
    "    # Want both vectors to have uniform allocation (1/num experts) across all\n",
    "    # num_expert elements. The two vectors will be pushed towards uniform allocation\n",
    "    # when the dot product is minimized.\n",
    "    loss = ops.mean(density_proxy * density) * ops.cast((num_experts**2), \"float32\")\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Router(layers.Layer):\n",
    "    def __init__(self, num_experts, expert_capacity):\n",
    "        self.num_experts = num_experts\n",
    "        self.route = layers.Dense(units=num_experts)\n",
    "        self.expert_capacity = expert_capacity\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # inputs shape: [tokens_per_batch, embed_dim]\n",
    "        # router_logits shape: [tokens_per_batch, num_experts]\n",
    "        router_logits = self.route(inputs)\n",
    "\n",
    "        if training:\n",
    "            # Add noise for exploration across experts.\n",
    "            router_logits += keras.random.uniform(\n",
    "                shape=router_logits.shape, minval=0.9, maxval=1.1\n",
    "            )\n",
    "        # Probabilities for each token of what expert it should be sent to.\n",
    "        router_probs = keras.activations.softmax(router_logits, axis=-1)\n",
    "        # Get the top−1 expert for each token. expert_gate is the top−1 probability\n",
    "        # from the router for each token. expert_index is what expert each token\n",
    "        # is going to be routed to.\n",
    "        expert_gate, expert_index = ops.top_k(router_probs, k=1)\n",
    "        # expert_mask shape: [tokens_per_batch, num_experts]\n",
    "        expert_mask = ops.one_hot(expert_index, self.num_experts)\n",
    "        # Compute load balancing loss.\n",
    "        aux_loss = load_balanced_loss(router_probs, expert_mask)\n",
    "        self.add_loss(aux_loss)\n",
    "        # Experts have a fixed capacity, ensure we do not exceed it. Construct\n",
    "        # the batch indices, to each expert, with position in expert make sure that\n",
    "        # not more that expert capacity examples can be routed to each expert.\n",
    "        position_in_expert = ops.cast(\n",
    "            ops.cumsum(expert_mask, axis=0) * expert_mask, \"int32\"\n",
    "        )\n",
    "        # Keep only tokens that fit within expert capacity.\n",
    "        expert_mask *= ops.cast(\n",
    "            ops.less(ops.cast(position_in_expert, \"int32\"), self.expert_capacity),\n",
    "            \"float32\",\n",
    "        )\n",
    "        expert_mask_flat = ops.sum(expert_mask, axis=-1)\n",
    "        # Mask out the experts that have overflowed the expert capacity.\n",
    "        expert_gate *= expert_mask_flat\n",
    "        # Combine expert outputs and scaling with router probability.\n",
    "        # combine_tensor shape: [tokens_per_batch, num_experts, expert_capacity]\n",
    "        combined_tensor = ops.expand_dims(\n",
    "            expert_gate\n",
    "            * expert_mask_flat\n",
    "            * ops.squeeze(ops.one_hot(expert_index, self.num_experts), 1),\n",
    "            -1,\n",
    "        ) * ops.squeeze(ops.one_hot(position_in_expert, self.expert_capacity), 1)\n",
    "        # Create binary dispatch_tensor [tokens_per_batch, num_experts, expert_capacity]\n",
    "        # that is 1 if the token gets routed to the corresponding expert.\n",
    "        dispatch_tensor = ops.cast(combined_tensor, \"float32\")\n",
    "\n",
    "        return dispatch_tensor, combined_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Switch(layers.Layer):\n",
    "    def __init__(\n",
    "        self, num_experts, embed_dim, ff_dim, num_tokens_per_batch, capacity_factor=1\n",
    "    ):\n",
    "        self.num_experts = num_experts\n",
    "        self.embed_dim = embed_dim\n",
    "        self.experts = [\n",
    "            create_feedforward_network(ff_dim, embed_dim) for _ in range(num_experts)\n",
    "        ]\n",
    "\n",
    "        self.expert_capacity = num_tokens_per_batch // self.num_experts\n",
    "        self.router = Router(self.num_experts, self.expert_capacity)\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = ops.shape(inputs)[0]\n",
    "        num_tokens_per_example = ops.shape(inputs)[1]\n",
    "\n",
    "        # inputs shape: [num_tokens_per_batch, embed_dim]\n",
    "        inputs = ops.reshape(inputs, [num_tokens_per_batch, self.embed_dim])\n",
    "        # dispatch_tensor shape: [expert_capacity, num_experts, tokens_per_batch]\n",
    "        # combine_tensor shape: [tokens_per_batch, num_experts, expert_capacity]\n",
    "        dispatch_tensor, combine_tensor = self.router(inputs)\n",
    "        # expert_inputs shape: [num_experts, expert_capacity, embed_dim]\n",
    "        expert_inputs = ops.einsum(\"ab,acd->cdb\", inputs, dispatch_tensor)\n",
    "        expert_inputs = ops.reshape(\n",
    "            expert_inputs, [self.num_experts, self.expert_capacity, self.embed_dim]\n",
    "        )\n",
    "        # Dispatch to experts\n",
    "        expert_input_list = ops.unstack(expert_inputs, axis=0)\n",
    "        expert_output_list = [\n",
    "            self.experts[idx](expert_input)\n",
    "            for idx, expert_input in enumerate(expert_input_list)\n",
    "        ]\n",
    "        # expert_outputs shape: [expert_capacity, num_experts, embed_dim]\n",
    "        expert_outputs = ops.stack(expert_output_list, axis=1)\n",
    "        # expert_outputs_combined shape: [tokens_per_batch, embed_dim]\n",
    "        expert_outputs_combined = ops.einsum(\n",
    "            \"abc,xba->xc\", expert_outputs, combine_tensor\n",
    "        )\n",
    "        # output shape: [batch_size, num_tokens_per_example, embed_dim]\n",
    "        outputs = ops.reshape(\n",
    "            expert_outputs_combined,\n",
    "            [batch_size, num_tokens_per_example, self.embed_dim],\n",
    "        )\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ffn, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        # The ffn can be either a standard feedforward network or a switch\n",
    "        # layer with a Mixture of Experts.\n",
    "        self.ffn = ffn\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier():\n",
    "    switch = Switch(num_experts, embed_dim, ff_dim, num_tokens_per_batch)\n",
    "    transformer_block = TransformerBlock(embed_dim // num_heads, num_heads, switch)\n",
    "\n",
    "    inputs = layers.Input(shape=(num_tokens_per_example,))\n",
    "    embedding_layer = TokenAndPositionEmbedding(\n",
    "        num_tokens_per_example, vocab_size, embed_dim\n",
    "    )\n",
    "    x = embedding_layer(inputs)\n",
    "    x = transformer_block(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Dense(ff_dim, activation=\"relu\")(x) \n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "    classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 641ms/step - accuracy: 0.6665 - loss: 1.5749 - val_accuracy: 0.8788 - val_loss: 1.2904\n",
      "Epoch 2/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 634ms/step - accuracy: 0.9211 - loss: 1.2108 - val_accuracy: 0.8704 - val_loss: 1.3028\n",
      "Epoch 3/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 629ms/step - accuracy: 0.9580 - loss: 1.1251 - val_accuracy: 0.8611 - val_loss: 1.3653\n",
      "Epoch 4/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 621ms/step - accuracy: 0.9778 - loss: 1.0737 - val_accuracy: 0.8524 - val_loss: 1.5357\n",
      "Epoch 5/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 728ms/step - accuracy: 0.9868 - loss: 1.0430 - val_accuracy: 0.8382 - val_loss: 1.6533\n",
      "Epoch 6/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 638ms/step - accuracy: 0.9903 - loss: 1.0326 - val_accuracy: 0.8446 - val_loss: 1.8236\n",
      "Epoch 7/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 649ms/step - accuracy: 0.9927 - loss: 1.0241 - val_accuracy: 0.8428 - val_loss: 1.8575\n",
      "Epoch 8/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 628ms/step - accuracy: 0.9951 - loss: 1.0162 - val_accuracy: 0.8322 - val_loss: 1.8481\n",
      "Epoch 9/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 628ms/step - accuracy: 0.9952 - loss: 1.0152 - val_accuracy: 0.8354 - val_loss: 2.1084\n",
      "Epoch 10/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 631ms/step - accuracy: 0.9957 - loss: 1.0123 - val_accuracy: 0.8230 - val_loss: 2.2112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2ed626da0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_experiment(classifier):\n",
    "    classifier.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate), #поменять на RMSProp\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    history = classifier.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=(x_val, y_val),\n",
    "    )\n",
    "    return history\n",
    "\n",
    "\n",
    "classifier = create_classifier()\n",
    "run_experiment(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = ops.shape(x)[-1]\n",
    "        positions = ops.arange(start=0, stop=maxlen, step=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 20000  # Only consider the top 20k words\n",
    "maxlen = 200  # Only consider the first 200 words of each movie review\n",
    "(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(num_words=vocab_size)\n",
    "print(len(x_train), \"Training sequences\")\n",
    "print(len(x_val), \"Validation sequences\")\n",
    "x_train = keras.utils.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = keras.utils.pad_sequences(x_val, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 32  # Embedding size for each token\n",
    "num_heads = 2  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "inputs = layers.Input(shape=(maxlen,))\n",
    "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(20, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=32, epochs=2, validation_data=(x_val, y_val)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
